Modules loaded
uc2n481
uc2n481
uc2n481
uc2n481
uc2n482
uc2n482
uc2n482
uc2n482
uc2n483
uc2n483
uc2n483
uc2n483
uc2n484
uc2n484
uc2n484
uc2n484
16: uc2n481 uc2n481 uc2n481 uc2n481 uc2n482 uc2n482 uc2n482 uc2n482 uc2n483 uc2n483 uc2n483 uc2n483 uc2n484 uc2n484 uc2n484 uc2n484
start building
-- The CUDA compiler identification is NVIDIA 11.0.194
-- The CXX compiler identification is GNU 8.3.1
-- Detecting CUDA compiler ABI info
-- Detecting CUDA compiler ABI info - done
-- Check for working CUDA compiler: /opt/bwhpc/common/devel/cuda/11.0/bin/nvcc - skipped
-- Detecting CUDA compile features
-- Detecting CUDA compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /usr/bin/g++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Found MPI_CXX: /pfs/data5/software_uc2/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so (found version "3.1") 
-- Found MPI: TRUE (found version "3.1")  
-- Found CUDAToolkit: /opt/bwhpc/common/devel/cuda/11.0/include (found version "11.0.194") 
-- Looking for C++ include pthread.h
-- Looking for C++ include pthread.h - found
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed
-- Looking for pthread_create in pthreads
-- Looking for pthread_create in pthreads - not found
-- Looking for pthread_create in pthread
-- Looking for pthread_create in pthread - found
-- Found Threads: TRUE  
-- Configuring done
-- Generating done
-- Build files have been written to: /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4
Scanning dependencies of target test_base
[  3%] Building CUDA object CMakeFiles/test_base.dir/tests/src/base.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[  6%] Linking CUDA shared library libtest_base.so
[  6%] Built target test_base
Scanning dependencies of target mpicufft
[  9%] Building CXX object CMakeFiles/mpicufft.dir/src/mpicufft.cpp.o
[ 12%] Linking CXX shared library libmpicufft.so
[ 12%] Built target mpicufft
Scanning dependencies of target timer
[ 15%] Building CXX object CMakeFiles/timer.dir/src/timer.cpp.o
[ 18%] Linking CXX shared library libtimer.so
[ 18%] Built target timer
Scanning dependencies of target pencil_decomp
[ 21%] Building CXX object CMakeFiles/pencil_decomp.dir/src/pencil/mpicufft_pencil.cpp.o
[ 24%] Building CXX object CMakeFiles/pencil_decomp.dir/src/pencil/mpicufft_pencil_opt1.cpp.o
[ 27%] Linking CXX shared library libpencil_decomp.so
[ 27%] Built target pencil_decomp
Scanning dependencies of target pencil_tests
[ 30%] Building CUDA object CMakeFiles/pencil_tests.dir/tests/src/pencil/base.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 33%] Building CUDA object CMakeFiles/pencil_tests.dir/tests/src/pencil/random_dist_1D.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 36%] Building CUDA object CMakeFiles/pencil_tests.dir/tests/src/pencil/random_dist_2D.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 39%] Building CUDA object CMakeFiles/pencil_tests.dir/tests/src/pencil/random_dist_3D.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 42%] Linking CUDA shared library libpencil_tests.so
[ 42%] Built target pencil_tests
Scanning dependencies of target pencil
[ 45%] Building CXX object CMakeFiles/pencil.dir/tests/src/pencil/main.cpp.o
[ 48%] Linking CXX executable pencil
[ 48%] Built target pencil
Scanning dependencies of target slab_decomp
[ 51%] Building CXX object CMakeFiles/slab_decomp.dir/src/slab/default/mpicufft_slab.cpp.o
[ 54%] Building CXX object CMakeFiles/slab_decomp.dir/src/slab/default/mpicufft_slab_opt1.cpp.o
[ 57%] Building CXX object CMakeFiles/slab_decomp.dir/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp.o
[ 60%] Building CXX object CMakeFiles/slab_decomp.dir/src/slab/z_then_yx/mpicufft_slab_z_then_yx_opt1.cpp.o
[ 63%] Building CXX object CMakeFiles/slab_decomp.dir/src/slab/y_then_zx/mpicufft_slab_y_then_zx.cpp.o
[ 66%] Linking CXX shared library libslab_decomp.so
[ 66%] Built target slab_decomp
Scanning dependencies of target slab_tests
[ 69%] Building CUDA object CMakeFiles/slab_tests.dir/tests/src/slab/base.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 72%] Building CUDA object CMakeFiles/slab_tests.dir/tests/src/slab/random_dist_default.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 75%] Building CUDA object CMakeFiles/slab_tests.dir/tests/src/slab/random_dist_y_then_zx.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 78%] Building CUDA object CMakeFiles/slab_tests.dir/tests/src/slab/random_dist_z_then_yx.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 81%] Linking CUDA shared library libslab_tests.so
[ 81%] Built target slab_tests
Scanning dependencies of target slab
[ 84%] Building CXX object CMakeFiles/slab.dir/tests/src/slab/main.cpp.o
[ 87%] Linking CXX executable slab
[ 87%] Built target slab
Scanning dependencies of target reference_tests
[ 90%] Building CUDA object CMakeFiles/reference_tests.dir/tests/src/reference/reference.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 93%] Linking CUDA shared library libreference_tests.so
[ 93%] Built target reference_tests
Scanning dependencies of target reference
[ 96%] Building CXX object CMakeFiles/reference.dir/tests/src/reference/main.cpp.o
[100%] Linking CXX executable reference
[100%] Built target reference
finished building
*****************************************************************************
Starting on HOST16
*****************************************************************************
-----------------------------------------------------------------------------
Partition 2x8 / 4x4
-----------------------------------------------------------------------------
Pencil Default
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3611036] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3611036] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3611193] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3611193] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3611460] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3611460] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3611603] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3611603] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3611747] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3611747] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3611893] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3611893] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3612174] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3612174] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3612320] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3612320] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3612467] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3612467] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3612612] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3612612] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3612773] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3612773] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3613040] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3613040] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3613187] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3613187] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3613334] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3613334] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3613476] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3613476] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3613758] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3613758] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3613902] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3613902] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3614049] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3614049] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3614193] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3614193] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3614349] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3614349] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3614615] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3614615] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3614761] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3614761] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3614908] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3614908] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3615050] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3615050] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3615338] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3615338] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3615484] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3615484] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3615629] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3615629] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3615771] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3615771] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3615927] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3615927] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3616195] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3616195] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3616343] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3616343] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3616486] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3616486] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3616645] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3616645] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3616917] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3616917] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3617064] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3617064] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3617204] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3617204] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3617365] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3617365] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3617507] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3617507] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3617775] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3617775] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3617921] [[33965,0],0] ORTE_ERROR_LOG: Out of resource in file util/show_help.c at line 507
[uc2n481.localdomain:3617921] 14 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3617921] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3618075] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3618075] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3618220] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3618220] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3618491] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3618491] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3618635] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3618635] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3618794] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3618794] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3618941] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3618941] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3619085] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3619085] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3619356] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3619356] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3619519] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3619519] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3619670] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3619670] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3619829] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3619829] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3620095] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3620095] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3620240] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3620240] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3620386] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3620386] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3620529] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3620529] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3620687] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3620687] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3620956] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3620956] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3621123] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3621123] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3621268] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3621268] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3621432] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3621432] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3621706] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3621706] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3621851] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3621851] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3621991] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3621991] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3622149] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3622149] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3622296] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3622296] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3622562] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3622562] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3622733] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3622733] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3622880] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3622880] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3623042] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3623042] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3623325] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3623325] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3623470] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3623470] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3623618] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3623618] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3623779] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3623779] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3623927] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3623927] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3624210] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3624210] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3624386] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3624386] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3624550] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3624550] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3624724] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3624724] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3625008] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3625008] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3625157] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3625157] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3625316] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3625316] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3625467] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3625467] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3625633] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3625633] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3625919] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3625919] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3626143] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3626143] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3626309] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3626309] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3626534] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3626534] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3626821] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3626821] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3626983] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3626983] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3627152] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3627152] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3627320] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3627320] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3627492] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3627492] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3627804] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3627804] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3628032] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3628032] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3628221] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3628221] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3628448] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3628448] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3628756] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3628756] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3628934] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3628934] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3629117] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3629117] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3629311] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3629311] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3629520] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3629520] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3629859] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3629859] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3630188] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3630188] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3630403] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3630403] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3630722] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3630722] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3631048] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3631048] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3631260] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3631260] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3631479] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3631479] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3631700] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3631700] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481:3631717] *** An error occurred in MPI_Irecv
[uc2n481:3631717] *** reported by process [3665297409,2]
[uc2n481:3631717] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n481:3631717] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3631717] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3631717] ***    and potentially your MPI job)
[uc2n481.localdomain:3631700] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3631842] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3631842] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481:3631862] *** An error occurred in MPI_Irecv
[uc2n481:3631862] *** reported by process [3670933505,1]
[uc2n481:3631862] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n481:3631862] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3631862] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3631862] ***    and potentially your MPI job)
[uc2n481.localdomain:3631842] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3632012] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3632012] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n483:360936] *** An error occurred in MPI_Irecv
[uc2n483:360936] *** reported by process [3684696065,9]
[uc2n483:360936] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n483:360936] *** MPI_ERR_COUNT: invalid count argument
[uc2n483:360936] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n483:360936] ***    and potentially your MPI job)
[uc2n481.localdomain:3632012] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3632167] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3632167] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n482:458448] *** An error occurred in MPI_Irecv
[uc2n482:458448] *** reported by process [3691708417,6]
[uc2n482:458448] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n482:458448] *** MPI_ERR_COUNT: invalid count argument
[uc2n482:458448] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n482:458448] ***    and potentially your MPI job)
[uc2n481.localdomain:3632167] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3632310] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3632310] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n484:4086333] *** An error occurred in MPI_Irecv
[uc2n484:4086333] *** reported by process [3701080065,14]
[uc2n484:4086333] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n484:4086333] *** MPI_ERR_COUNT: invalid count argument
[uc2n484:4086333] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n484:4086333] ***    and potentially your MPI job)
[uc2n481.localdomain:3632310] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3632476] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3632476] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n483:361418] *** An error occurred in MPI_Irecv
[uc2n483:361418] *** reported by process [3715104769,11]
[uc2n483:361418] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n483:361418] *** MPI_ERR_COUNT: invalid count argument
[uc2n483:361418] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n483:361418] ***    and potentially your MPI job)
[uc2n481.localdomain:3632476] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3632636] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3632636] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n483:361570] *** An error occurred in MPI_Irecv
[uc2n483:361570] *** reported by process [3721396225,9]
[uc2n483:361570] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n483:361570] *** MPI_ERR_COUNT: invalid count argument
[uc2n483:361570] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n483:361570] ***    and potentially your MPI job)
[uc2n481.localdomain:3632636] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3632779] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3632779] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n484:4086807] *** An error occurred in MPI_Alltoallv
[uc2n484:4086807] *** reported by process [3735486465,15]
[uc2n484:4086807] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n484:4086807] *** MPI_ERR_COUNT: invalid count argument
[uc2n484:4086807] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n484:4086807] ***    and potentially your MPI job)
[uc2n481.localdomain:3632779] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3632930] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3632930] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n482:459253] *** An error occurred in MPI_Alltoallw
[uc2n482:459253] *** reported by process [3742236673,7]
[uc2n482:459253] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n482:459253] *** MPI_ERR_COUNT: invalid count argument
[uc2n482:459253] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n482:459253] ***    and potentially your MPI job)
[uc2n481.localdomain:3632930] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3633088] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3633088] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3633231] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3633231] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3633391] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3633391] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3633535] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3633535] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3633679] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3633679] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3633839] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3633839] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3633992] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3633992] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3634140] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3634140] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3634283] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3634283] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3634440] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3634440] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3634583] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3634583] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3634740] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3634740] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3634884] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3634884] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3635029] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3635029] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3635188] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3635188] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3635340] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3635340] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3635488] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3635488] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3635632] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3635632] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3635777] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3635777] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3635937] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3635937] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3636094] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3636094] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3636242] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3636242] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3636387] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3636387] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3636546] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3636546] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3636697] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3636697] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3636846] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3636846] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3637003] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3637003] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3637148] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3637148] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3637295] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3637295] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3637472] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3637472] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3637637] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3637637] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3637784] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3637784] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3637954] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3637954] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3638126] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3638126] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3638274] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3638274] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3638434] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3638434] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3638600] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3638600] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 2 with PID 0 on
node uc2n481 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3638747] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3638747] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 2 with PID 0 on
node uc2n481 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3638894] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3638894] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481:3638934] *** An error occurred in MPI_Irecv
[uc2n481:3638934] *** reported by process [910295041,3]
[uc2n481:3638934] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n481:3638934] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3638934] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3638934] ***    and potentially your MPI job)
[uc2n481.localdomain:3638894] 7 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3639136] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3639136] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 3 with PID 0 on
node uc2n481 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3639283] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3639283] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n482:465916] *** An error occurred in MPI_Irecv
[uc2n482:465916] *** reported by process [937361409,7]
[uc2n482:465916] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n482:465916] *** MPI_ERR_COUNT: invalid count argument
[uc2n482:465916] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n482:465916] ***    and potentially your MPI job)
[uc2n481.localdomain:3639283] 3 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3639551] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3639551] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 2 with PID 0 on
node uc2n481 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3639713] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3639713] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 15 with PID 4093889 on
node uc2n484 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3639859] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3639859] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 15 with PID 4094056 on
node uc2n484 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3640024] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3640024] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 3 with PID 0 on
node uc2n481 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128
2021-09-29 02:04:11.764173
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128
2021-09-29 02:04:24.750385
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128
2021-09-29 02:04:30.292293
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128
2021-09-29 02:04:37.051742
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128
2021-09-29 02:04:42.568520
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128
2021-09-29 02:04:49.394148
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128
2021-09-29 02:05:01.163217
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128
2021-09-29 02:05:07.385499
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128
2021-09-29 02:05:12.942869
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 256
2021-09-29 02:05:18.444050
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 256
2021-09-29 02:05:23.983563
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 256
2021-09-29 02:05:29.517144
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 256
2021-09-29 02:05:39.682394
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 256
2021-09-29 02:05:45.220397
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 256
2021-09-29 02:05:52.063614
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 256
2021-09-29 02:05:58.095431
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 256
2021-09-29 02:06:03.639502
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 256
2021-09-29 02:06:09.230089
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 256 -nz 256
2021-09-29 02:06:17.490377
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 256 -nz 256
2021-09-29 02:06:24.897933
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 256 -nz 256
2021-09-29 02:06:30.508100
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 256 -nz 256
2021-09-29 02:06:38.414362
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 256 -nz 256
2021-09-29 02:06:43.998985
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 256 -nz 256
2021-09-29 02:06:52.199285
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 256 -nz 256
2021-09-29 02:07:05.110563
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 256 -nz 256
2021-09-29 02:07:10.706254
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 256 -nz 256
2021-09-29 02:07:16.293601
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256
2021-09-29 02:07:21.932974
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256
2021-09-29 02:07:28.040461
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256
2021-09-29 02:07:33.687231
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256
2021-09-29 02:07:44.298766
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256
2021-09-29 02:07:50.091360
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256
2021-09-29 02:08:00.411947
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256
2021-09-29 02:08:08.081144
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256
2021-09-29 02:08:13.740550
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256
2021-09-29 02:08:19.377369
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 512
2021-09-29 02:08:25.190703
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 512
2021-09-29 02:08:30.977894
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 512
2021-09-29 02:08:36.792461
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 512
2021-09-29 02:08:49.257062
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 512
2021-09-29 02:08:55.075954
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 512
2021-09-29 02:09:05.924644
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 512
2021-09-29 02:09:11.777956
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 512
2021-09-29 02:09:17.576970
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 512
2021-09-29 02:09:27.355981
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 512 -nz 512
2021-09-29 02:09:34.215422
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 512 -nz 512
2021-09-29 02:09:40.368548
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 512 -nz 512
2021-09-29 02:09:46.529314
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 512 -nz 512
2021-09-29 02:10:01.685982
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 512 -nz 512
2021-09-29 02:10:09.558052
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 512 -nz 512
2021-09-29 02:10:24.560034
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 512 -nz 512
2021-09-29 02:10:30.727302
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 512 -nz 512
2021-09-29 02:10:37.302605
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 512 -nz 512
2021-09-29 02:10:44.071454
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512
2021-09-29 02:10:52.086751
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512
2021-09-29 02:10:58.848374
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512
2021-09-29 02:11:05.633431
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512
2021-09-29 02:11:30.433590
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512
2021-09-29 02:11:37.178053
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512
2021-09-29 02:12:01.695379
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512
2021-09-29 02:12:09.259107
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512
2021-09-29 02:12:16.034996
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512
2021-09-29 02:12:22.867166
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 1024
2021-09-29 02:12:30.465044
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 1024
2021-09-29 02:12:39.241211
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 1024
2021-09-29 02:12:48.336116
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 1024
2021-09-29 02:13:14.846889
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 1024
2021-09-29 02:13:23.240530
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 1024
2021-09-29 02:13:49.043795
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 1024
2021-09-29 02:13:58.317744
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 1024
2021-09-29 02:14:06.581289
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 1024
2021-09-29 02:14:15.233863
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 02:14:25.737712
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 02:14:39.327483
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 02:14:53.933810
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 02:15:47.280143
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 02:16:01.185221
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 02:16:49.825660
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 02:17:03.457044
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 02:17:17.023693
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 02:17:31.869587
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 02:17:48.968234
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 02:18:12.325947
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 02:18:37.279002
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 02:20:18.075568
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 02:20:41.832857
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 02:22:18.159044
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 02:22:41.425052
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 02:23:04.020922
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 02:23:30.267213
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 02:23:59.809720
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 02:24:41.707690
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 02:25:24.704695
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 02:27:19.072637
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 02:28:00.938403
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 02:29:51.386973
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 02:30:32.790011
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 02:31:17.286611
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 02:32:01.811374
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 02:32:57.755054
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 02:34:17.565252
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 02:35:35.463042
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 02:39:19.586837
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 02:40:33.615966
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 02:44:07.649852
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 02:45:22.617709
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 02:46:38.045649
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 02:47:57.372263
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 02:49:39.187740
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 02:49:45.549730
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 02:49:55.622180
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 02:50:15.153135
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 02:50:25.361876
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 02:50:44.714004
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 02:50:58.533412
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 02:51:08.687387
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 02:51:18.839314
b''

Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 02:51:29.463493
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 02:51:37.739345
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 02:51:43.443995
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 02:51:49.221391
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 02:51:54.915342
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 02:52:00.795091
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 02:52:06.637193
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 02:52:14.080571
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 02:52:20.266458
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 02:52:26.423139
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 02:52:32.538605
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 02:52:38.403804
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 02:52:44.619232
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 02:52:52.158025
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 02:53:00.563052
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 02:53:06.376136
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 02:53:12.212681
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 02:53:18.066402
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 02:53:23.946889
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 02:53:31.002205
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 02:53:39.464645
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 02:53:47.981663
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 02:53:55.064880
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 02:54:03.517145
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 02:54:10.478288
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 02:54:19.971056
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 02:54:27.350793
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 02:54:34.376244
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 02:54:51.741292
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 02:55:11.217900
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 02:55:34.561991
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 02:55:52.125058
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 02:56:15.401753
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 02:56:33.569647
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 02:56:50.988743
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 02:57:09.016744
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 02:57:26.876931
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 02:57:39.031703
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 02:57:50.522044
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 02:59:31.946585
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 02:59:50.171643
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 03:01:24.964626
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 03:01:44.148659
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 03:01:55.540774
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 03:02:17.470020
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3640187] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3640187] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3640331] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3640331] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3640600] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3640600] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3640746] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3640746] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3640891] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3640891] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3641045] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3641045] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3641312] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3641312] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3641466] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3641466] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3641608] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3641608] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3641765] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3641765] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3641907] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3641907] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3642177] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3642177] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3642324] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3642324] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3642466] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3642466] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3642629] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3642629] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3642897] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3642897] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3643040] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3643040] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3643190] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3643190] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3643332] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3643332] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3643489] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3643489] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3643758] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3643758] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3643907] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3643907] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3644051] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3644051] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3644207] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3644207] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3644478] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3644478] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3644621] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3644621] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3644769] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3644769] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3644912] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3644912] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3645074] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3645074] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3645341] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3645341] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3645488] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3645488] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3645630] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3645630] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3645789] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3645789] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3646058] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3646058] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3646202] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3646202] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3646350] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3646350] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3646496] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3646496] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3646651] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3646651] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3646919] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3646919] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3647066] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3647066] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3647210] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3647210] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3647372] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3647372] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3647643] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3647643] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3647789] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3647789] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3647946] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3647946] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3648092] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3648092] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3648235] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3648235] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3648505] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3648505] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3648670] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3648670] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3648819] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3648819] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3648980] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3648980] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3649248] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3649248] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3649391] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3649391] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3649538] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3649538] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3649683] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3649683] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3649838] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3649838] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3650106] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3650106] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3650274] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3650274] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3650420] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3650420] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3650587] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3650587] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3650861] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3650861] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3651005] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3651005] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3651160] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3651160] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3651303] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3651303] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3651451] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3651451] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3651719] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3651719] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3651884] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3651884] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3652047] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3652047] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3652198] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3652198] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3652540] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3652540] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3652686] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3652686] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3652829] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3652829] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3652986] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3652986] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3653131] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3653131] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3653404] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3653404] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3653594] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3653594] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3653743] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3653743] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3653915] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3653915] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3654201] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3654201] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3654349] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3654349] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3654504] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3654504] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3654653] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3654653] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3654815] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3654815] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3655091] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3655091] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3655304] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3655304] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3655454] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3655454] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3655668] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3655668] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3655942] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3655942] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3656103] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3656103] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3656269] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3656269] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3656420] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3656420] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3656591] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3656591] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3656881] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3656881] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3657107] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3657107] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3657272] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3657272] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3657487] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3657487] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3657781] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3657781] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3657948] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3657948] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3658115] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3658115] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3658282] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3658282] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3658462] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3658462] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3658771] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3658771] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3659067] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3659067] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3659259] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3659259] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3659540] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3659540] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3659849] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3659849] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3660027] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3660027] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3660214] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3660214] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3660407] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3660407] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3660633] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3660633] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3660991] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3660991] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3661444] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3661444] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3661666] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3661666] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3662102] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3662102] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3662447] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3662447] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3662670] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3662670] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
The call to cuMemcpyAsync failed. This is a unrecoverable error and will
cause the program to abort.
  cuMemcpyAsync(0x14a9e1fe0be0, 0x14ae225260a4, 131040) returned value 1
Check the cuda.h file for what the return value means.
--------------------------------------------------------------------------
[uc2n483.localdomain:392170] CUDA: Error in cuMemcpy: res=-1, dest=0x14a9e1fe0be0, src=0x14ae225260a4, size=131040
[uc2n483:392170] *** Process received signal ***
[uc2n483:392170] Signal: Aborted (6)
[uc2n483:392170] Signal code:  (-6)
[uc2n483:392170] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x14ae50a01dd0]
[uc2n483:392170] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x14ae5066470f]
[uc2n483:392170] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x14ae5064eb25]
[uc2n483:392170] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x14ae4f5ce375]
[uc2n483:392170] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_unpack+0xb9)[0x14ae4f5c5399]
[uc2n483:392170] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_recv_request_progress_frag+0x124)[0x14ae5c57db04]
[uc2n483:392170] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xd8e21)[0x14ae4f62ae21]
[uc2n483:392170] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda75c)[0x14ae4f62c75c]
[uc2n483:392170] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x14ae4f62d1a6]
[uc2n483:392170] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x14ae4f5b4a1b]
[uc2n483:392170] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x14ae4f5baef5]
[uc2n483:392170] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x14ae5c3f78ea]
[uc2n483:392170] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x1db)[0x14ae5c45c77b]
[uc2n483:392170] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x14ae5c468702]
[uc2n483:392170] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x14ae5c40a42b]
[uc2n483:392170] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE28All2All_Sync_SecondTransposeEPvb+0x261)[0x14ae66b4db21]
[uc2n483:392170] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execR2CEPvPKvi+0x486)[0x14ae66b4a0c6]
[uc2n483:392170] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase0Eii+0x686)[0x14ae66dabd76]
[uc2n483:392170] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x2f)[0x14ae66dab677]
[uc2n483:392170] [19] pencil[0x40326b]
[uc2n483:392170] [20] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x14ae506506a3]
[uc2n483:392170] [21] pencil[0x4035fe]
[uc2n483:392170] *** End of error message ***
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[uc2n481.localdomain:3662685] CUDA: Error in cuMemcpy: res=-1, dest=0x14b371fe0be0, src=0x14b7b45b37e4, size=131040
[uc2n481:3662685] *** Process received signal ***
[uc2n481:3662685] Signal: Aborted (6)
[uc2n481:3662685] Signal code:  (-6)
[uc2n481:3662685] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x14b7e3069dd0]
[uc2n481:3662685] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x14b7e2ccc70f]
[uc2n481:3662685] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x14b7e2cb6b25]
[uc2n481:3662685] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x14b7e1c36375]
[uc2n481:3662685] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_unpack+0xb9)[0x14b7e1c2d399]
[uc2n481:3662685] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_recv_request_progress_frag+0x124)[0x14b7eebe5b04]
[uc2n481:3662685] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xd8e21)[0x14b7e1c92e21]
[uc2n481:3662685] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda75c)[0x14b7e1c9475c]
[uc2n481:3662685] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x14b7e1c951a6]
[uc2n481:3662685] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x14b7e1c1ca1b]
[uc2n481:3662685] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x14b7e1c22ef5]
[uc2n481:3662685] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x14b7eea5f8ea]
[uc2n481:3662685] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x1db)[0x14b7eeac477b]
[uc2n481:3662685] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x14b7eead0702]
[uc2n481:3662685] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x14b7eea7242b]
[uc2n481:3662685] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE28All2All_Sync_SecondTransposeEPvb+0x261)[0x14b7f91b5b21]
[uc2n481:3662685] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execR2CEPvPKvi+0x486)[0x14b7f91b20c6]
[uc2n481:3662685] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase0Eii+0x686)[0x14b7f9413d76]
[uc2n481:3662685] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x2f)[0x14b7f9413677]
[uc2n481:3662685] [19] pencil[0x40326b]
[uc2n481:3662685] [20] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x14b7e2cb86a3]
[uc2n481:3662685] [21] pencil[0x4035fe]
[uc2n481:3662685] *** End of error message ***
[uc2n482.localdomain:490238] CUDA: Error in cuMemcpy: res=-1, dest=0x1464ddfe0be0, src=0x14690a5da364, size=131040
[uc2n482:490238] *** Process received signal ***
[uc2n482:490238] Signal: Aborted (6)
[uc2n482:490238] Signal code:  (-6)
[uc2n482:490238] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x14694dab1dd0]
[uc2n482:490238] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x14694d71470f]
[uc2n482:490238] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x14694d6feb25]
[uc2n482:490238] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x14694c67e375]
[uc2n482:490238] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_unpack+0xb9)[0x14694c675399]
[uc2n482:490238] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_recv_request_progress_frag+0x124)[0x14695962db04]
[uc2n482:490238] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xd8e21)[0x14694c6dae21]
[uc2n482:490238] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda75c)[0x14694c6dc75c]
[uc2n482:490238] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x14694c6dd1a6]
[uc2n482:490238] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x14694c664a1b]
[uc2n482:490238] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x14694c66aef5]
[uc2n482:490238] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x1469594a78ea]
[uc2n482:490238] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x1db)[0x14695950c77b]
[uc2n482:490238] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x146959518702]
[uc2n482:490238] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x1469594ba42b]
[uc2n482:490238] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE28All2All_Sync_SecondTransposeEPvb+0x261)[0x146963bfdb21]
[uc2n482:490238] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execR2CEPvPKvi+0x486)[0x146963bfa0c6]
[uc2n482:490238] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase0Eii+0x686)[0x146963e5bd76]
[uc2n482:490238] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x2f)[0x146963e5b677]
[uc2n482:490238] [19] pencil[0x40326b]
[uc2n482:490238] [20] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x14694d7006a3]
[uc2n482:490238] [21] pencil[0x4035fe]
[uc2n482:490238] *** End of error message ***
--------------------------------------------------------------------------
mpiexec noticed that process rank 8 with PID 392170 on node uc2n483 exited on signal 6 (Aborted).
--------------------------------------------------------------------------
[uc2n481.localdomain:3662670] 2 more processes have sent help message help-mpi-common-cuda.txt / cuMemcpyAsync failed
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3662839] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3662839] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
The call to cuMemcpyAsync failed. This is a unrecoverable error and will
cause the program to abort.
  cuMemcpyAsync(0x153283fe0be0, 0x1536c20f73a4, 131040) returned value 1
Check the cuda.h file for what the return value means.
--------------------------------------------------------------------------
[uc2n483.localdomain:392347] CUDA: Error in cuMemcpy: res=-1, dest=0x153283fe0be0, src=0x1536c20f73a4, size=131040
[uc2n483:392347] *** Process received signal ***
[uc2n483:392347] Signal: Aborted (6)
[uc2n483:392347] Signal code:  (-6)
[uc2n481.localdomain:3662855] CUDA: Error in cuMemcpy: res=-1, dest=0x147e43fe0be0, src=0x1482837586e4, size=131040
[uc2n481:3662855] *** Process received signal ***
[uc2n481:3662855] Signal: Aborted (6)
[uc2n481:3662855] Signal code:  (-6)
[uc2n481:3662855] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x1482b7bb1dd0]
[uc2n481:3662855] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x1482b781470f]
[uc2n481:3662855] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x1482b77feb25]
[uc2n481:3662855] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x1482b677e375]
[uc2n481:3662855] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_unpack+0xb9)[0x1482b6775399]
[uc2n481:3662855] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_recv_request_progress_frag+0x124)[0x1482c372db04]
[uc2n481:3662855] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xd8e21)[0x1482b67dae21]
[uc2n481:3662855] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda75c)[0x1482b67dc75c]
[uc2n481:3662855] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x1482b67dd1a6]
[uc2n481:3662855] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x1482b6764a1b]
[uc2n481:3662855] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x1482b676aef5]
[uc2n481:3662855] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x1482c35a78ea]
[uc2n481:3662855] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_coll_basic_alltoallw_intra+0x252)[0x1482c364bb32]
[uc2n481:3662855] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallw+0x1eb)[0x1482c35baccb]
[uc2n481:3662855] [14] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE31All2All_MPIType_SecondTransposeEPvb+0x15d)[0x1482cdcfe20d]
[uc2n481:3662855] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execR2CEPvPKvi+0x486)[0x1482cdcfa0c6]
[uc2n481:3662855] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase0Eii+0x686)[0x1482cdf5bd76]
[uc2n481:3662855] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x2f)[0x1482cdf5b677]
[uc2n481:3662855] [18] pencil[0x40326b]
[uc2n481:3662855] [19] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x1482b78006a3]
[uc2n481:3662855] [20] pencil[0x4035fe]
[uc2n481:3662855] *** End of error message ***
[uc2n483:392347] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x1536f51b6dd0]
[uc2n483:392347] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x1536f4e1970f]
[uc2n483:392347] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x1536f4e03b25]
[uc2n483:392347] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x1536f3d83375]
[uc2n483:392347] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_unpack+0xb9)[0x1536f3d7a399]
[uc2n483:392347] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_recv_request_progress_frag+0x124)[0x153700d32b04]
[uc2n483:392347] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xd8e21)[0x1536f3ddfe21]
[uc2n483:392347] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda75c)[0x1536f3de175c]
[uc2n483:392347] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x1536f3de21a6]
[uc2n483:392347] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x1536f3d69a1b]
[uc2n483:392347] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x1536f3d6fef5]
[uc2n483:392347] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x153700bac8ea]
[uc2n483:392347] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_coll_basic_alltoallw_intra+0x252)[0x153700c50b32]
[uc2n483:392347] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallw+0x1eb)[0x153700bbfccb]
[uc2n483:392347] [14] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE31All2All_MPIType_SecondTransposeEPvb+0x15d)[0x15370b30320d]
[uc2n483:392347] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execR2CEPvPKvi+0x486)[0x15370b2ff0c6]
[uc2n483:392347] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase0Eii+0x686)[0x15370b560d76]
[uc2n483:392347] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x2f)[0x15370b560677]
[uc2n483:392347] [18] pencil[0x40326b]
[uc2n483:392347] [19] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x1536f4e056a3]
[uc2n483:392347] [20] pencil[0x4035fe]
[uc2n483:392347] *** End of error message ***
[uc2n482.localdomain:490419] CUDA: Error in cuMemcpy: res=-1, dest=0x1503edfe0be0, src=0x15081c57c1a4, size=131040
[uc2n482:490419] *** Process received signal ***
[uc2n482:490419] Signal: Aborted (6)
[uc2n482:490419] Signal code:  (-6)
[uc2n482:490419] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x15085c72ddd0]
[uc2n482:490419] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x15085c39070f]
[uc2n482:490419] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x15085c37ab25]
[uc2n482:490419] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x15085b2fa375]
[uc2n482:490419] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_unpack+0xb9)[0x15085b2f1399]
[uc2n482:490419] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_recv_request_progress_frag+0x124)[0x1508682a9b04]
[uc2n482:490419] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xd8e21)[0x15085b356e21]
[uc2n482:490419] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda75c)[0x15085b35875c]
[uc2n482:490419] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x15085b3591a6]
[uc2n482:490419] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x15085b2e0a1b]
[uc2n482:490419] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x15085b2e6ef5]
[uc2n482:490419] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x1508681238ea]
[uc2n482:490419] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_coll_basic_alltoallw_intra+0x252)[0x1508681c7b32]
[uc2n482:490419] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallw+0x1eb)[0x150868136ccb]
[uc2n482:490419] [14] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE31All2All_MPIType_SecondTransposeEPvb+0x15d)[0x15087287a20d]
[uc2n482:490419] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execR2CEPvPKvi+0x486)[0x1508728760c6]
[uc2n482:490419] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase0Eii+0x686)[0x150872ad7d76]
[uc2n482:490419] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x2f)[0x150872ad7677]
[uc2n482:490419] [18] pencil[0x40326b]
[uc2n482:490419] [19] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x15085c37c6a3]
[uc2n482:490419] [20] pencil[0x4035fe]
[uc2n482:490419] *** End of error message ***
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 0 with PID 0 on node uc2n481 exited on signal 6 (Aborted).
--------------------------------------------------------------------------
[uc2n481.localdomain:3662839] 2 more processes have sent help message help-mpi-common-cuda.txt / cuMemcpyAsync failed
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3663000] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3663000] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3663163] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3663163] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3663321] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3663321] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3663470] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3663470] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3663612] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3663612] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3663759] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3663759] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3663923] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3663923] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3664066] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3664066] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3664212] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3664212] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3664356] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3664356] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3664501] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3664501] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3664665] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3664665] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3664809] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3664809] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3664958] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3664958] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3665105] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3665105] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3665271] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3665271] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3665417] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3665417] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3665559] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3665559] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3665706] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3665706] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3665851] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3665851] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3666019] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3666019] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3666166] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3666166] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3666315] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3666315] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3666460] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3666460] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3666622] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3666622] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3666769] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3666769] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3666916] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3666916] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3667060] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3667060] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3667267] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3667267] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3667442] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3667442] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3667593] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3667593] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3667755] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3667755] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3667909] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3667909] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3668083] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3668083] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3668243] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3668243] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3668393] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3668393] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3668553] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3668553] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 15 with PID 4123245 on
node uc2n484 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3668700] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3668700] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 14 with PID 4123410 on
node uc2n484 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3668864] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3668864] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3669092] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3669092] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 2 with PID 0 on
node uc2n481 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3669251] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3669251] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3669480] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3669480] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 15 with PID 4124201 on
node uc2n484 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3669641] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3669641] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 15 with PID 4124355 on
node uc2n484 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3669793] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3669793] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 6 with PID 497715 on
node uc2n482 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3669958] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3669958] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 14 with PID 4124671 on
node uc2n484 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128
2021-09-29 03:02:31.110421
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128
2021-09-29 03:02:37.420926
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128
2021-09-29 03:02:42.903776
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128
2021-09-29 03:02:49.308976
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128
2021-09-29 03:02:54.773330
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128
2021-09-29 03:03:01.405555
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128
2021-09-29 03:03:08.129370
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128
2021-09-29 03:03:14.431171
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128
2021-09-29 03:03:20.731592
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 256
2021-09-29 03:03:26.908822
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 256
2021-09-29 03:03:33.273876
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 256
2021-09-29 03:03:39.528344
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 256
2021-09-29 03:03:46.674322
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 256
2021-09-29 03:03:53.248723
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 256
2021-09-29 03:03:59.842498
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 256
2021-09-29 03:04:05.368810
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 256
2021-09-29 03:04:10.848441
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 256
2021-09-29 03:04:16.763207
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 256 -nz 256
2021-09-29 03:04:23.079367
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 256 -nz 256
2021-09-29 03:04:31.591173
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 256 -nz 256
2021-09-29 03:04:37.161109
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 256 -nz 256
2021-09-29 03:04:44.662461
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 256 -nz 256
2021-09-29 03:04:50.256488
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 256 -nz 256
2021-09-29 03:04:57.773501
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 256 -nz 256
2021-09-29 03:05:03.732593
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 256 -nz 256
2021-09-29 03:05:10.765597
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 256 -nz 256
2021-09-29 03:05:17.062246
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256
2021-09-29 03:05:23.173974
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256
2021-09-29 03:05:29.236721
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256
2021-09-29 03:05:35.328629
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256
2021-09-29 03:05:45.158730
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256
2021-09-29 03:05:50.946620
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256
2021-09-29 03:06:00.720675
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256
2021-09-29 03:06:06.388879
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256
2021-09-29 03:06:12.054446
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256
2021-09-29 03:06:17.741357
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 512
2021-09-29 03:06:23.590052
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 512
2021-09-29 03:06:30.330306
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 512
2021-09-29 03:06:38.860953
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 512
2021-09-29 03:06:48.536243
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 512
2021-09-29 03:06:54.421724
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 512
2021-09-29 03:07:04.173522
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 512
2021-09-29 03:07:12.521291
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 512
2021-09-29 03:07:22.936806
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 512
2021-09-29 03:07:28.921317
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 512 -nz 512
2021-09-29 03:07:34.920732
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 512 -nz 512
2021-09-29 03:07:41.130911
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 512 -nz 512
2021-09-29 03:07:47.288792
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 512 -nz 512
2021-09-29 03:08:08.222321
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 512 -nz 512
2021-09-29 03:08:14.447827
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 512 -nz 512
2021-09-29 03:08:28.078755
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 512 -nz 512
2021-09-29 03:08:34.756957
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 512 -nz 512
2021-09-29 03:08:41.018593
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 512 -nz 512
2021-09-29 03:08:47.210268
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512
2021-09-29 03:08:53.625961
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512
2021-09-29 03:09:00.546264
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512
2021-09-29 03:09:11.135233
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512
2021-09-29 03:09:37.595811
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512
2021-09-29 03:09:46.103610
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512
2021-09-29 03:10:09.946805
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512
2021-09-29 03:10:17.316593
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512
2021-09-29 03:10:24.214236
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512
2021-09-29 03:10:32.687940
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 1024
2021-09-29 03:10:40.048024
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 1024
2021-09-29 03:10:48.419109
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 1024
2021-09-29 03:10:56.565540
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 1024
2021-09-29 03:11:20.772963
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 1024
2021-09-29 03:11:29.582167
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 1024
2021-09-29 03:11:53.495685
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 1024
2021-09-29 03:12:04.545353
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 1024
2021-09-29 03:12:12.836578
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 1024
2021-09-29 03:12:21.210142
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 03:12:30.350934
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 03:12:41.159306
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 03:12:52.816103
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 03:13:34.815418
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 03:13:45.675283
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 03:14:26.717066
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 03:14:37.555172
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 03:14:49.295364
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 03:15:00.234592
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 03:15:12.638333
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 03:15:30.098414
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 03:15:48.044274
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 03:17:06.427830
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 03:17:22.960549
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 03:18:38.213864
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 03:18:54.831240
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 03:19:11.561683
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 03:19:29.057748
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 03:19:48.962097
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 03:20:14.856747
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 03:20:42.628403
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 03:22:16.441592
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 03:22:43.287286
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 03:24:10.258862
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 03:24:36.518560
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 03:25:02.674244
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 03:25:30.110321
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 03:26:02.841346
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 03:26:51.754715
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 03:27:38.812520
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 03:30:41.978660
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 03:31:30.631017
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 03:34:20.953921
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 03:35:07.893888
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 03:35:53.994942
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 03:36:41.504860
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 03:37:43.345689
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 03:39:17.054269
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 03:40:59.717757
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 03:47:02.076633
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 03:48:32.349691
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 03:54:15.060499
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 03:55:51.198204
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 03:57:28.282772
b'2 total processes killed (some possibly by mpiexec during cleanup)\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 03:57:39.925143
b'2 total processes killed (some possibly by mpiexec during cleanup)\n'

Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 03:57:54.306079
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 03:58:03.186199
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 03:58:09.464370
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 03:58:16.403931
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 03:58:22.164706
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 03:58:27.985471
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 03:58:33.640906
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 03:58:39.340320
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 03:58:44.997834
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 03:58:50.683244
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 03:58:56.566458
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 03:59:02.375530
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 03:59:09.094287
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 03:59:17.080160
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 03:59:25.630535
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 03:59:31.419187
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 03:59:37.145673
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 03:59:42.997842
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 03:59:48.894291
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 03:59:55.870505
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 04:00:02.887957
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 04:00:10.875238
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 04:00:18.219771
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 04:00:26.157442
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 04:00:33.171376
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 04:00:40.420230
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 04:00:49.002270
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 04:00:56.033489
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 04:01:13.854857
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 04:01:30.659726
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 04:01:51.585099
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 04:02:08.840495
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 04:02:29.638757
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 04:02:46.641073
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 04:03:03.515349
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 04:03:20.335934
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 04:03:37.374778
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 04:03:49.296555
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 04:04:03.102235
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 04:05:58.067964
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 04:06:09.960625
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 04:07:59.575244
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 04:08:11.278339
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 04:08:29.938873
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 04:08:44.258471
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

Pencil Opt1
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3670106] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3670106] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3670264] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3670264] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3670406] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3670406] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3670558] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3670558] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3670703] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3670703] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3670846] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3670846] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3671003] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3671003] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3671147] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3671147] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3671294] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3671294] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3671437] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3671437] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3671581] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3671581] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3671743] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3671743] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3671887] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3671887] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3672036] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3672036] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3672180] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3672180] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3672335] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3672335] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3672482] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3672482] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3672626] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3672626] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3672770] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3672770] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3672917] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3672917] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3673071] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3673071] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3673217] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3673217] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3673363] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3673363] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3673511] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3673511] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3673654] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3673654] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3673814] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3673814] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3673956] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3673956] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3674104] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3674104] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3674250] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3674250] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3674403] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3674403] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3674550] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3674550] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3674695] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3674695] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3674845] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3674845] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3675001] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3675001] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3675144] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3675144] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3675291] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3675291] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3675436] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3675436] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3675594] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3675594] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3675739] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3675739] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3675887] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3675887] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3676028] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3676028] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3676185] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3676185] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3676330] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3676330] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3676475] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3676475] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3676619] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3676619] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3676778] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3676778] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3676920] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3676920] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3677071] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3677071] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3677232] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3677232] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3677378] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3677378] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3677526] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3677526] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3677670] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3677670] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3677828] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3677828] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3677972] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3677972] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3678121] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3678121] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3678278] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3678278] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3678422] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3678422] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3678570] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3678570] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3678735] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3678735] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3678887] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3678887] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3679046] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3679046] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3679191] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3679191] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3679339] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3679339] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3679500] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3679500] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3679645] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3679645] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3679792] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3679792] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3679963] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3679963] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3680124] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3680124] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3680291] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3680291] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3680440] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3680440] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3680604] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3680604] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3680746] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3680746] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3680910] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3680910] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3681057] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3681057] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3681202] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3681202] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3681390] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3681390] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3681540] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3681540] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3681722] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3681722] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3681868] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3681868] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3682035] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3682035] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3682183] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3682183] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3682361] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3682361] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3682516] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3682516] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3682681] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3682681] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3682878] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3682878] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3683046] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3683046] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3683260] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3683260] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3683422] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3683422] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3683593] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3683593] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3683744] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3683744] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3683937] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3683937] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3684111] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3684111] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3684296] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3684296] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3684548] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3684548] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3684720] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3684720] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3685005] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3685005] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3685182] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3685182] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3685375] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3685375] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3685547] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3685547] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3685762] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3685762] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3685967] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3685967] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3686178] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3686178] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3686458] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3686458] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3686669] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3686669] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3686974] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3686974] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3687187] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3687187] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3687416] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3687416] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3687629] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3687629] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481:3687919] *** An error occurred in MPI_Irecv
[uc2n481:3687919] *** reported by process [4123131905,0]
[uc2n481:3687919] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n481:3687919] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3687919] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3687919] ***    and potentially your MPI job)
[uc2n481.localdomain:3687905] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3687905] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3687905] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n483:418115] *** An error occurred in MPI_Irecv
[uc2n483:418115] *** reported by process [4132438017,11]
[uc2n483:418115] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n483:418115] *** MPI_ERR_COUNT: invalid count argument
[uc2n483:418115] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n483:418115] ***    and potentially your MPI job)
[uc2n481.localdomain:3688051] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3688051] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3688051] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3688209] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3688209] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n483:418262] *** An error occurred in MPI_Irecv
[uc2n483:418262] *** reported by process [4147249153,8]
[uc2n483:418262] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n483:418262] *** MPI_ERR_COUNT: invalid count argument
[uc2n483:418262] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n483:418262] ***    and potentially your MPI job)
[uc2n481.localdomain:3688209] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n484:4143456:0:4143456] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c46e400010)
[uc2n482:517160:0:517160] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14899a400010)
[uc2n484:4143454:0:4143454] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1527d2400010)
[uc2n482:517162:0:517162] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14b99a400010)
[uc2n482:517159:0:517159] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c85a400010)
[uc2n482:517161:0:517161] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14d32a400010)
[uc2n484:4143455:0:4143455] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x151188400010)
[uc2n484:4143453:0:4143453] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14eb90400010)
[uc2n481:3688379:0:3688379] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x146bfa400000)
[uc2n481:3688380:0:3688380] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x15209a400000)
[uc2n481:3688378:0:3688378] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x149048400000)
[uc2n481:3688377:0:3688377] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14bea4400000)
[uc2n483:418429:0:418429] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14cdd8400000)
[uc2n483:418430:0:418430] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14f11a400000)
[uc2n483:418431:0:418431] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x147558400000)
[uc2n483:418428:0:418428] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c8f0400000)
==== backtrace (tid:3688378) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3688377) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3688380) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3688379) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 418429) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 418428) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 517161) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
==== backtrace (tid: 517160) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 517162) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 517159) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:4143453) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:4143454) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
==== backtrace (tid: 418431) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 418430) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:4143455) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:4143456) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 12 with PID 4143453 on node uc2n484 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
[uc2n481.localdomain:3688363] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3688363] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n484:4143655:0:4143655] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14714e400000)
[uc2n484:4143656:0:4143656] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x151288400000)
[uc2n484:4143654:0:4143654] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14d1e8400000)
[uc2n484:4143653:0:4143653] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x145f18400000)
[uc2n482:517347:0:517347] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x15462a400000)
[uc2n482:517349:0:517349] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x148008400000)
[uc2n482:517348:0:517348] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x149cba400000)
[uc2n482:517346:0:517346] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x149618400000)
==== backtrace (tid: 517348) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 517349) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 517347) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 517346) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:4143656) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:4143655) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:4143653) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:4143654) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[uc2n481:3688560:0:3688560] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14b742400000)
==== backtrace (tid:3688560) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
10 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
13 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
[uc2n481:3688561:0:3688561] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14f210400000)
==== backtrace (tid:3688561) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
10 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
13 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
[uc2n481:3688562:0:3688562] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14797e400000)
==== backtrace (tid:3688562) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
10 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
13 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
[uc2n481:3688563:0:3688563] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e68e400000)
==== backtrace (tid:3688563) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
10 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
13 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
[uc2n483:418616:0:418616] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1504da400000)
[uc2n483:418615:0:418615] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e4da400000)
[uc2n483:418617:0:418617] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14de00400000)
[uc2n483:418614:0:418614] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x146bf0400000)
==== backtrace (tid: 418616) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
10 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
13 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 418615) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
10 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
13 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 418617) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
10 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
13 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 418614) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
10 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
13 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
[uc2n481.localdomain:3688544] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3688544] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec noticed that process rank 13 with PID 4143654 on node uc2n484 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n482:517536] *** An error occurred in MPI_Irecv
[uc2n482:517536] *** reported by process [4177854465,6]
[uc2n482:517536] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n482:517536] *** MPI_ERR_COUNT: invalid count argument
[uc2n482:517536] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n482:517536] ***    and potentially your MPI job)
[uc2n481.localdomain:3688742] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3688742] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3688742] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n484:4143993] *** An error occurred in MPI_Isend
[uc2n484:4143993] *** reported by process [4187226113,15]
[uc2n484:4143993] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n484:4143993] *** MPI_ERR_COUNT: invalid count argument
[uc2n484:4143993] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n484:4143993] ***    and potentially your MPI job)
[uc2n481.localdomain:3688887] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3688887] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3688887] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n483:419107] *** An error occurred in MPI_Alltoallv
[uc2n483:419107] *** reported by process [4201185281,8]
[uc2n483:419107] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n483:419107] *** MPI_ERR_COUNT: invalid count argument
[uc2n483:419107] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n483:419107] ***    and potentially your MPI job)
[uc2n481.localdomain:3689034] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3689034] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3689034] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n484:4144304] *** An error occurred in MPI_Alltoallw
[uc2n484:4144304] *** reported by process [4207607809,15]
[uc2n484:4144304] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n484:4144304] *** MPI_ERR_COUNT: invalid count argument
[uc2n484:4144304] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n484:4144304] ***    and potentially your MPI job)
[uc2n481.localdomain:3689192] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3689192] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3689192] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3689339] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3689339] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3689486] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3689486] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3689639] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3689639] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3689797] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3689797] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3689940] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3689940] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3690086] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3690086] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3690239] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3690239] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3690381] [[65454,0],0] ORTE_ERROR_LOG: Data unpack had inadequate space in file util/show_help.c at line 507
[uc2n481.localdomain:3690381] 14 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3690381] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3690548] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3690548] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3690692] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3690692] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3690838] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3690838] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3690991] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3690991] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3691146] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3691146] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3691292] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3691292] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3691437] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3691437] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3691592] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3691592] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3691737] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3691737] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3691894] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3691894] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3692036] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3692036] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3692180] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3692180] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3692337] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3692337] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3692480] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3692480] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3692639] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3692639] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3692785] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3692785] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3692940] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3692940] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3693080] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3693080] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3693241] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3693241] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3693385] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3693385] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3693547] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3693547] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3693704] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3693704] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3693912] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3693912] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3694065] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3694065] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3694228] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3694228] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3694400] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3694400] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3694553] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3694553] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3694720] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3694720] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3694881] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3694881] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n482:523981] *** An error occurred in MPI_Irecv
[uc2n482:523981] *** reported by process [3506569217,7]
[uc2n482:523981] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n482:523981] *** MPI_ERR_COUNT: invalid count argument
[uc2n482:523981] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n482:523981] ***    and potentially your MPI job)
[uc2n481.localdomain:3694881] 8 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3695098] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3695098] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n482:524203] *** An error occurred in MPI_Irecv
[uc2n482:524203] *** reported by process [3520659457,4]
[uc2n482:524203] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n482:524203] *** MPI_ERR_COUNT: invalid count argument
[uc2n482:524203] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n482:524203] ***    and potentially your MPI job)
[uc2n481.localdomain:3695098] 7 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3695317] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3695317] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481:3695337] *** An error occurred in MPI_Irecv
[uc2n481:3695337] *** reported by process [3539337217,3]
[uc2n481:3695337] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n481:3695337] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3695337] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3695337] ***    and potentially your MPI job)
[uc2n481.localdomain:3695317] 7 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3695540] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3695540] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n482:524663:0:524663] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x145c68400010)
==== backtrace (tid: 524663) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
20 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
[uc2n481:3695564:0:3695564] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e01a400000)
==== backtrace (tid:3695564) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
14 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[uc2n482:524660:0:524660] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14d264400010)
==== backtrace (tid: 524660) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
20 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
[uc2n484:4150790:0:4150790] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1508d2400010)
==== backtrace (tid:4150790) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
20 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
mpiexec noticed that process rank 7 with PID 524663 on node uc2n482 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3695770] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3695770] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n482:524912:0:524912] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x145c78400000)
==== backtrace (tid: 524912) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
11 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[uc2n481:3695791:0:3695791] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x146dc6400000)
==== backtrace (tid:3695791) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
10 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
13 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
[uc2n482:524909:0:524909] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1501e4400000)
==== backtrace (tid: 524909) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
11 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
[uc2n484:4151022:0:4151022] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14cebe400000)
==== backtrace (tid:4151022) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
11 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
mpiexec noticed that process rank 7 with PID 524912 on node uc2n482 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3695988] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3695988] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481:3696019] *** An error occurred in MPI_Irecv
[uc2n481:3696019] *** reported by process [3579248641,2]
[uc2n481:3696019] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n481:3696019] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3696019] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3696019] ***    and potentially your MPI job)
[uc2n481.localdomain:3695988] 4 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3696220] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3696220] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n482:525386] *** An error occurred in MPI_Isend
[uc2n482:525386] *** reported by process [3598647297,5]
[uc2n482:525386] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n482:525386] *** MPI_ERR_COUNT: invalid count argument
[uc2n482:525386] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n482:525386] ***    and potentially your MPI job)
[uc2n481.localdomain:3696220] 10 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3696441] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3696441] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481:3696458] *** An error occurred in MPI_Alltoallv
[uc2n481:3696458] *** reported by process [3608805377,0]
[uc2n481:3696458] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n481:3696458] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3696458] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3696458] ***    and potentially your MPI job)
[uc2n481.localdomain:3696441] 2 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3696661] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3696661] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n482:525838] *** An error occurred in MPI_Alltoallw
[uc2n482:525838] *** reported by process [3627417601,4]
[uc2n482:525838] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n482:525838] *** MPI_ERR_COUNT: invalid count argument
[uc2n482:525838] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n482:525838] ***    and potentially your MPI job)
[uc2n481.localdomain:3696661] 4 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 04:08:58.060805
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 04:09:04.439637
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 04:09:09.961825
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 04:09:17.777295
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 04:09:23.487748
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 04:09:30.024362
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 04:09:36.447597
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 04:09:42.097272
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 04:09:47.618970
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 04:09:53.374207
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 04:09:58.888054
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 04:10:04.425285
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 04:10:11.502511
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 04:10:17.056084
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 04:10:24.444717
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 04:10:32.660489
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 04:10:38.775330
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 04:10:44.285425
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 04:10:50.304370
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 04:10:55.873074
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 04:11:01.451512
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 04:11:10.649217
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 04:11:16.202786
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 04:11:23.522674
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 04:11:29.097805
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 04:11:35.455209
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 04:11:41.248729
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 04:11:49.919458
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 04:11:55.568641
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 04:12:01.214198
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 04:12:09.811442
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 04:12:15.459539
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 04:12:29.104744
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 04:12:34.743508
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 04:12:41.198594
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 04:12:47.254745
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 04:12:54.226811
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 04:13:01.558658
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 04:13:07.694724
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 04:13:19.628847
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 04:13:25.753585
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 04:13:38.428559
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 04:13:44.220685
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 04:13:51.659552
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 04:13:57.433107
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 04:14:05.790515
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 04:14:11.829671
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 04:14:17.882935
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 04:14:32.946038
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 04:14:39.570794
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 04:14:53.382981
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 04:14:59.438883
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 04:15:08.862267
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 04:15:14.956891
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 04:15:26.933092
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 04:15:33.611230
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 04:15:40.871675
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 04:15:59.868575
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 04:16:06.537250
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 04:16:27.330859
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 04:16:35.486478
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 04:16:45.813691
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 04:16:52.538266
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 04:17:05.502398
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 04:17:13.622120
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 04:17:21.962456
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 04:17:55.361512
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 04:18:03.430446
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 04:18:40.801101
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 04:18:48.799508
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 04:19:04.476337
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 04:19:12.542121
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 04:19:32.691945
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 04:19:46.177091
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 04:19:59.819694
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 04:20:38.221417
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 04:20:51.778748
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 04:21:35.923625
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 04:21:49.466416
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 04:22:14.710230
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 04:22:28.463498
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 04:23:02.744485
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 04:23:25.199135
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 04:23:46.783688
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 04:24:57.919707
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 04:25:19.762070
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 04:26:39.540294
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 04:27:02.163496
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 04:27:34.494317
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 04:28:01.383821
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 04:28:44.831167
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 04:29:26.535908
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 04:30:05.075366
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 04:32:21.656793
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 04:33:01.075386
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 04:35:33.085954
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 04:36:11.975503
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 04:37:08.876677
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 04:37:49.252846
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 04:39:08.927378
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 04:40:25.937257
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 04:41:38.713466
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 04:44:30.598673
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 04:45:43.745335
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 04:48:53.598277
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 04:50:07.205168
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 04:51:55.372397
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 04:53:11.068792
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 04:55:44.140888
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 04:55:54.321001
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 04:56:04.081983
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 04:56:20.130295
b'3 total processes killed (some possibly by mpiexec during cleanup)\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 04:56:26.093007
b'3 total processes killed (some possibly by mpiexec during cleanup)\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 04:56:34.836290
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 04:56:44.603992
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 04:56:54.398472
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 04:57:05.860847
b''

Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 04:57:15.651542
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 04:57:23.159379
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 04:57:28.863762
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 04:57:37.536191
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 04:57:43.420467
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 04:57:49.386553
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 04:57:55.289535
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 04:58:01.143331
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 04:58:07.004255
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 04:58:14.663182
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 04:58:20.518758
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 04:58:27.340416
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 04:58:33.430369
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 04:58:39.275191
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 04:58:47.893307
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 04:58:53.781121
b'Result (avg): 8.36382e-09\nResult (max): 2.65886e-07\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 04:58:59.677620
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 04:59:05.562018
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 04:59:11.512401
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 04:59:18.613789
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 04:59:25.551182
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 04:59:33.247416
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 04:59:40.198356
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 04:59:47.971057
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 04:59:54.910216
b'Result (avg): 3521.4\nResult (max): 17377.9\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 05:00:02.100228
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 05:00:09.022428
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 05:00:16.269785
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 05:00:34.376176
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 05:00:52.033285
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 05:01:13.265107
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 05:01:31.142754
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 05:01:51.468317
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 05:02:09.909634
b'Result (avg): 9960.22\nResult (max): 49152\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 05:02:31.419950
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 05:02:48.605034
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 05:03:07.731498
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 05:04:34.147653
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 05:06:07.565408
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 05:07:45.444360
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 05:09:08.888918
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 05:10:33.365341
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 05:12:05.098767
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 05:13:37.458802
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 05:15:08.698683
b''

--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3696883] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3696883] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3697032] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3697032] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3697176] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3697176] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3697331] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3697331] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3697476] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3697476] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3697625] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3697625] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3697771] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3697771] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3697928] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3697928] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3698073] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3698073] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3698218] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3698218] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3698363] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3698363] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3698506] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3698506] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3698666] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3698666] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3698811] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3698811] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3698957] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3698957] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3699101] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3699101] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3699242] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3699242] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3699398] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3699398] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3699544] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3699544] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3699687] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3699687] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3699833] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3699833] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3699976] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3699976] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3700136] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3700136] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3700287] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3700287] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3700430] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3700430] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3700587] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3700587] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3700732] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3700732] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3700878] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3700878] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3701022] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3701022] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3701178] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3701178] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3701322] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3701322] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3701467] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3701467] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3701615] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3701615] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3701756] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3701756] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3701918] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3701918] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3702063] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3702063] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3702209] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3702209] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3702353] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3702353] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3702508] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3702508] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3702657] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3702657] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3702798] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3702798] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3702947] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3702947] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3703102] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3703102] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3703250] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3703250] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3703397] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3703397] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3703542] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3703542] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3703704] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3703704] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3703850] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3703850] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3704001] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3704001] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3704142] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3704142] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3704299] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3704299] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3704448] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3704448] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3704605] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3704605] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3704750] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3704750] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3704901] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3704901] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3705043] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3705043] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3705204] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3705204] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3705349] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3705349] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3705496] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3705496] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3705657] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3705657] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3705801] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3705801] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3705951] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3705951] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3706109] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3706109] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3706259] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3706259] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3706402] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3706402] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3706562] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3706562] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3706714] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3706714] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3706871] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3706871] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3707021] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3707021] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3707179] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3707179] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3707331] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3707331] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3707492] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3707492] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3707642] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3707642] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3707802] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3707802] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3707951] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3707951] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3708111] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3708111] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3708259] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3708259] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3708434] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3708434] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3708591] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3708591] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3708758] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3708758] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3708906] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3708906] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3709089] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3709089] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3709242] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3709242] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3709404] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3709404] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3709572] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3709572] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3709737] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3709737] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3709913] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3709913] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3710076] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3710076] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3710250] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3710250] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3710408] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3710408] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3710592] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3710592] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3710754] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3710754] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3710921] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3710921] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3711117] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3711117] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3711282] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3711282] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3711504] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3711504] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3711669] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3711669] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3711888] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3711888] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3712053] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3712053] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3712275] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3712275] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3712467] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3712467] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3712641] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3712641] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3712861] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3712861] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3713050] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3713050] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3713293] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3713293] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3713471] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3713471] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3713757] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3713757] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3713939] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3713939] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3714252] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3714252] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3714461] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3714461] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3714683] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3714683] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n483:445628:0:445628] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1475ba400010)
[uc2n483:445627:0:445627] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x15476a400010)
[uc2n484:4170723:0:4170723] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1488fa400010)
[uc2n484:4170724:0:4170724] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14547e400010)
[uc2n482:545091:0:545091] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x154b64400010)
[uc2n482:545090:0:545090] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14de9a400010)
[uc2n481:3715044:0:3715044] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14d2aa400010)
[uc2n481:3715043:0:3715043] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1520e8400010)
[uc2n483:445626:0:445626] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x146f8e400000)
[uc2n483:445625:0:445625] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x152bd6400000)
[uc2n484:4170722:0:4170722] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x153b18400000)
[uc2n484:4170721:0:4170721] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x151f84400000)
[uc2n482:545089:0:545089] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x149e00400000)
[uc2n482:545088:0:545088] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e19e400000)
[uc2n481:3715042:0:3715042] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1546b4400000)
[uc2n481:3715041:0:3715041] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14b362400000)
==== backtrace (tid: 545088) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 545089) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3715044) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
==== backtrace (tid:4170724) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:4170723) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
==== backtrace (tid:3715043) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 545090) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 545091) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:4170722) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:4170721) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3715042) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3715041) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 445627) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 445628) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 445626) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 445625) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[uc2n481.localdomain:3715026] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3715026] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec noticed that process rank 12 with PID 4170721 on node uc2n484 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n483:445817:0:445817] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c7a4400000)
[uc2n483:445818:0:445818] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14615a400000)
[uc2n481:3715236:0:3715236] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x151602400000)
[uc2n481:3715237:0:3715237] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14dc1a400000)
[uc2n484:4170908:0:4170908] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x147a8a400000)
[uc2n484:4170907:0:4170907] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x145d48400000)
[uc2n482:545292:0:545292] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14abbe400000)
[uc2n482:545291:0:545291] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x147f6e400000)
==== backtrace (tid:3715236) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3715237) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:4170908) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:4170907) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 445817) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 445818) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 545291) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 545292) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[uc2n483:445815:0:445815] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e114400000)
==== backtrace (tid: 445815) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
10 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
13 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
[uc2n483:445816:0:445816] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x148fea400000)
==== backtrace (tid: 445816) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
10 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
13 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
[uc2n481.localdomain:3715219] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3715219] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n482:545289:0:545289] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14fcd4400000)
==== backtrace (tid: 545289) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
10 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
13 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
[uc2n482:545290:0:545290] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x15003a400000)
==== backtrace (tid: 545290) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
10 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
13 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
mpiexec noticed that process rank 7 with PID 545292 on node uc2n482 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3715385] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3715385] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3715604] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3715604] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n483:446573:0:446573] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x149d8a000010)
[uc2n483:446574:0:446574] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14fad6000010)
[uc2n483:446571:0:446571] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x147596800010)
[uc2n483:446572:0:446572] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e25a000010)
[uc2n484:4171635:0:4171635] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e44a000010)
[uc2n484:4171636:0:4171636] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1484ce000010)
[uc2n484:4171634:0:4171634] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c454000010)
[uc2n484:4171633:0:4171633] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14f0f2c00010)
==== backtrace (tid: 446573) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
17 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 446574) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
17 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 446571) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
17 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 446572) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
17 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:4171636) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
17 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:4171635) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
17 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:4171634) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
17 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
[uc2n481.localdomain:3715929] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3715929] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
==== backtrace (tid:4171633) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
17 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
[uc2n482:546045:0:546045] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1461b8000000)
[uc2n482:546046:0:546046] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1469ca000000)
[uc2n482:546043:0:546043] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x146ee6800000)
[uc2n482:546044:0:546044] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1490ca000000)
[uc2n481:3715947:0:3715947] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14ad0e000000)
[uc2n481:3715946:0:3715946] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1520b8000000)
[uc2n481:3715944:0:3715944] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x150a7e800000)
[uc2n481:3715945:0:3715945] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14b888000000)
==== backtrace (tid:3715947) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
11 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3715946) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
11 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3715945) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
11 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3715944) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
11 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 546044) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
11 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 546043) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
11 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 546046) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
11 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 546045) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
11 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 12 with PID 4171633 on node uc2n484 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n483:446756:0:446756] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x148ad0000000)
[uc2n483:446757:0:446757] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14b03a000000)
[uc2n483:446754:0:446754] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e86e800000)
[uc2n483:446755:0:446755] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1468e8000000)
[uc2n484:4171827:0:4171827] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c3aa000000)
[uc2n484:4171828:0:4171828] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x150ec8000000)
[uc2n484:4171826:0:4171826] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14f76a000000)
[uc2n484:4171825:0:4171825] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14700ec00000)
==== backtrace (tid: 446756) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 446757) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:4171827) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:4171828) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 446754) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 446755) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:4171826) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:4171825) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[uc2n481:3716141:0:3716141] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x154c9a800000)
==== backtrace (tid:3716141) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
10 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
13 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
[uc2n481:3716142:0:3716142] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x149040000000)
==== backtrace (tid:3716142) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
10 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
13 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
[uc2n481:3716143:0:3716143] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1462de000000)
==== backtrace (tid:3716143) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
10 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
13 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
[uc2n481:3716144:0:3716144] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x151b1a000000)
==== backtrace (tid:3716144) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
10 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
13 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
[uc2n482:546230:0:546230] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14625a000000)
[uc2n482:546231:0:546231] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x152ace000000)
[uc2n482:546229:0:546229] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x150ab2000000)
[uc2n482:546228:0:546228] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14b572800000)
==== backtrace (tid: 546230) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
10 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
13 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 546231) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
10 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
13 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 546229) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
10 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
13 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 546228) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
10 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000002dd76 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
13 0x000000000002d677 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
[uc2n481.localdomain:3716110] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3716110] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec noticed that process rank 10 with PID 446756 on node uc2n483 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3716308] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3716308] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3716455] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3716455] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3716610] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3716610] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3716755] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3716755] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3716910] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3716910] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3717054] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3717054] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3717210] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3717210] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3717356] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3717356] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3717514] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3717514] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3717659] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3717659] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3717801] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3717801] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3717959] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3717959] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3718102] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3718102] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3718260] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3718260] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3718404] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3718404] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3718558] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3718558] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3718702] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3718702] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3718856] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3718856] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3719000] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3719000] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3719144] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3719144] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3719301] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3719301] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3719446] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3719446] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3719603] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3719603] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3719748] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3719748] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3719902] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3719902] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3720047] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3720047] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3720208] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3720208] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3720352] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3720352] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3720514] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3720514] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3720672] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3720672] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3720831] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3720831] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3720983] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3720983] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3721147] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3721147] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3721305] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3721305] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3721467] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3721467] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3721627] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3721627] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3721779] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3721779] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3722000] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3722000] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3722243] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3722243] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3722468] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3722468] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481:3722486:0:3722486] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x153d8a400010)
==== backtrace (tid:3722486) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
20 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
[uc2n481:3722485:0:3722485] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14a2ae400010)
==== backtrace (tid:3722485) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
20 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[uc2n481:3722484:0:3722484] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14ba1e400000)
==== backtrace (tid:3722484) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
14 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
[uc2n482:552889:0:552889] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c5e8400010)
==== backtrace (tid: 552889) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
20 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
[uc2n482:552888:0:552888] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x150aa4400010)
==== backtrace (tid: 552888) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
20 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
[uc2n482:552887:0:552887] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14f930400000)
==== backtrace (tid: 552887) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
14 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
[uc2n484:4178315:0:4178315] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x15266a400010)
==== backtrace (tid:4178315) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
20 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
mpiexec noticed that process rank 3 with PID 0 on node uc2n481 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3722714] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3722714] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481:3722737:0:3722737] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14bd90400000)
==== backtrace (tid:3722737) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
11 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
[uc2n481:3722736:0:3722736] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x145bee400000)
==== backtrace (tid:3722736) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
11 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[uc2n482:553144:0:553144] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x151120400000)
==== backtrace (tid: 553144) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
11 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
[uc2n482:553145:0:553145] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14888e400000)
==== backtrace (tid: 553145) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
11 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
mpiexec noticed that process rank 3 with PID 0 on node uc2n481 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3722937] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3722937] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3723185] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3723185] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3723408] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3723408] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481:3723423:0:3723423] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x15334e800000)
[uc2n481:3723426:0:3723426] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x150a48000000)
[uc2n481:3723424:0:3723424] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x147748000000)
[uc2n481:3723425:0:3723425] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14957e000000)
==== backtrace (tid:3723426) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
11 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
14 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3723425) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
11 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
14 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3723424) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
11 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
14 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3723423) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
11 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
14 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[uc2n482:553856:0:553856] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1505b4000000)
==== backtrace (tid: 553856) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
11 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
14 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
[uc2n482:553857:0:553857] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x150ae0000000)
==== backtrace (tid: 553857) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
11 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
14 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
[uc2n482:553854:0:553854] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x148a42800000)
==== backtrace (tid: 553854) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
11 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
14 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
[uc2n482:553855:0:553855] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1488ce000000)
==== backtrace (tid: 553855) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
11 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
14 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
mpiexec noticed that process rank 3 with PID 0 on node uc2n481 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3723661] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3723661] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481:3723683:0:3723683] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14aaa0000000)
[uc2n481:3723682:0:3723682] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x15486e800000)
[uc2n481:3723685:0:3723685] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x153c5a000000)
[uc2n481:3723684:0:3723684] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e018000000)
==== backtrace (tid:3723683) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
10 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
13 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3723682) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
10 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
13 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3723685) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
10 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
13 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3723684) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
10 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
13 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[uc2n483:454372:0:454372] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e69e000000)
[uc2n483:454370:0:454370] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14af50000000)
[uc2n483:454369:0:454369] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14b4d2800000)
[uc2n483:454371:0:454371] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1464d8000000)
==== backtrace (tid: 454369) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
11 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 454371) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
11 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 454370) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
11 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 454372) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfef MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x0000000000030a81 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
11 0x000000000002d6e7 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
mpiexec noticed that process rank 2 with PID 0 on node uc2n481 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 05:16:42.702702
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 05:16:58.974300
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 05:17:04.437791
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 05:17:10.244808
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 05:17:15.722402
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 05:17:23.443555
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 05:17:33.608696
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 05:17:40.093800
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 05:17:45.558832
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 05:17:51.532682
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 05:17:57.015708
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 05:18:02.499714
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 05:18:08.645992
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 05:18:14.169410
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 05:18:20.631443
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 05:18:26.115242
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 05:18:32.397081
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 05:18:37.904118
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 05:18:44.896715
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 05:18:50.425307
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 05:18:55.930690
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 05:19:02.081851
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 05:19:07.621413
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 05:19:24.581024
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 05:19:32.228752
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 05:19:40.955185
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 05:19:46.823430
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 05:19:54.450775
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 05:20:00.032478
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 05:20:05.635209
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 05:20:12.526486
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 05:20:18.589413
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 05:20:25.874557
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 05:20:32.567575
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 05:20:39.810873
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 05:20:45.404266
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 05:20:53.141452
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 05:20:58.894144
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 05:21:05.666284
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 05:21:14.111801
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 05:21:20.369362
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 05:21:29.475482
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 05:21:35.245908
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 05:21:45.647791
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 05:21:52.194836
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 05:22:02.173140
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 05:22:08.245523
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 05:22:17.446856
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 05:22:26.935356
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 05:22:33.062815
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 05:22:42.633559
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 05:22:52.248267
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 05:23:05.086542
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 05:23:11.142269
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 05:23:25.657280
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 05:23:32.374438
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 05:23:39.075506
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 05:23:50.847598
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 05:23:57.587024
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 05:24:11.242289
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 05:24:17.998985
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 05:24:31.344402
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 05:24:38.600042
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 05:24:53.803786
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 05:25:01.911842
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 05:25:12.033475
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 05:25:30.203097
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 05:25:38.254221
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 05:26:00.609097
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 05:26:08.836884
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 05:26:30.182770
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 05:26:38.242481
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 05:27:03.154302
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 05:27:14.030639
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 05:27:25.466935
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 05:27:47.104334
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 05:27:58.221740
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 05:28:24.373228
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 05:28:34.966420
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 05:29:13.757984
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 05:29:27.550258
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 05:30:13.262899
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 05:30:28.815190
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 05:30:44.680808
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 05:31:20.707958
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 05:31:36.555261
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 05:32:22.730049
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 05:32:38.257366
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 05:33:23.735370
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 05:33:40.121748
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 05:34:33.771458
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 05:34:59.369171
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 05:35:25.046949
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 05:36:32.589328
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 05:36:58.871383
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 05:38:25.212057
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 05:38:50.462138
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 05:40:14.110093
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 05:40:40.085014
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 05:42:20.158285
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 05:43:08.452958
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 05:43:54.766552
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 05:45:26.980841
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 05:46:13.867463
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 05:48:10.213732
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 05:48:59.240727
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 05:51:36.192455
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 05:52:22.885299
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 05:55:35.928165
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 05:57:04.429829
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 05:58:32.280381
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 06:01:34.792712
b'2 total processes killed (some possibly by mpiexec during cleanup)\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 06:01:40.918000
b'2 total processes killed (some possibly by mpiexec during cleanup)\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 06:01:48.033081
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 06:03:16.268952
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 06:06:57.912990
b'3 total processes killed (some possibly by mpiexec during cleanup)\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 06:07:05.851525
b'3 total processes killed (some possibly by mpiexec during cleanup)\n'

Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 06:07:16.243602
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 06:07:23.827535
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 06:07:29.938911
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 06:07:36.120610
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 06:07:41.797750
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 06:07:47.970694
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 06:07:56.540418
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 06:08:03.422321
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 06:08:09.098201
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 06:08:14.802396
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 06:08:20.590771
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 06:08:29.946113
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 06:08:35.954095
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 06:08:41.786626
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 06:08:47.762300
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 06:08:53.543466
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 06:08:59.424604
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 06:09:06.757680
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 06:09:12.675968
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 06:09:21.373296
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 06:09:28.264579
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 06:09:35.494812
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 06:09:43.005249
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 06:09:50.432472
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 06:09:57.369074
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 06:10:04.599177
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 06:10:12.525646
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 06:10:19.873913
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 06:10:36.957431
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 06:10:53.749654
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 06:11:11.976824
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 06:11:28.907389
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 06:11:47.749156
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 06:12:04.599657
b'Result (avg): 1.21209e-06\nResult (max): 1.80351e-05\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 06:12:22.261077
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 06:12:38.921314
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 06:12:57.110620
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 06:14:32.256183
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 06:16:08.302220
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 06:17:49.526163
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 06:19:09.454846
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 06:20:34.072964
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 06:22:19.083003
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 06:23:58.325605
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 06:25:22.369081
b''

Pencil Default Inverse
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3723922] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3723922] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3724077] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3724077] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3724349] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3724349] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3724498] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3724498] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3724640] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3724640] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3724797] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3724797] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3724944] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3724944] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3725087] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3725087] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3725235] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3725235] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3725377] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3725377] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3725522] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3725522] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3725809] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3725809] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3725953] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3725953] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3726099] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3726099] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3726244] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3726244] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3726399] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3726399] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3726544] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3726544] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3726686] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3726686] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3726833] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3726833] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3726987] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3726987] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3727258] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3727258] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3727405] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3727405] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3727550] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3727550] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3727708] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3727708] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3727857] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3727857] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3728001] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3728001] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3728150] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3728150] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3728293] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3728293] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3728449] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3728449] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3728719] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3728719] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3728869] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3728869] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3729011] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3729011] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3729170] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3729170] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3729313] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3729313] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3729460] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3729460] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3729602] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3729602] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3729747] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3729747] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3729907] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3729907] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3730173] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3730173] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3730321] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3730321] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3730466] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3730466] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3730623] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3730623] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3730772] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3730772] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3730914] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3730914] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3731071] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3731071] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3731217] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3731217] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3731362] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3731362] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3731635] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3731635] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3731798] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3731798] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3731945] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3731945] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3732106] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3732106] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3732247] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3732247] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3732399] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3732399] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3732543] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3732543] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3732696] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3732696] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3732842] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3732842] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3733110] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3733110] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3733285] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3733285] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3733432] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3733432] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3733607] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3733607] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3733754] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3733754] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3733896] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3733896] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3734043] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3734043] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3734196] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3734196] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3734349] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3734349] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3734618] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3734618] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3734793] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3734793] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3734951] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3734951] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3735123] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3735123] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3735272] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3735272] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3735430] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3735430] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3735576] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3735576] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3735724] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3735724] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3735889] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3735889] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3736163] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3736163] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3736371] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3736371] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3736520] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3736520] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3736733] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3736733] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3736883] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3736883] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3737046] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3737046] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3737195] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3737195] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3737358] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3737358] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3737525] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3737525] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3737820] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3737820] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3738070] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3738070] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3738233] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3738233] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3738499] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3738499] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3738657] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3738657] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3738824] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3738824] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3738997] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3738997] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3739165] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3739165] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3739353] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3739353] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3739664] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3739664] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3739937] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3739937] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3740111] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3740111] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3740380] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3740380] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3740553] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3740553] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3740750] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3740750] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3740942] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3740942] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3741135] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3741135] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3741380] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3741380] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3741717] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3741717] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3742118] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3742118] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3742322] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3742322] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3742722] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3742722] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3742939] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3742939] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3743145] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3743145] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3743360] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3743360] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481:3743621] *** An error occurred in MPI_Irecv
[uc2n481:3743621] *** reported by process [2941648897,2]
[uc2n481:3743621] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n481:3743621] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3743621] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3743621] ***    and potentially your MPI job)
[uc2n481.localdomain:3743604] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3743604] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3743604] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481:3743764] *** An error occurred in MPI_Irecv
[uc2n481:3743764] *** reported by process [2418409473,0]
[uc2n481:3743764] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n481:3743764] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3743764] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3743764] ***    and potentially your MPI job)
[uc2n481.localdomain:3743748] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3743748] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3743748] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481:3743911] *** An error occurred in MPI_Irecv
[uc2n481:3743911] *** reported by process [2428174337,0]
[uc2n481:3743911] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n481:3743911] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3743911] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3743911] ***    and potentially your MPI job)
[uc2n481.localdomain:3743897] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3743897] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3743897] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481:3744058] *** An error occurred in MPI_Irecv
[uc2n481:3744058] *** reported by process [2433286145,0]
[uc2n481:3744058] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n481:3744058] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3744058] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3744058] ***    and potentially your MPI job)
[uc2n481.localdomain:3744043] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3744043] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3744043] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481:3744216] *** An error occurred in MPI_Irecv
[uc2n481:3744216] *** reported by process [2447900673,0]
[uc2n481:3744216] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n481:3744216] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3744216] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3744216] ***    and potentially your MPI job)
[uc2n481.localdomain:3744202] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3744202] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3744202] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n483:475463] *** An error occurred in MPI_Irecv
[uc2n483:475463] *** reported by process [2457403393,8]
[uc2n483:475463] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n483:475463] *** MPI_ERR_COUNT: invalid count argument
[uc2n483:475463] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n483:475463] ***    and potentially your MPI job)
[uc2n481.localdomain:3744347] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3744347] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3744347] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n484:07232] *** An error occurred in MPI_Isend
[uc2n484:07232] *** reported by process [2463301633,13]
[uc2n484:07232] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n484:07232] *** MPI_ERR_COUNT: invalid count argument
[uc2n484:07232] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n484:07232] ***    and potentially your MPI job)
[uc2n481.localdomain:3744497] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3744497] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3744497] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481:3744666] *** An error occurred in MPI_Alltoallv
[uc2n481:3744666] *** reported by process [2476933121,0]
[uc2n481:3744666] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n481:3744666] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3744666] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3744666] ***    and potentially your MPI job)
[uc2n481.localdomain:3744641] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3744641] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3744641] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481:3744812] *** An error occurred in MPI_Alltoallw
[uc2n481:3744812] *** reported by process [2486960129,0]
[uc2n481:3744812] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n481:3744812] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3744812] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3744812] ***    and potentially your MPI job)
[uc2n481.localdomain:3744798] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3744798] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3744798] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 06:26:56.353366
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 06:27:09.817346
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 06:27:17.993146
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 06:27:25.551464
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 06:27:30.999524
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 06:27:38.180430
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 06:27:43.756323
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 06:27:49.289140
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 06:27:55.501810
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 06:28:01.428920
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 06:28:06.970215
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 06:28:12.527100
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 06:28:19.842983
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 06:28:25.350281
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 06:28:34.864260
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 06:28:40.493666
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 06:28:46.601556
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 06:28:52.434970
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 06:28:58.075656
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 06:29:07.888745
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 06:29:13.492661
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 06:29:25.076138
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 06:29:30.640309
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 06:29:39.845425
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 06:29:45.421675
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 06:29:51.882185
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 06:29:57.453217
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 06:30:03.117417
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 06:30:08.769629
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 06:30:14.427313
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 06:30:27.021026
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 06:30:32.646028
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 06:30:44.947394
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 06:30:50.722467
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 06:30:56.422321
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 06:31:02.054721
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 06:31:07.870482
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 06:31:13.694846
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 06:31:19.503725
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 06:31:32.160148
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 06:31:37.980092
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 06:31:50.883440
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 06:31:56.726214
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 06:32:02.591455
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 06:32:09.769306
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 06:32:15.942317
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 06:32:22.094580
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 06:32:28.223911
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 06:32:48.336702
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 06:32:54.464667
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 06:33:13.878812
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 06:33:21.246092
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 06:33:27.440804
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 06:33:33.566886
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 06:33:40.151855
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 06:33:46.925995
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 06:33:55.022103
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 06:34:29.568334
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 06:34:36.677377
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 06:35:10.255122
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 06:35:17.023347
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 06:35:24.194322
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 06:35:31.018926
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 06:35:38.645627
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 06:35:47.220922
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 06:35:55.401500
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 06:36:33.129403
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 06:36:41.702215
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 06:37:17.974179
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 06:37:29.784183
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 06:37:41.722576
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 06:37:50.168266
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 06:38:03.994513
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 06:38:20.539726
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 06:38:36.137141
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 06:39:46.323523
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 06:40:02.401016
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 06:41:13.480748
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 06:41:29.986315
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 06:41:46.760922
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 06:42:02.906563
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 06:42:22.305824
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 06:42:48.556991
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 06:43:15.223451
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 06:45:31.355939
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 06:45:56.360703
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 06:48:10.793582
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 06:48:35.078625
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 06:49:05.298923
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 06:49:31.544946
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 06:50:07.821247
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 06:50:53.093170
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 06:51:39.420261
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 06:54:09.873793
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 06:54:54.088393
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 06:57:22.419463
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 06:58:07.624582
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 06:58:55.938627
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 06:59:45.686988
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 07:00:45.902597
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 07:02:08.026605
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 07:03:24.484044
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 07:08:18.636382
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 07:09:40.124150
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 07:14:29.759413
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 07:15:49.945648
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 07:17:08.212054
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 07:18:27.168827
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 07:20:15.709538
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 07:20:23.072947
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 07:20:30.414134
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 07:20:37.733515
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 07:20:45.053358
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 07:20:52.957649
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 07:21:01.216735
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 07:21:09.724124
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 07:21:19.293544
b''

--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3744948] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3744948] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3745094] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3745094] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3745363] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3745363] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3745519] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3745519] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3745662] [[38748,0],0] ORTE_ERROR_LOG: Data unpack would read past end of buffer in file util/show_help.c at line 507
[uc2n481.localdomain:3745662] 14 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3745662] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3745809] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3745809] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3745953] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3745953] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3746096] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3746096] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3746259] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3746259] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3746403] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3746403] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3746549] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3746549] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3746818] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3746818] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3746962] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3746962] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3747117] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3747117] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3747260] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3747260] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3747402] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3747402] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3747547] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3747547] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3747691] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3747691] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3747847] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3747847] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3747990] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3747990] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3748259] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3748259] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3748410] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3748410] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3748553] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3748553] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3748714] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3748714] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3748857] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3748857] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3749002] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3749002] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3749148] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3749148] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3749291] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3749291] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3749449] [[34411,0],0] ORTE_ERROR_LOG: Data unpack had inadequate space in file util/show_help.c at line 501
[uc2n481.localdomain:3749449] 14 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3749449] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3749716] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3749716] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3749865] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3749865] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3750009] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3750009] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3750166] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3750166] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3750308] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3750308] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3750452] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3750452] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3750598] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3750598] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3750741] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3750741] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3750902] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3750902] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3751171] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3751171] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3751320] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3751320] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3751462] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3751462] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3751619] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3751619] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3751764] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3751764] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3751908] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3751908] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3752053] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3752053] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3752207] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3752207] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3752354] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3752354] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3752623] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3752623] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3752789] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3752789] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3752937] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3752937] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3753081] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3753081] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3753226] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3753226] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3753383] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3753383] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3753528] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3753528] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3753677] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3753677] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3753823] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3753823] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3754103] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3754103] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3754253] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3754253] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3754418] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3754418] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3754572] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3754572] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3754728] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3754728] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3754874] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3754874] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3755018] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3755018] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3755162] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3755162] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3755319] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3755319] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3755588] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3755588] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3755758] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3755758] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3755905] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3755905] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3756067] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3756067] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3756216] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3756216] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3756371] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3756371] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3756517] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3756517] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3756663] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3756663] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3756810] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3756810] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3757095] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3757095] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3757269] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3757269] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3757426] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3757426] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3757604] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3757604] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3757751] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3757751] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3757909] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3757909] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3758054] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3758054] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3758205] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3758205] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3758368] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3758368] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3758659] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3758659] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3758857] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3758857] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3759021] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3759021] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3759218] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3759218] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3759381] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3759381] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3759533] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3759533] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3759694] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3759694] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3759857] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3759857] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3760010] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3760010] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3760303] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3760303] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3760541] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3760541] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3760707] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3760707] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3760931] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3760931] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3761100] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3761100] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3761268] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3761268] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3761433] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3761433] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3761606] [[54756,0],0] ORTE_ERROR_LOG: Data unpack had inadequate space in file util/show_help.c at line 507
[uc2n481.localdomain:3761606] 14 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3761606] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3761777] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3761777] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3762091] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3762091] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3762414] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3762414] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3762590] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3762590] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3762911] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3762911] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3763086] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3763086] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3763273] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3763273] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3763460] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3763460] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3763655] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3763655] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3763881] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3763881] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3764223] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3764223] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3764703] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3764703] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
The call to cuMemcpyAsync failed. This is a unrecoverable error and will
cause the program to abort.
  cuMemcpyAsync(0x14592c258078, 0x1454e1fe0be0, 131040) returned value 1
Check the cuda.h file for what the return value means.
--------------------------------------------------------------------------
[uc2n481.localdomain:3764718] CUDA: Error in cuMemcpy: res=-1, dest=0x14592c258078, src=0x1454e1fe0be0, size=131040
[uc2n481:3764718] *** Process received signal ***
[uc2n481:3764718] Signal: Aborted (6)
[uc2n481:3764718] Signal code:  (-6)
[uc2n481:3764718] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x145951005dd0]
[uc2n481:3764718] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x145950c6870f]
[uc2n481:3764718] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x145950c52b25]
[uc2n481:3764718] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x14594fbd2375]
[uc2n481:3764718] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x14594fbc91e8]
[uc2n481:3764718] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_smcuda_prepare_src+0x126)[0x14594fc210a6]
[uc2n481:3764718] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x14595cb8422b]
[uc2n481:3764718] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x14595cb8727c]
[uc2n481:3764718] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_smcuda_component_progress+0x507)[0x14594fc234c7]
[uc2n481:3764718] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x14594fbb8a1b]
[uc2n481:3764718] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x14594fbbeef5]
[uc2n481:3764718] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x14595c9fb8ea]
[uc2n481:3764718] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x1db)[0x14595ca6077b]
[uc2n481:3764718] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x14595ca6c702]
[uc2n481:3764718] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x14595ca0e42b]
[uc2n481:3764718] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE27All2All_Sync_FirstTransposeEPvb+0x9fa)[0x14596715001a]
[uc2n481:3764718] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x3d3)[0x14596714e5e3]
[uc2n481:3764718] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x1459673b066e]
[uc2n481:3764718] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x1459673af6af]
[uc2n481:3764718] [19] pencil[0x40326b]
[uc2n481:3764718] [20] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x145950c546a3]
[uc2n481:3764718] [21] pencil[0x4035fe]
[uc2n481:3764718] *** End of error message ***
[uc2n484.localdomain:27924] CUDA: Error in cuMemcpy: res=-1, dest=0x14fc2802c078, src=0x14f7ddfe0be0, size=131040
[uc2n484:27924] *** Process received signal ***
[uc2n484:27924] Signal: Aborted (6)
[uc2n484:27924] Signal code:  (-6)
[uc2n484:27924] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x14fc4c703dd0]
[uc2n484:27924] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x14fc4c36670f]
[uc2n484:27924] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x14fc4c350b25]
[uc2n484:27924] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x14fc4b2d0375]
[uc2n484:27924] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x14fc4b2c71e8]
[uc2n484:27924] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_smcuda_prepare_src+0x126)[0x14fc4b31f0a6]
[uc2n484:27924] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x14fc5828222b]
[uc2n484:27924] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x14fc5828527c]
[uc2n484:27924] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_smcuda_component_progress+0x507)[0x14fc4b3214c7]
[uc2n484:27924] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x14fc4b2b6a1b]
[uc2n484:27924] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x14fc4b2bcef5]
[uc2n484:27924] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x14fc580f98ea]
[uc2n484:27924] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x1db)[0x14fc5815e77b]
[uc2n484:27924] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x14fc5816a702]
[uc2n484:27924] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x14fc5810c42b]
[uc2n484:27924] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE27All2All_Sync_FirstTransposeEPvb+0x9fa)[0x14fc6284e01a]
[uc2n484:27924] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x3d3)[0x14fc6284c5e3]
[uc2n484:27924] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x14fc62aae66e]
[uc2n484:27924] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x14fc62aad6af]
[uc2n484:27924] [19] pencil[0x40326b]
[uc2n484:27924] [20] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x14fc4c3526a3]
[uc2n484:27924] [21] pencil[0x4035fe]
[uc2n484:27924] *** End of error message ***
[uc2n482.localdomain:596915] CUDA: Error in cuMemcpy: res=-1, dest=0x150bb418c0f8, src=0x15076bfe0be0, size=131040
[uc2n482:596915] *** Process received signal ***
[uc2n482:596915] Signal: Aborted (6)
[uc2n482:596915] Signal code:  (-6)
[uc2n483.localdomain:496261] CUDA: Error in cuMemcpy: res=-1, dest=0x14bb4c3ae0f8, src=0x14b6fffe0be0, size=131040
[uc2n483:496261] *** Process received signal ***
[uc2n483:496261] Signal: Aborted (6)
[uc2n483:496261] Signal code:  (-6)
[uc2n483:496261] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x14bb70bbfdd0]
[uc2n483:496261] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x14bb7082270f]
[uc2n483:496261] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x14bb7080cb25]
[uc2n483:496261] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x14bb6f78c375]
[uc2n483:496261] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x14bb6f7831e8]
[uc2n483:496261] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_smcuda_prepare_src+0x126)[0x14bb6f7db0a6]
[uc2n483:496261] [ 6] [uc2n482:596915] [ 0] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x14bb7c73e22b]
[uc2n483:496261] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x14bb7c74127c]
[uc2n483:496261] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_smcuda_component_progress+0x507)[0x14bb6f7dd4c7]
[uc2n483:496261] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x14bb6f772a1b]
[uc2n483:496261] [10] /usr/lib64/libpthread.so.0(+0x12dd0)[0x150bdafd4dd0]
[uc2n482:596915] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x150bdac3770f]
[uc2n482:596915] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x150bdac21b25]
[uc2n482:596915] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x150bd9ba1375]
[uc2n482:596915] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x14bb6f778ef5]
[uc2n483:496261] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x150bd9b981e8]
[uc2n482:596915] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x14bb7c5b58ea]
[uc2n483:496261] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_smcuda_prepare_src+0x126)[0x150bd9bf00a6]
[uc2n482:596915] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x1db)[0x14bb7c61a77b]
[uc2n483:496261] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x14bb7c626702]
[uc2n483:496261] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x150be6b5322b]
[uc2n482:596915] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x14bb7c5c842b]
[uc2n483:496261] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE27All2All_Sync_FirstTransposeEPvb+0x9fa)[0x14bb86d0a01a]
[uc2n483:496261] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x3d3)[0x14bb86d085e3]
[uc2n483:496261] [17] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x150be6b5627c]
[uc2n482:596915] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_smcuda_component_progress+0x507)[0x150bd9bf24c7]
[uc2n482:596915] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x150bd9b87a1b]
[uc2n482:596915] [10] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x14bb86f6a66e]
[uc2n483:496261] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x14bb86f696af]
[uc2n483:496261] [19] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x150bd9b8def5]
[uc2n482:596915] [11] pencil[0x40326b]
[uc2n483:496261] [20] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x14bb7080e6a3]
[uc2n483:496261] [21] pencil[0x4035fe]
[uc2n483:496261] *** End of error message ***
/opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x150be69ca8ea]
[uc2n482:596915] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x1db)[0x150be6a2f77b]
[uc2n482:596915] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x150be6a3b702]
[uc2n482:596915] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x150be69dd42b]
[uc2n482:596915] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE27All2All_Sync_FirstTransposeEPvb+0x9fa)[0x150bf111f01a]
[uc2n482:596915] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x3d3)[0x150bf111d5e3]
[uc2n482:596915] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x150bf137f66e]
[uc2n482:596915] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x150bf137e6af]
[uc2n482:596915] [19] pencil[0x40326b]
[uc2n482:596915] [20] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x150bdac236a3]
[uc2n482:596915] [21] pencil[0x4035fe]
[uc2n482:596915] *** End of error message ***
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 12 with PID 27924 on node uc2n484 exited on signal 6 (Aborted).
--------------------------------------------------------------------------
[uc2n481.localdomain:3764703] 3 more processes have sent help message help-mpi-common-cuda.txt / cuMemcpyAsync failed
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3764874] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3764874] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3765305] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3765305] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3765527] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3765527] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3765747] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3765747] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3765761] CUDA: Error in cuMemcpy: res=1, dest=0x14721284e0f1, src=0x146dcffe0be0, size=131040
[uc2n481:3765761] *** Process received signal ***
[uc2n481:3765761] Signal: Aborted (6)
[uc2n481:3765761] Signal code:  (-6)
[uc2n481:3765761] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x147240c19dd0]
[uc2n481:3765761] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x14724087c70f]
[uc2n481:3765761] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x147240866b25]
[uc2n481:3765761] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x14723f7e6375]
[uc2n481:3765761] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x14723f7dd1e8]
[uc2n481:3765761] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_openib_prepare_src+0x81)[0x14723f838941]
[uc2n481:3765761] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x14724c79822b]
[uc2n481:3765761] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x14724c79b27c]
[uc2n481:3765761] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda31f)[0x14723f84431f]
[uc2n481:3765761] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x14723f8451a6]
[uc2n481:3765761] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x14723f7cca1b]
[uc2n481:3765761] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x14723f7d2ef5]
[uc2n481:3765761] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x14724c60f8ea]
[uc2n481:3765761] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x1db)[0x14724c67477b]
[uc2n481:3765761] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x14724c680702]
[uc2n481:3765761] [15] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x14724c62242b]
[uc2n481:3765761] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE28All2All_Sync_SecondTransposeEPvb+0x47b)[0x147256d65d3b]
[uc2n481:3765761] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x45e)[0x147256d6266e]
[uc2n481:3765761] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x147256fc466e]
[uc2n481:3765761] [19] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x147256fc36af]
[uc2n481:3765761] [20] pencil[0x40326b]
[uc2n481:3765761] [21] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x1472408686a3]
[uc2n481:3765761] [22] pencil[0x4035fe]
[uc2n481:3765761] *** End of error message ***
[uc2n483.localdomain:497325] CUDA: Error in cuMemcpy: res=1, dest=0x14fcd402b031, src=0x14f87dfe0be0, size=131040
[uc2n483:497325] *** Process received signal ***
[uc2n483:497325] Signal: Aborted (6)
[uc2n483:497325] Signal code:  (-6)
[uc2n483:497325] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x14fceffe7dd0]
[uc2n483:497325] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x14fcefc4a70f]
[uc2n483:497325] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x14fcefc34b25]
[uc2n483:497325] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x14fceebb4375]
[uc2n483:497325] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x14fceebab1e8]
[uc2n483:497325] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_openib_prepare_src+0x81)[0x14fceec06941]
[uc2n483:497325] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x14fcfbb6622b]
[uc2n483:497325] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x14fcfbb6927c]
[uc2n483:497325] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda31f)[0x14fceec1231f]
[uc2n483:497325] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x14fceec131a6]
[uc2n483:497325] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x14fceeb9aa1b]
[uc2n483:497325] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x14fceeba0ef5]
[uc2n483:497325] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x14fcfb9dd8ea]
[uc2n483:497325] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x1db)[0x14fcfba4277b]
[uc2n483:497325] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x14fcfba4e702]
[uc2n483:497325] [15] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x14fcfb9f042b]
[uc2n483:497325] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE28All2All_Sync_SecondTransposeEPvb+0x47b)[0x14fd06133d3b]
[uc2n483:497325] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x45e)[0x14fd0613066e]
[uc2n483:497325] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x14fd0639266e]
[uc2n483:497325] [19] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x14fd063916af]
[uc2n483:497325] [20] pencil[0x40326b]
[uc2n483:497325] [21] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x14fcefc366a3]
[uc2n483:497325] [22] pencil[0x4035fe]
[uc2n483:497325] *** End of error message ***
[uc2n482.localdomain:597997] CUDA: Error in cuMemcpy: res=1, dest=0x1461a320b1f1, src=0x145d61fe0be0, size=131040
[uc2n482:597997] *** Process received signal ***
[uc2n482:597997] Signal: Aborted (6)
[uc2n482:597997] Signal code:  (-6)
[uc2n482:597997] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x1461d1590dd0]
[uc2n482:597997] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x1461d11f370f]
[uc2n482:597997] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x1461d11ddb25]
[uc2n482:597997] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x1461d015d375]
[uc2n482:597997] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x1461d01541e8]
[uc2n482:597997] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_openib_prepare_src+0x81)[0x1461d01af941]
[uc2n482:597997] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x1461dd10f22b]
[uc2n482:597997] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x1461dd11227c]
[uc2n482:597997] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda31f)[0x1461d01bb31f]
[uc2n482:597997] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x1461d01bc1a6]
[uc2n482:597997] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x1461d0143a1b]
[uc2n482:597997] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x1461d0149ef5]
[uc2n482:597997] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x1461dcf868ea]
[uc2n482:597997] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x1db)[0x1461dcfeb77b]
[uc2n482:597997] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x1461dcff7702]
[uc2n482:597997] [15] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x1461dcf9942b]
[uc2n482:597997] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE28All2All_Sync_SecondTransposeEPvb+0x47b)[0x1461e76dcd3b]
[uc2n482:597997] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x45e)[0x1461e76d966e]
[uc2n482:597997] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x1461e793b66e]
[uc2n482:597997] [19] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x1461e793a6af]
[uc2n482:597997] [20] pencil[0x40326b]
[uc2n482:597997] [21] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x1461d11df6a3]
[uc2n482:597997] [22] pencil[0x4035fe]
[uc2n482:597997] *** End of error message ***
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 8 with PID 497325 on node uc2n483 exited on signal 6 (Aborted).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3765904] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3765904] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n482.localdomain:598161] CUDA: Error in cuMemcpy: res=1, dest=0x14d6e8228031, src=0x14d291fe0be0, size=131040
[uc2n482:598161] *** Process received signal ***
[uc2n482:598161] Signal: Aborted (6)
[uc2n482:598161] Signal code:  (-6)
[uc2n482:598161] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x14d70360bdd0]
[uc2n482:598161] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x14d70326e70f]
[uc2n482:598161] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x14d703258b25]
[uc2n482:598161] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x14d7021d8375]
[uc2n482:598161] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x14d7021cf1e8]
[uc2n482:598161] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_openib_prepare_src+0x81)[0x14d70222a941]
[uc2n482:598161] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x14d70f18a22b]
[uc2n482:598161] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x14d70f18d27c]
[uc2n482:598161] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda31f)[0x14d70223631f]
[uc2n482:598161] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x14d7022371a6]
[uc2n482:598161] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x14d7021bea1b]
[uc2n482:598161] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x14d7021c4ef5]
[uc2n482:598161] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x14d70f0018ea]
[uc2n482:598161] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_coll_basic_alltoallw_intra+0x252)[0x14d70f0a5b32]
[uc2n482:598161] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallw+0x1eb)[0x14d70f014ccb]
[uc2n482:598161] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE31All2All_MPIType_SecondTransposeEPvb+0x393)[0x14d719758443]
[uc2n482:598161] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x45e)[0x14d71975466e]
[uc2n482:598161] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x14d7199b666e]
[uc2n482:598161] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x14d7199b56af]
[uc2n482:598161] [19] pencil[0x40326b]
[uc2n482:598161] [20] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x14d70325a6a3]
[uc2n482:598161] [21] pencil[0x4035fe]
[uc2n482:598161] *** End of error message ***
[uc2n483.localdomain:497486] CUDA: Error in cuMemcpy: res=1, dest=0x149d97b1b071, src=0x149955fe0be0, size=131040
[uc2n483:497486] *** Process received signal ***
[uc2n483:497486] Signal: Aborted (6)
[uc2n483:497486] Signal code:  (-6)
[uc2n483:497486] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x149dc9fd4dd0]
[uc2n483:497486] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x149dc9c3770f]
[uc2n483:497486] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x149dc9c21b25]
[uc2n483:497486] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x149dc8ba1375]
[uc2n483:497486] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x149dc8b981e8]
[uc2n483:497486] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_openib_prepare_src+0x81)[0x149dc8bf3941]
[uc2n483:497486] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x149dd5b5322b]
[uc2n483:497486] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x149dd5b5627c]
[uc2n483:497486] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda31f)[0x149dc8bff31f]
[uc2n483:497486] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x149dc8c001a6]
[uc2n483:497486] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x149dc8b87a1b]
[uc2n483:497486] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x149dc8b8def5]
[uc2n483:497486] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x149dd59ca8ea]
[uc2n483:497486] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_coll_basic_alltoallw_intra+0x252)[0x149dd5a6eb32]
[uc2n483:497486] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallw+0x1eb)[0x149dd59ddccb]
[uc2n483:497486] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE31All2All_MPIType_SecondTransposeEPvb+0x393)[0x149de0121443]
[uc2n483:497486] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x45e)[0x149de011d66e]
[uc2n483:497486] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x149de037f66e]
[uc2n483:497486] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x149de037e6af]
[uc2n483:497486] [19] pencil[0x40326b]
[uc2n483:497486] [20] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x149dc9c236a3]
[uc2n483:497486] [21] pencil[0x4035fe]
[uc2n483:497486] *** End of error message ***
[uc2n481.localdomain:3765920] CUDA: Error in cuMemcpy: res=1, dest=0x1507d821d0f1, src=0x150381fe0be0, size=131040
[uc2n481:3765920] *** Process received signal ***
[uc2n481:3765920] Signal: Aborted (6)
[uc2n481:3765920] Signal code:  (-6)
[uc2n481:3765920] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x1507f31bbdd0]
[uc2n481:3765920] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x1507f2e1e70f]
[uc2n481:3765920] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x1507f2e08b25]
[uc2n481:3765920] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x1507f1d88375]
[uc2n481:3765920] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x1507f1d7f1e8]
[uc2n481:3765920] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_openib_prepare_src+0x81)[0x1507f1dda941]
[uc2n481:3765920] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x1507fed3a22b]
[uc2n481:3765920] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x1507fed3d27c]
[uc2n481:3765920] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda31f)[0x1507f1de631f]
[uc2n481:3765920] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x1507f1de71a6]
[uc2n481:3765920] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x1507f1d6ea1b]
[uc2n481:3765920] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x1507f1d74ef5]
[uc2n481:3765920] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x1507febb18ea]
[uc2n481:3765920] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_coll_basic_alltoallw_intra+0x252)[0x1507fec55b32]
[uc2n481:3765920] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallw+0x1eb)[0x1507febc4ccb]
[uc2n481:3765920] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE31All2All_MPIType_SecondTransposeEPvb+0x393)[0x150809308443]
[uc2n481:3765920] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x45e)[0x15080930466e]
[uc2n481:3765920] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x15080956666e]
[uc2n481:3765920] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x1508095656af]
[uc2n481:3765920] [19] pencil[0x40326b]
[uc2n481:3765920] [20] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x1507f2e0a6a3]
[uc2n481:3765920] [21] pencil[0x4035fe]
[uc2n481:3765920] *** End of error message ***
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 4 with PID 598161 on node uc2n482 exited on signal 6 (Aborted).
--------------------------------------------------------------------------
Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 07:21:27.750183
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 07:21:33.341172
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 07:21:38.779249
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 07:21:45.179786
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 07:21:52.770831
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 07:21:59.077003
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 07:22:04.535684
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 07:22:10.031121
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 07:22:15.527771
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 07:22:21.048764
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 07:22:27.578495
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 07:22:33.099699
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 07:22:39.466462
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 07:22:44.968276
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 07:22:51.385574
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 07:22:56.899417
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 07:23:02.887585
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 07:23:08.412763
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 07:23:13.972490
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 07:23:19.833828
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 07:23:26.200606
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 07:23:33.531181
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 07:23:39.072400
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 07:23:46.857069
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 07:23:52.774695
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 07:23:58.433371
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 07:24:03.990493
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 07:24:11.030741
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 07:24:16.676381
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 07:24:22.296479
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 07:24:31.249668
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 07:24:36.965165
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 07:24:45.895721
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 07:24:51.757814
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 07:24:58.051988
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 07:25:03.683838
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 07:25:09.482654
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 07:25:15.349082
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 07:25:24.458439
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 07:25:33.782012
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 07:25:39.637063
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 07:25:49.026372
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 07:25:54.941501
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 07:26:00.859494
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 07:26:06.781027
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 07:26:12.774327
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 07:26:18.933677
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 07:26:25.110534
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 07:26:42.994109
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 07:26:49.192417
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 07:27:02.037214
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 07:27:09.328232
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 07:27:15.588876
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 07:27:21.770071
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 07:27:29.831390
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 07:27:37.366106
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 07:27:46.106363
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 07:28:07.531593
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 07:28:14.456030
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 07:28:36.621713
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 07:28:43.548512
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 07:28:50.886787
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 07:28:58.468525
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 07:29:06.634462
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 07:29:14.816773
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 07:29:25.804515
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 07:29:49.719063
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 07:29:59.391765
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 07:30:21.558662
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 07:30:32.996153
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 07:30:41.886539
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 07:30:50.210765
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 07:30:59.364519
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 07:31:10.048347
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 07:31:20.763416
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 07:32:01.913265
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 07:32:12.641987
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 07:32:54.698953
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 07:33:05.437175
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 07:33:16.178831
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 07:33:27.075617
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 07:33:39.907239
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 07:33:56.706658
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 07:34:15.997256
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 07:35:32.828574
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 07:35:49.726552
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 07:37:02.525796
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 07:37:19.513261
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 07:37:37.331737
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 07:37:53.849615
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 07:38:13.467955
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 07:38:39.699748
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 07:39:05.821789
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 07:40:50.663342
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 07:41:16.404548
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 07:42:54.869772
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 07:43:20.630554
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 07:43:47.339261
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 07:44:13.852251
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 07:44:46.361671
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 07:45:32.996238
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 07:46:18.540540
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 07:49:52.617623
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 07:50:39.466254
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 07:53:56.258685
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 07:54:41.960542
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 07:55:27.671178
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 07:56:14.199936
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 07:57:13.510123
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 07:58:47.969204
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 08:00:23.006093
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 08:06:10.184862
b'3 total processes killed (some possibly by mpiexec during cleanup)\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 08:06:21.329153
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 08:11:50.856338
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 08:13:25.427630
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 08:15:00.228871
b'2 total processes killed (some possibly by mpiexec during cleanup)\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 08:15:09.850480
b'2 total processes killed (some possibly by mpiexec during cleanup)\n'

Pencil Opt1 Inverse
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3766074] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3766074] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3766220] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3766220] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3766493] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3766493] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3766636] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3766636] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3766790] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3766790] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3766936] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3766936] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3767205] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3767205] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3767353] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3767353] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3767495] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3767495] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3767658] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3767658] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3767802] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3767802] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3768071] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3768071] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3768220] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3768220] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3768362] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3768362] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3768525] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3768525] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3768796] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3768796] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3768940] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3768940] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3769087] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3769087] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3769229] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3769229] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3769384] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3769384] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3769653] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3769653] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3769799] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3769799] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3769949] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3769949] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3770092] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3770092] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3770375] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3770375] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3770521] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3770521] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3770665] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3770665] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3770812] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3770812] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3770957] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3770957] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3771237] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3771237] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3771384] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3771384] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3771526] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3771526] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3771675] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3771675] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3771954] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3771954] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3772100] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3772100] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3772246] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3772246] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3772391] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3772391] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3772534] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3772534] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3772818] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3772818] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3772963] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3772963] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3773112] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3773112] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3773257] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3773257] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3773537] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3773537] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3773681] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3773681] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3773824] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3773824] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3773970] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3773970] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3774127] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3774127] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3774396] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3774396] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3774541] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3774541] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3774691] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3774691] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3774850] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3774850] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3775119] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3775119] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3775262] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3775262] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3775409] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3775409] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3775564] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3775564] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3775708] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3775708] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3775978] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3775978] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3776127] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3776127] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3776283] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3776283] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3776432] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3776432] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3776699] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3776699] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3776862] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3776862] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3777006] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3777006] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3777155] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3777155] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3777298] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3777298] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3777579] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3777579] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3777729] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3777729] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3777887] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3777887] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3778057] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3778057] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3778328] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3778328] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3778472] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3778472] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3778615] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3778615] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3778778] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3778778] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3778928] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3778928] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3779211] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3779211] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3779377] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3779377] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3779529] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3779529] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3779695] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3779695] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3779978] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3779978] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3780126] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3780126] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3780289] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3780289] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3780444] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3780444] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3780608] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3780608] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3780896] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3780896] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3781088] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3781088] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3781241] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3781241] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3781435] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3781435] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3781727] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3781727] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3781887] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3781887] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3782047] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3782047] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3782261] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3782261] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3782443] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3782443] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3782744] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3782744] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3782964] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3782964] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3783143] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3783143] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3783374] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3783374] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3783685] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3783685] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3783852] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3783852] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3784028] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3784028] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3784217] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3784217] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3784428] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3784428] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3784761] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3784761] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3785006] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3785006] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3785215] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3785215] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3785474] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3785474] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3785812] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3785812] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3785988] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3785988] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3786198] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3786198] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481:3786438] *** An error occurred in MPI_Irecv
[uc2n481:3786438] *** reported by process [1989607425,2]
[uc2n481:3786438] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n481:3786438] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3786438] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3786438] ***    and potentially your MPI job)
[uc2n481.localdomain:3786421] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3786421] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3786421] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481:3786580] *** An error occurred in MPI_Irecv
[uc2n481:3786580] *** reported by process [2002976769,0]
[uc2n481:3786580] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n481:3786580] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3786580] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3786580] ***    and potentially your MPI job)
[uc2n481.localdomain:3786561] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3786561] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3786561] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481:3786734] *** An error occurred in MPI_Irecv
[uc2n481:3786734] *** reported by process [2009202689,0]
[uc2n481:3786734] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n481:3786734] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3786734] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3786734] ***    and potentially your MPI job)
[uc2n481.localdomain:3786720] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3786720] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3786720] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481:3786882] *** An error occurred in MPI_Irecv
[uc2n481:3786882] *** reported by process [2018705409,2]
[uc2n481:3786882] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n481:3786882] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3786882] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3786882] ***    and potentially your MPI job)
[uc2n481.localdomain:3786865] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3786865] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3786865] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481:3787028] *** An error occurred in MPI_Irecv
[uc2n481:3787028] *** reported by process [2032599041,0]
[uc2n481:3787028] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n481:3787028] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3787028] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3787028] ***    and potentially your MPI job)
[uc2n481.localdomain:3787013] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3787013] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3787013] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481:3787176] *** An error occurred in MPI_Irecv
[uc2n481:3787176] *** reported by process [2042232833,2]
[uc2n481:3787176] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n481:3787176] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3787176] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3787176] ***    and potentially your MPI job)
[uc2n481.localdomain:3787160] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3787160] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3787160] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481:3787340] *** An error occurred in MPI_Irecv
[uc2n481:3787340] *** reported by process [2048786433,2]
[uc2n481:3787340] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n481:3787340] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3787340] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3787340] ***    and potentially your MPI job)
[uc2n481.localdomain:3787324] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3787324] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3787324] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481:3787485] *** An error occurred in MPI_Alltoallv
[uc2n481:3787485] *** reported by process [2062155777,2]
[uc2n481:3787485] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n481:3787485] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3787485] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3787485] ***    and potentially your MPI job)
[uc2n481.localdomain:3787464] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3787464] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3787464] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481:3787629] *** An error occurred in MPI_Alltoallw
[uc2n481:3787629] *** reported by process [2071920641,2]
[uc2n481:3787629] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n481:3787629] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3787629] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3787629] ***    and potentially your MPI job)
[uc2n481.localdomain:3787613] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3787613] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3787613] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 08:15:21.505835
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 08:15:28.592274
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 08:15:34.123824
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 08:15:41.708953
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 08:15:47.204733
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 08:15:53.373903
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 08:15:58.852682
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 08:16:04.404625
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 08:16:09.944887
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 08:16:15.629358
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 08:16:21.168987
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 08:16:26.692108
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 08:16:33.980840
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 08:16:39.687258
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 08:16:48.281304
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 08:16:53.774521
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 08:16:59.358534
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 08:17:04.863626
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 08:17:10.712044
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 08:17:16.268588
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 08:17:21.818105
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 08:17:28.373819
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 08:17:33.926414
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 08:17:40.670761
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 08:17:46.221449
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 08:17:51.904338
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 08:17:57.658827
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 08:18:04.551089
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 08:18:10.226827
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 08:18:16.520792
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 08:18:23.979594
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 08:18:30.554498
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 08:18:40.132251
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 08:18:46.224937
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 08:18:51.961361
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 08:18:57.727441
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 08:19:04.067979
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 08:19:12.086516
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 08:19:17.900036
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 08:19:27.895395
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 08:19:33.671573
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 08:19:43.923892
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 08:19:49.682024
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 08:19:55.599714
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 08:20:01.631911
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 08:20:08.793969
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 08:20:14.823331
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 08:20:20.888620
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 08:20:31.309056
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 08:20:37.410612
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 08:20:47.924255
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 08:20:53.999259
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 08:21:00.386514
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 08:21:06.441653
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 08:21:15.191373
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 08:21:21.835833
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 08:21:28.546875
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 08:21:41.915823
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 08:21:48.982351
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 08:22:04.513480
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 08:22:11.184258
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 08:22:18.103311
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 08:22:24.850776
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 08:22:34.432646
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 08:22:43.237048
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 08:22:51.081146
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 08:23:12.057620
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 08:23:20.128852
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 08:23:45.552099
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 08:23:53.832289
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 08:24:03.216249
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 08:24:11.605533
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 08:24:25.226579
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 08:24:39.881169
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 08:24:54.990305
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 08:25:21.265334
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 08:25:35.498682
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 08:26:05.970523
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 08:26:21.510444
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 08:26:32.752867
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 08:26:47.905426
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 08:27:09.953983
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 08:27:34.956864
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 08:27:59.186414
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 08:28:46.130317
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 08:29:10.576479
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 08:30:06.160383
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 08:30:33.528794
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 08:30:49.573551
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 08:31:15.681149
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 08:31:44.682118
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 08:32:27.399574
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 08:33:09.367332
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 08:34:38.419968
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 08:35:25.215563
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 08:37:15.603783
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 08:37:59.900441
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 08:38:26.183840
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 08:39:12.090141
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 08:40:04.790337
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 08:41:20.038251
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 08:42:36.818566
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 08:44:34.707842
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 08:45:51.057528
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 08:48:11.013451
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 08:49:26.626864
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 08:50:13.109546
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 08:51:31.603146
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 08:53:10.434854
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 08:53:14.757858
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 08:53:22.665974
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 08:53:29.731769
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 08:53:37.426256
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 08:53:44.507734
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 08:53:51.569459
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 08:53:55.690224
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 08:54:03.631454
b''

--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3787759] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3787759] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3787909] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3787909] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3788187] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3788187] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3788331] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3788331] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3788478] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3788478] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3788623] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3788623] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3788901] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3788901] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3789046] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3789046] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3789190] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3789190] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3789335] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3789335] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3789480] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3789480] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3789748] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3789748] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3789908] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3789908] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3790053] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3790053] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3790196] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3790196] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3790471] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3790471] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3790616] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3790616] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3790769] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3790769] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3790915] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3790915] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3791058] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3791058] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3791328] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3791328] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3791471] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3791471] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3791627] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3791627] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3791776] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3791776] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3792043] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3792043] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3792191] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3792191] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3792334] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3792334] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3792492] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3792492] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3792639] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3792639] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3792907] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3792907] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3793054] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3793054] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3793199] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3793199] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3793353] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3793353] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3793622] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3793622] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3793766] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3793766] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3793911] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3793911] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3794056] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3794056] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3794211] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3794211] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3794479] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3794479] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3794626] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3794626] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3794769] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3794769] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3794934] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3794934] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3795202] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3795202] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3795345] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3795345] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3795493] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3795493] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3795638] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3795638] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3795791] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3795791] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3796060] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3796060] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3796208] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3796208] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3796351] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3796351] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3796509] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3796509] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3796777] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3796777] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3796926] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3796926] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3797071] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3797071] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3797230] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3797230] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3797374] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3797374] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3797645] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3797645] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3797806] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3797806] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3797951] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3797951] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3798102] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3798102] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3798380] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3798380] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3798525] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3798525] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3798712] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3798712] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3798861] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3798861] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3799019] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3799019] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3799289] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3799289] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3799453] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3799453] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3799600] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3799600] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3799764] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3799764] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3800034] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3800034] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3800185] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3800185] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3800330] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3800330] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3800491] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3800491] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3800638] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3800638] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3800922] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3800922] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3801075] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3801075] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3801232] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3801232] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3801384] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3801384] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3801671] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3801671] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3801821] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3801821] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3801979] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3801979] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3802129] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3802129] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3802286] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3802286] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3802575] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3802575] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3802745] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3802745] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3802898] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3802898] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3803086] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3803086] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3803361] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3803361] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3803520] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3803520] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3803670] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3803670] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3803842] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3803842] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3804007] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3804007] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3804300] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3804300] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3804498] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3804498] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3804662] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3804662] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3804878] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3804878] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3805169] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3805169] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3805338] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3805338] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3805506] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3805506] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3805698] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3805698] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3805873] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3805873] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3806185] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3806185] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3806385] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3806385] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3806576] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3806576] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3806816] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3806816] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3807118] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3807118] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3807311] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3807311] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3807502] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3807502] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3807735] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3807735] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3807950] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3807950] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3808290] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3808290] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n484:72569:0:72569] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1502ae400010)
[uc2n482:642546:0:642546] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x150fae400010)
[uc2n483:540971:0:540971] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14bb5a400010)
[uc2n482:642547:0:642547] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1539b8400010)
[uc2n484:72568:0:72568] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x150798400010)
[uc2n481:3808590:0:3808590] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x146cc8400010)
[uc2n481:3808591:0:3808591] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x15293e400010)
[uc2n483:540970:0:540970] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x148558400010)
==== backtrace (tid:3808590) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002bbc5 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
18 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3808591) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002bbc5 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
18 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 540971) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002bbc5 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
18 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 540970) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002bbc5 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
18 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 642547) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002bbc5 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
18 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 642546) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002bbc5 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
18 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:  72569) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002bbc5 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
18 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:  72568) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002bbc5 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
18 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
[uc2n481.localdomain:3808573] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3808573] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 3 with PID 0 on node uc2n481 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n483:541139:0:541139] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1455e8400000)
[uc2n482:642725:0:642725] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x149b84400000)
[uc2n482:642724:0:642724] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1525ba400000)
[uc2n481:3808768:0:3808768] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x151d18400000)
[uc2n484:72740:0:72740] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1492a0400000)
==== backtrace (tid: 541139) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c263 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
[uc2n484:72741:0:72741] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x146a64400000)
[uc2n481:3808767:0:3808767] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14714e400000)
[uc2n483:541138:0:541138] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x151c7e400000)
==== backtrace (tid: 642725) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c263 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 642724) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c263 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3808768) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c263 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:  72740) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c263 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:  72741) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c263 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3808767) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c263 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 541138) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c263 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
[uc2n481.localdomain:3808750] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3808750] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 11 with PID 541139 on node uc2n483 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3808916] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3808916] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3809262] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3809262] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n484:73478:0:73478] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x147214000010)
[uc2n484:73477:0:73477] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14b2ce000010)
[uc2n484:73475:0:73475] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c736c00010)
[uc2n484:73476:0:73476] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14f4ca000010)
[uc2n483:541896:0:541896] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x153be4000010)
[uc2n483:541895:0:541895] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e0fe000010)
[uc2n483:541893:0:541893] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14872a800010)
[uc2n483:541894:0:541894] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x148cfa000010)
==== backtrace (tid:  73478) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002d85d MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
18 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:  73477) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002d85d MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
18 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:  73475) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002d85d MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
18 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:  73476) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002d85d MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
18 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 541896) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002d85d MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
18 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 541895) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002d85d MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
18 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 541893) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002d85d MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
18 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 541894) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002d85d MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
18 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[uc2n481.localdomain:3809481] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3809481] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec noticed that process rank 14 with PID 73477 on node uc2n484 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n484:73671:0:73671] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14ce5a000000)
[uc2n484:73672:0:73672] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14ed18000000)
[uc2n484:73669:0:73669] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14d848c00000)
[uc2n484:73670:0:73670] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14753e000000)
[uc2n483:542078:0:542078] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x146cfa000000)
[uc2n483:542077:0:542077] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1504f4800000)
[uc2n483:542079:0:542079] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x150de8000000)
[uc2n483:542080:0:542080] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x153014000000)
==== backtrace (tid:  73671) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002ded3 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:  73672) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002ded3 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:  73669) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002ded3 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:  73670) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002ded3 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 542078) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002ded3 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 542080) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002ded3 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 542079) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002ded3 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 542077) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002ded3 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[uc2n481.localdomain:3809629] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3809629] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec noticed that process rank 15 with PID 73672 on node uc2n484 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 08:54:11.237017
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 08:54:16.734893
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 08:54:22.198468
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 08:54:28.360086
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 08:54:33.824948
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 08:54:41.613731
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 08:54:47.133230
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 08:54:52.693892
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 08:54:58.147855
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 08:55:03.853532
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 08:55:09.370579
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 08:55:14.924770
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 08:55:21.280004
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 08:55:26.760549
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 08:55:33.214441
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 08:55:38.681809
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 08:55:44.362824
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 08:55:49.803036
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 08:55:55.681529
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 08:56:01.189607
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 08:56:06.712917
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 08:56:12.955091
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 08:56:18.495427
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 08:56:25.639383
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 08:56:31.145450
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 08:56:36.983506
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 08:56:42.466462
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 08:56:48.790708
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 08:56:56.322152
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 08:57:01.958092
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 08:57:08.927382
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 08:57:14.515390
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 08:57:22.079275
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 08:57:27.720040
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 08:57:33.782592
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 08:57:39.354497
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 08:57:45.769408
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 08:57:51.817895
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 08:57:57.570907
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 08:58:05.948044
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 08:58:11.782368
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 08:58:21.255512
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 08:58:26.996297
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 08:58:33.295291
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 08:58:39.058278
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 08:58:46.419714
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 08:58:52.448320
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 08:58:58.499414
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 08:59:07.107094
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 08:59:13.194919
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 08:59:23.012280
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 08:59:29.066618
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 08:59:37.413773
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 08:59:43.478798
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 08:59:52.839086
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 09:00:01.505878
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 09:00:08.177865
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 09:00:20.542032
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 09:00:27.236549
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 09:00:41.851144
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 09:00:49.201647
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 09:00:56.924852
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 09:01:04.109648
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 09:01:14.145213
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 09:01:22.083625
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 09:01:30.071325
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 09:01:48.044495
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 09:01:56.135140
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 09:02:18.984829
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 09:02:26.927396
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 09:02:36.906968
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 09:02:44.901279
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 09:02:59.502771
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 09:03:10.132323
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 09:03:20.673819
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 09:03:40.889051
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 09:03:51.792595
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 09:04:17.271607
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 09:04:27.966940
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 09:04:42.436030
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 09:04:53.060485
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 09:05:16.923464
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 09:05:32.698689
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 09:05:48.179909
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 09:06:23.349520
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 09:06:39.042614
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 09:07:25.081249
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 09:07:40.732076
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 09:07:59.677355
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 09:08:15.570524
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 09:08:45.037196
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 09:09:10.692931
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 09:09:36.481463
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 09:10:40.911167
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 09:11:08.033005
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 09:12:32.992375
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 09:12:59.950912
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 09:13:32.327338
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 09:13:58.619800
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 09:14:51.789579
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 09:15:37.572013
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 09:16:24.010912
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 09:17:47.222555
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 09:18:33.771742
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 09:20:22.191088
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 09:21:08.605525
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 09:22:08.451461
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 09:22:56.223424
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 09:24:38.132549
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 09:26:04.611333
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 09:27:31.359088
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 09:30:11.619097
b'3 total processes killed (some possibly by mpiexec during cleanup)\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 09:30:20.824681
b'3 total processes killed (some possibly by mpiexec during cleanup)\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 09:30:29.774826
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 09:31:56.705550
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 09:33:32.780304
b'2 total processes killed (some possibly by mpiexec during cleanup)\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 09:33:41.462389
b'2 total processes killed (some possibly by mpiexec during cleanup)\n'

-----------------------------------------------------------------------------
Partition 8x2
-----------------------------------------------------------------------------
Pencil Default
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3809786] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3809786] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3809933] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3809933] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3810201] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3810201] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3810347] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3810347] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3810492] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3810492] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3810653] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3810653] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3810921] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3810921] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3811067] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3811067] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3811213] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3811213] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3811358] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3811358] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3811508] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3811508] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3811779] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3811779] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3811922] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3811922] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3812068] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3812068] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3812213] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3812213] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3812490] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3812490] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3812636] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3812636] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3812781] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3812781] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3812928] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3812928] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3813072] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3813072] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3813341] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3813341] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3813503] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3813503] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3813645] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3813645] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3813792] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3813792] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3814061] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3814061] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3814216] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3814216] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3814365] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3814365] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3814505] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3814505] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3814655] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3814655] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3814923] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3814923] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3815076] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3815076] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3815225] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3815225] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3815372] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3815372] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3815640] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3815640] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3815791] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3815791] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3815944] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3815944] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3816087] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3816087] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3816233] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3816233] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3816502] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3816502] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3816659] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3816659] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3816801] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3816801] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3816948] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3816948] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3817217] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3817217] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3817373] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3817373] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3817519] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3817519] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3817664] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3817664] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3817812] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3817812] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3818082] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3818082] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3818240] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3818240] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3818384] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3818384] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3818532] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3818532] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3818812] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3818812] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3818956] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3818956] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3819103] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3819103] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3819249] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3819249] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3819400] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3819400] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3819671] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3819671] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3819820] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3819820] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3819966] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3819966] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3820132] [[64069,0],0] ORTE_ERROR_LOG: Data unpack would read past end of buffer in file util/show_help.c at line 501
[uc2n481.localdomain:3820132] 14 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3820132] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3820403] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3820403] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3820558] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3820558] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3820707] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3820707] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3820849] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3820849] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3820997] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3820997] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3821266] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3821266] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3821429] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3821429] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3821578] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3821578] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3821737] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3821737] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3822010] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3822010] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3822166] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3822166] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3822315] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3822315] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3822461] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3822461] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3822607] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3822607] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3822890] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3822890] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3823060] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3823060] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3823205] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3823205] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3823370] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3823370] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3823640] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3823640] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3823785] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3823785] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3823945] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3823945] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3824092] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3824092] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3824239] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3824239] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3824525] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3824525] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3824716] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3824716] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3824861] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3824861] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3825056] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3825056] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3825327] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3825327] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3825483] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3825483] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3825633] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3825633] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3825781] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3825781] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3825946] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3825946] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3826231] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3826231] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3826436] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3826436] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3826600] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3826600] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3826796] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3826796] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3827069] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3827069] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3827230] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3827230] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3827384] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3827384] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3827546] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3827546] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3827719] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3827719] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3828007] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3828007] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3828275] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3828275] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3828441] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3828441] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3828687] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3828687] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3828985] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3828985] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3829152] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3829152] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3829317] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3829317] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481:3829549] *** An error occurred in MPI_Irecv
[uc2n481:3829549] *** reported by process [3745316865,2]
[uc2n481:3829549] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n481:3829549] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3829549] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3829549] ***    and potentially your MPI job)
[uc2n481.localdomain:3829532] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3829532] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3829532] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481:3829695] *** An error occurred in MPI_Irecv
[uc2n481:3829695] *** reported by process [3750625281,1]
[uc2n481:3829695] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n481:3829695] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3829695] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3829695] ***    and potentially your MPI job)
[uc2n481.localdomain:3829679] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3829679] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3829679] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3829837] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3829837] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481:3830281] *** An error occurred in MPI_Alltoallv
[uc2n481:3830281] *** reported by process [3252027393,2]
[uc2n481:3830281] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n481:3830281] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3830281] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3830281] ***    and potentially your MPI job)
[uc2n481.localdomain:3830263] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3830263] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3830263] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3830421] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3830421] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481:3830796] *** An error occurred in MPI_Irecv
[uc2n481:3830796] *** reported by process [3285909505,2]
[uc2n481:3830796] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n481:3830796] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3830796] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3830796] ***    and potentially your MPI job)
[uc2n481.localdomain:3830778] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3830778] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3830778] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481:3830943] *** An error occurred in MPI_Irecv
[uc2n481:3830943] *** reported by process [3299934209,1]
[uc2n481:3830943] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n481:3830943] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3830943] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3830943] ***    and potentially your MPI job)
[uc2n481.localdomain:3830928] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3830928] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3830928] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481:3831089] *** An error occurred in MPI_Irecv
[uc2n481:3831089] *** reported by process [3309109249,0]
[uc2n481:3831089] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n481:3831089] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3831089] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3831089] ***    and potentially your MPI job)
[uc2n481.localdomain:3831068] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3831068] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3831068] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481:3831250] *** An error occurred in MPI_Irecv
[uc2n481:3831250] *** reported by process [3315335169,3]
[uc2n481:3831250] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n481:3831250] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3831250] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3831250] ***    and potentially your MPI job)
[uc2n481.localdomain:3831229] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3831229] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3831229] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3831374] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3831374] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3831523] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3831523] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3831679] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3831679] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3831822] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3831822] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3831983] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3831983] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3832127] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3832127] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3832280] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3832280] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3832426] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3832426] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3832569] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3832569] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3832721] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3832721] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3832868] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3832868] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3833026] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3833026] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3833171] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3833171] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3833317] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3833317] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3833474] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3833474] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3833627] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3833627] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3833771] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3833771] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3833920] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3833920] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3834063] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3834063] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3834223] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3834223] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3834381] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3834381] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3834526] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3834526] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3834670] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3834670] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3834829] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3834829] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3834981] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3834981] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3835132] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3835132] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3835278] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3835278] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3835433] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3835433] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3835583] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3835583] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3835758] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3835758] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3835910] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3835910] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3836070] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3836070] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3836233] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3836233] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3836391] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3836391] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3836555] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3836555] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3836705] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3836705] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3836863] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3836863] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 3 with PID 0 on
node uc2n481 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3837014] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3837014] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 15 with PID 101628 on
node uc2n484 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3837172] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3837172] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3837401] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3837401] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 2 with PID 0 on
node uc2n481 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3837561] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3837561] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3837790] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3837790] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 2 with PID 0 on
node uc2n481 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3837948] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3837948] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 14 with PID 102575 on
node uc2n484 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3838095] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3838095] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 14 with PID 102728 on
node uc2n484 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3838257] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3838257] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 14 with PID 102895 on
node uc2n484 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128
2021-09-29 09:33:51.044481
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128
2021-09-29 09:33:57.569531
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128
2021-09-29 09:34:03.395787
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128
2021-09-29 09:34:11.254884
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128
2021-09-29 09:34:16.714367
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128
2021-09-29 09:34:22.920287
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128
2021-09-29 09:34:28.459367
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128
2021-09-29 09:34:33.976295
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128
2021-09-29 09:34:39.446523
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 256
2021-09-29 09:34:45.150714
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 256
2021-09-29 09:34:50.638963
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 256
2021-09-29 09:34:56.694703
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 256
2021-09-29 09:35:02.760071
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 256
2021-09-29 09:35:08.262276
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 256
2021-09-29 09:35:14.292115
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 256
2021-09-29 09:35:19.824209
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 256
2021-09-29 09:35:25.323825
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 256
2021-09-29 09:35:30.883297
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 256 -nz 256
2021-09-29 09:35:36.522703
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 256 -nz 256
2021-09-29 09:35:42.907327
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 256 -nz 256
2021-09-29 09:35:48.446315
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 256 -nz 256
2021-09-29 09:35:55.082598
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 256 -nz 256
2021-09-29 09:36:01.365225
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 256 -nz 256
2021-09-29 09:36:08.872022
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 256 -nz 256
2021-09-29 09:36:14.411725
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 256 -nz 256
2021-09-29 09:36:19.948833
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 256 -nz 256
2021-09-29 09:36:26.797914
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256
2021-09-29 09:36:32.458623
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256
2021-09-29 09:36:38.078852
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256
2021-09-29 09:36:43.692367
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256
2021-09-29 09:36:51.482157
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256
2021-09-29 09:37:00.760224
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256
2021-09-29 09:37:08.448612
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256
2021-09-29 09:37:14.135960
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256
2021-09-29 09:37:19.756364
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256
2021-09-29 09:37:25.339245
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 512
2021-09-29 09:37:34.840882
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 512
2021-09-29 09:37:40.515626
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 512
2021-09-29 09:37:46.191275
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 512
2021-09-29 09:37:54.248425
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 512
2021-09-29 09:37:59.901613
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 512
2021-09-29 09:38:10.891270
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 512
2021-09-29 09:38:16.832390
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 512
2021-09-29 09:38:22.559700
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 512
2021-09-29 09:38:28.229956
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 512 -nz 512
2021-09-29 09:38:33.964367
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 512 -nz 512
2021-09-29 09:38:42.083485
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 512 -nz 512
2021-09-29 09:38:48.095775
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 512 -nz 512
2021-09-29 09:38:58.953990
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 512 -nz 512
2021-09-29 09:39:04.862223
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 512 -nz 512
2021-09-29 09:39:15.074887
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 512 -nz 512
2021-09-29 09:39:24.803882
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 512 -nz 512
2021-09-29 09:39:30.676406
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 512 -nz 512
2021-09-29 09:39:36.545095
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512
2021-09-29 09:39:44.023715
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512
2021-09-29 09:39:50.668541
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512
2021-09-29 09:39:56.926838
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512
2021-09-29 09:40:12.572067
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512
2021-09-29 09:40:18.866930
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512
2021-09-29 09:40:34.844559
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512
2021-09-29 09:40:43.034136
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512
2021-09-29 09:40:49.620930
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512
2021-09-29 09:40:55.895083
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 1024
2021-09-29 09:41:02.456566
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 1024
2021-09-29 09:41:09.425639
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 1024
2021-09-29 09:41:16.515808
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 1024
2021-09-29 09:41:34.992323
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 1024
2021-09-29 09:41:45.381342
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 1024
2021-09-29 09:42:02.013223
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 1024
2021-09-29 09:42:09.714835
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 1024
2021-09-29 09:42:19.722360
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 1024
2021-09-29 09:42:26.732120
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 09:42:34.282661
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 09:42:43.141493
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 09:42:55.403966
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 09:43:25.972377
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 09:43:34.480531
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 09:44:02.034689
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 09:44:10.437480
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 09:44:19.119307
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 09:44:27.555115
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 09:44:37.155613
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 09:44:48.462231
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 09:44:59.735034
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 09:45:54.919716
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 09:46:06.383918
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 09:46:55.609814
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 09:47:10.243275
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 09:47:22.336312
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 09:47:33.775373
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 09:47:47.434200
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 09:48:04.428415
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 09:48:21.205915
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 09:49:37.009589
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 09:49:53.916276
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 09:50:57.108836
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 09:51:13.932627
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 09:51:32.044131
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 09:51:49.385967
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 09:52:10.926885
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 09:52:39.230165
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 09:53:07.365772
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 09:55:32.954473
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 09:56:01.291472
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 09:58:02.143190
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 09:58:30.321170
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 09:59:01.942550
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 09:59:30.720793
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 10:00:08.273288
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 10:00:16.803601
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 10:00:27.654297
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 10:05:19.523479
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 10:05:27.658511
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 10:09:31.466316
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 10:09:40.252521
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 10:09:46.070850
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 10:09:52.061895
b''

Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 10:09:58.181931
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 10:10:06.809624
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 10:10:12.484535
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 10:10:18.207056
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 10:10:23.857668
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 10:10:29.605793
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 10:10:35.415496
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 10:10:41.139130
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 10:10:46.804470
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 10:10:52.583934
b'Result (avg): 5.01735e-09\nResult (max): 5.42241e-08\n'

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 10:10:58.419203
b'Result (avg): 5.01735e-09\nResult (max): 5.42241e-08\n'

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 10:11:04.326809
b'Result (avg): 5.01735e-09\nResult (max): 5.42241e-08\n'

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 10:11:10.693367
b'Result (avg): 5.01735e-09\nResult (max): 5.42241e-08\n'

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 10:11:19.871206
b'Result (avg): 5.01735e-09\nResult (max): 5.42241e-08\n'

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 10:11:26.276832
b'Result (avg): 5.01735e-09\nResult (max): 5.42241e-08\n'

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 10:11:32.083416
b'Result (avg): 5.01735e-09\nResult (max): 5.42241e-08\n'

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 10:11:37.898540
b'Result (avg): 5.01735e-09\nResult (max): 5.42241e-08\n'

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 10:11:43.686686
b'Result (avg): 5.01735e-09\nResult (max): 5.42241e-08\n'

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 10:11:49.519527
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 10:11:56.484301
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 10:12:03.494261
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 10:12:11.106026
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 10:12:18.147480
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 10:12:29.038137
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 10:12:36.067012
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 10:12:43.111511
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 10:12:50.161613
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 10:12:57.172122
b'Result (avg): 7.38396e-07\nResult (max): 9.23959e-06\n'

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 10:13:13.857529
b'Result (avg): 7.38396e-07\nResult (max): 9.23959e-06\n'

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 10:13:30.385815
b'Result (avg): 7.38396e-07\nResult (max): 9.23959e-06\n'

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 10:13:50.677186
b'Result (avg): 7.38396e-07\nResult (max): 9.23959e-06\n'

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 10:14:07.349343
b'Result (avg): 7.38396e-07\nResult (max): 9.23959e-06\n'

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 10:14:26.224807
b'Result (avg): 7.38396e-07\nResult (max): 9.23959e-06\n'

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 10:14:42.811011
b'Result (avg): 7.38396e-07\nResult (max): 9.23959e-06\n'

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 10:14:59.692762
b'Result (avg): 7.38396e-07\nResult (max): 9.23959e-06\n'

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 10:15:16.301650
b'Result (avg): 7.38396e-07\nResult (max): 9.23959e-06\n'

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 10:15:32.758452
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 10:15:44.855425
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 10:16:00.610794
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 10:17:50.263658
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 10:18:02.129638
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 10:19:48.054894
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 10:19:59.897340
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 10:20:12.698604
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 10:20:26.208241
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3838405] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3838405] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3838554] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3838554] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3838698] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3838698] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n483
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3838858] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3838858] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3839005] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3839005] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3839149] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3839149] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3839293] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3839293] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3839449] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3839449] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3839592] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3839592] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3839736] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3839736] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3839883] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3839883] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3840027] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3840027] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3840182] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3840182] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3840328] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3840328] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3840475] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3840475] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3840620] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3840620] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3840764] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3840764] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3840927] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3840927] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3841071] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3841071] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3841216] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3841216] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3841364] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3841364] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3841517] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3841517] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3841664] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3841664] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3841808] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3841808] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3841952] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3841952] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3842098] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3842098] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3842255] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3842255] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3842402] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3842402] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3842548] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3842548] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3842693] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3842693] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3842852] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3842852] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3842996] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3842996] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3843141] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3843141] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3843287] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3843287] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3843444] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3843444] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3843588] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3843588] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3843735] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3843735] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3843882] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3843882] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3844035] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3844035] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3844181] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3844181] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3844326] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3844326] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3844473] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3844473] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3844632] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3844632] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3844777] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3844777] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3844924] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3844924] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3845082] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3845082] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3845226] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3845226] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3845371] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3845371] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3845518] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3845518] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3845672] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3845672] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3845819] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3845819] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3845964] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3845964] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3846132] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3846132] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3846274] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3846274] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3846436] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3846436] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3846582] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3846582] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3846727] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3846727] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3846876] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3846876] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3847031] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3847031] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3847179] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3847179] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3847325] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3847325] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3847494] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3847494] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3847640] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3847640] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3847803] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3847803] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3847948] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3847948] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3848095] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3848095] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3848252] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3848252] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3848398] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3848398] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3848548] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3848548] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3848710] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3848710] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3848876] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3848876] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3849023] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3849023] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3849196] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3849196] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3849356] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3849356] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3849503] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3849503] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3849652] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3849652] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3849809] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3849809] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3849959] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3849959] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3850116] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3850116] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3850308] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3850308] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3850453] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3850453] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3850656] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3850656] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3850812] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3850812] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3850959] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3850959] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3851121] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3851121] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3851268] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3851268] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3851445] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3851445] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3851604] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3851604] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3851804] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3851804] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3851954] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3851954] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3852167] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3852167] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3852317] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3852317] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3852476] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3852476] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3852644] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3852644] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3852814] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3852814] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3853004] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3853004] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3853155] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3853155] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3853405] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3853405] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3853562] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3853562] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3853811] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3853811] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3853996] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3853996] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3854160] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3854160] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3854342] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3854342] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3854517] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3854517] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3854747] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3854747] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3854918] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3854918] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3855250] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3855250] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3855415] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3855415] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481:3855802] *** An error occurred in MPI_Irecv
[uc2n481:3855802] *** reported by process [1703542785,0]
[uc2n481:3855802] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n481:3855802] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3855802] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3855802] ***    and potentially your MPI job)
[uc2n481.localdomain:3855787] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3855787] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3855787] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481:3855945] *** An error occurred in MPI_Irecv
[uc2n481:3855945] *** reported by process [1712783361,0]
[uc2n481:3855945] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n481:3855945] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3855945] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3855945] ***    and potentially your MPI job)
[uc2n481.localdomain:3855926] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3855926] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3855926] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n483:589532] *** An error occurred in MPI_Isend
[uc2n483:589532] *** reported by process [1727070209,9]
[uc2n483:589532] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n483:589532] *** MPI_ERR_COUNT: invalid count argument
[uc2n483:589532] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n483:589532] ***    and potentially your MPI job)
[uc2n481.localdomain:3856080] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3856080] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3856080] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481:3856253] *** An error occurred in MPI_Alltoallv
[uc2n481:3856253] *** reported by process [1733230593,0]
[uc2n481:3856253] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n481:3856253] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3856253] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3856253] ***    and potentially your MPI job)
[uc2n481.localdomain:3856238] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3856238] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3856238] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n484:121425] *** An error occurred in MPI_Alltoallw
[uc2n484:121425] *** reported by process [1747124225,15]
[uc2n484:121425] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n484:121425] *** MPI_ERR_COUNT: invalid count argument
[uc2n484:121425] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n484:121425] ***    and potentially your MPI job)
[uc2n481.localdomain:3856386] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3856386] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3856386] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481:3856547] *** An error occurred in MPI_Irecv
[uc2n481:3856547] *** reported by process [1756561409,1]
[uc2n481:3856547] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n481:3856547] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3856547] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3856547] ***    and potentially your MPI job)
[uc2n481.localdomain:3856530] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3856530] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3856530] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481:3856691] *** An error occurred in MPI_Irecv
[uc2n481:3856691] *** reported by process [1761869825,0]
[uc2n481:3856691] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n481:3856691] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3856691] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3856691] ***    and potentially your MPI job)
[uc2n481.localdomain:3856677] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3856677] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3856677] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481:3856847] *** An error occurred in MPI_Irecv
[uc2n481:3856847] *** reported by process [1771765761,1]
[uc2n481:3856847] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n481:3856847] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3856847] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3856847] ***    and potentially your MPI job)
[uc2n481.localdomain:3856826] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3856826] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3856826] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481:3856995] *** An error occurred in MPI_Irecv
[uc2n481:3856995] *** reported by process [1785921537,1]
[uc2n481:3856995] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n481:3856995] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3856995] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3856995] ***    and potentially your MPI job)
[uc2n481.localdomain:3856978] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3856978] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481.localdomain:3856978] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3857118] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3857118] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3857272] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3857272] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3857424] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3857424] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3857579] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3857579] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3857766] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3857766] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3857909] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3857909] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3858063] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3858063] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3858209] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3858209] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3858368] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3858368] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3858512] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3858512] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3858657] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3858657] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3858812] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3858812] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3858966] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3858966] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3859111] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3859111] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3859255] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3859255] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3859408] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3859408] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3859552] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3859552] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3859707] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3859707] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3859856] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3859856] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3860001] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3860001] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3860154] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3860154] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3860315] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3860315] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3860463] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3860463] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3860610] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3860610] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3860761] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3860761] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3860917] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3860917] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3861060] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3861060] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3861209] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3861209] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3861369] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3861369] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3861527] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3861527] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3861692] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3861692] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3861854] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3861854] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3862008] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3862008] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3862173] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3862173] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3862326] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3862326] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3862491] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3862491] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3862653] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3862653] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481:3862671] *** An error occurred in MPI_Irecv
[uc2n481:3862671] *** reported by process [1079771137,3]
[uc2n481:3862671] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n481:3862671] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3862671] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3862671] ***    and potentially your MPI job)
[uc2n481.localdomain:3862653] 1 more process has sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3862858] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3862858] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481:3862876] *** An error occurred in MPI_Irecv
[uc2n481:3862876] *** reported by process [1097531393,3]
[uc2n481:3862876] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n481:3862876] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3862876] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3862876] ***    and potentially your MPI job)
[uc2n481.localdomain:3862858] 1 more process has sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3863074] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3863074] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481:3863097] *** An error occurred in MPI_Isend
[uc2n481:3863097] *** reported by process [1107492865,3]
[uc2n481:3863097] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n481:3863097] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3863097] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3863097] ***    and potentially your MPI job)
[uc2n481.localdomain:3863074] 2 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3863289] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3863289] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481:3863310] *** An error occurred in MPI_Alltoallv
[uc2n481:3863310] *** reported by process [1121452033,3]
[uc2n481:3863310] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n481:3863310] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3863310] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3863310] ***    and potentially your MPI job)
[uc2n481.localdomain:3863289] 3 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3863509] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3863509] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481:3863533] *** An error occurred in MPI_Alltoallw
[uc2n481:3863533] *** reported by process [1140064257,3]
[uc2n481:3863533] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n481:3863533] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3863533] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3863533] ***    and potentially your MPI job)
[uc2n481.localdomain:3863509] 3 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3863712] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3863712] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481:3863746] *** An error occurred in MPI_Irecv
[uc2n481:3863746] *** reported by process [1149304833,3]
[uc2n481:3863746] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n481:3863746] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3863746] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3863746] ***    and potentially your MPI job)
[uc2n481.localdomain:3863712] 2 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3863930] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3863930] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481:3863950] *** An error occurred in MPI_Irecv
[uc2n481:3863950] *** reported by process [1163591681,3]
[uc2n481:3863950] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n481:3863950] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3863950] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3863950] ***    and potentially your MPI job)
[uc2n481.localdomain:3863930] 1 more process has sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3864144] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3864144] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481:3864164] *** An error occurred in MPI_Irecv
[uc2n481:3864164] *** reported by process [1181810689,1]
[uc2n481:3864164] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n481:3864164] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3864164] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3864164] ***    and potentially your MPI job)
[uc2n481.localdomain:3864144] 1 more process has sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3864362] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3864362] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481:3864382] *** An error occurred in MPI_Irecv
[uc2n481:3864382] *** reported by process [1191903233,3]
[uc2n481:3864382] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n481:3864382] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3864382] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3864382] ***    and potentially your MPI job)
[uc2n481.localdomain:3864362] 3 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 10:20:38.602584
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 10:20:46.398144
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 10:20:51.841408
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 10:21:00.402918
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 10:21:06.232494
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 10:21:12.953999
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 10:21:18.940693
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 10:21:25.283997
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 10:21:30.868996
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 10:21:37.365717
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 10:21:42.814098
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 10:21:48.300308
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 10:21:54.549460
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 10:22:00.520418
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 10:22:07.004712
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 10:22:13.084656
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 10:22:20.668814
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 10:22:26.615832
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 10:22:34.321598
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 10:22:40.387186
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 10:22:46.472664
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 10:22:53.183658
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 10:22:59.255270
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 10:23:05.756894
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 10:23:11.926120
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 10:23:21.171041
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 10:23:27.023028
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 10:23:36.681003
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 10:23:42.703385
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 10:23:48.827117
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 10:23:55.369382
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 10:24:01.357503
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 10:24:08.308174
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 10:24:14.336300
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 10:24:23.774668
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 10:24:29.882937
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 10:24:39.618804
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 10:24:46.239734
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 10:24:52.635795
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 10:24:59.654524
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 10:25:05.849472
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 10:25:17.284721
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 10:25:24.260501
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 10:25:36.470035
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 10:25:42.641478
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 10:25:55.647560
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 10:26:02.711807
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 10:26:09.227429
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 10:26:16.502182
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 10:26:22.834526
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 10:26:31.355806
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 10:26:37.476686
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 10:26:56.118150
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 10:27:03.041201
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 10:27:24.157620
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 10:27:30.917038
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 10:27:38.133070
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 10:27:46.928426
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 10:27:55.365808
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 10:28:06.477479
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 10:28:13.191598
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 10:28:32.829693
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 10:28:39.514417
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 10:29:00.721017
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 10:29:08.055494
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 10:29:15.400214
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 10:29:27.090528
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 10:29:34.712442
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 10:29:50.682805
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 10:29:59.317097
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 10:30:32.545493
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 10:30:39.936251
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 10:31:16.048314
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 10:31:24.851526
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 10:31:33.570797
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 10:31:47.410863
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 10:31:56.406498
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 10:32:16.218746
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 10:32:24.943898
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 10:33:24.368060
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 10:33:33.124002
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 10:34:43.302520
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 10:34:55.015027
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 10:35:06.599409
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 10:35:28.541773
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 10:35:40.772917
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 10:36:17.639549
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 10:36:29.256481
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 10:37:33.451758
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 10:37:45.170368
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 10:38:59.065300
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 10:39:16.346029
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 10:39:33.641027
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 10:40:11.429124
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 10:40:29.562612
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 10:41:30.627228
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 10:41:47.855041
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 10:43:47.926840
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 10:44:06.055362
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 10:46:23.194376
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 10:46:55.137489
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 10:47:24.094932
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 10:48:22.467744
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 10:48:53.403207
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 10:50:26.909561
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 10:50:55.836184
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 10:54:45.915506
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 10:55:15.457923
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 10:59:33.886720
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 10:59:39.398231
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 10:59:47.949708
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 10:59:56.666549
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 11:00:04.223728
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 11:00:12.781416
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 11:00:20.338576
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 11:00:25.070986
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 11:00:33.535431
b''

Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 11:00:38.279848
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 11:00:47.292600
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 11:00:53.458345
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 11:00:59.666058
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 11:01:06.024384
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 11:01:12.186143
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 11:01:18.301009
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 11:01:24.469386
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 11:01:30.669063
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 11:01:36.900174
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 11:01:43.192640
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 11:01:49.552147
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 11:01:55.898251
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 11:02:02.232191
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 11:02:08.646753
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 11:02:15.152847
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 11:02:21.695730
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 11:02:28.088859
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 11:02:34.793618
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 11:02:42.187204
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 11:02:49.545576
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 11:02:57.786025
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 11:03:05.201541
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 11:03:14.260584
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 11:03:21.638681
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 11:03:29.742387
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 11:03:37.540850
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 11:03:45.605062
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 11:04:05.537507
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 11:04:22.559387
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 11:04:40.048413
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 11:04:57.069013
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 11:05:15.528903
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 11:05:32.403302
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 11:05:51.404818
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 11:06:08.333393
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 11:06:27.773181
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 11:07:44.780883
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 11:09:08.544526
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 11:10:32.801861
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 11:11:56.379298
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 11:13:20.095119
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 11:14:43.748791
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 11:16:07.413218
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 11:17:32.281743
b''

Pencil Default Inverse
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3864583] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3864583] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3864732] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3864732] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3865000] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3865000] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3865144] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3865144] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3865305] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3865305] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3865449] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3865449] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3865599] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3865599] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3865742] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3865742] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3865896] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3865896] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3866041] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3866041] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3866185] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3866185] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3866459] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3866459] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3866601] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3866601] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3866757] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3866757] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3866904] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3866904] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3867046] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3867046] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3867195] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3867195] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3867338] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3867338] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3867496] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3867496] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3867645] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3867645] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3867911] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3867911] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3868057] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3868057] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3868201] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3868201] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3868356] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3868356] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3868501] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3868501] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3868644] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3868644] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3868792] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3868792] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3868939] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3868939] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3869093] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3869093] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3869362] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3869362] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3869507] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3869507] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3869653] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3869653] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3869816] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3869816] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3869960] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3869960] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3870108] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3870108] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3870253] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3870253] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3870407] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3870407] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3870554] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3870554] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3870822] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3870822] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3870967] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3870967] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3871123] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3871123] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3871271] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3871271] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3871415] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3871415] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3871562] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3871562] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3871708] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3871708] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3871866] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3871866] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3872011] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3872011] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3872278] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3872278] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3872425] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3872425] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3872582] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3872582] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3872729] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3872729] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3872878] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3872878] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3873021] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3873021] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3873175] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3873175] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3873322] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3873322] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3873465] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3873465] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3873737] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3873737] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3873902] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3873902] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3874043] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3874043] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3874195] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3874195] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3874349] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3874349] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3874495] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3874495] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3874641] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3874641] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3874783] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3874783] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3874943] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3874943] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3875212] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3875212] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3875366] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3875366] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3875525] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3875525] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3875676] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3875676] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3875831] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3875831] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3875978] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3875978] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3876126] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3876126] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3876271] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3876271] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3876428] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3876428] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3876699] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3876699] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3876872] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3876872] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3877020] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3877020] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3877186] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3877186] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3877342] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3877342] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3877492] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3877492] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3877639] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3877639] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3877786] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3877786] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3877947] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3877947] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3878218] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3878218] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3878408] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3878408] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3878565] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3878565] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3878747] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3878747] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3878904] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3878904] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3879051] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3879051] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3879202] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3879202] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3879364] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3879364] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3879524] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3879524] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3879804] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3879804] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3880017] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3880017] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3880168] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3880168] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3880375] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3880375] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3880528] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3880528] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3880687] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3880687] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3880835] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3880835] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3881005] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3881005] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3881171] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3881171] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3881461] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3881461] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3881732] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3881732] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3881897] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3881897] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3882148] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3882148] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3882312] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3882312] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3882479] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3882479] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3882645] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3882645] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3882815] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3882815] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n484:148430] *** An error occurred in MPI_Irecv
[uc2n484:148430] *** reported by process [2401173505,15]
[uc2n484:148430] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n484:148430] *** MPI_ERR_COUNT: invalid count argument
[uc2n484:148430] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n484:148430] ***    and potentially your MPI job)
[uc2n481.localdomain:3882815] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3882974] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3882974] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481:3882991] *** An error occurred in MPI_Irecv
[uc2n481:3882991] *** reported by process [2415788033,3]
[uc2n481:3882991] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n481:3882991] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3882991] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3882991] ***    and potentially your MPI job)
[uc2n481.localdomain:3882974] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3883119] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3883119] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3883557] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3883557] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481:3883577] *** An error occurred in MPI_Alltoallv
[uc2n481:3883577] *** reported by process [4060413953,3]
[uc2n481:3883577] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n481:3883577] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3883577] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3883577] ***    and potentially your MPI job)
[uc2n481.localdomain:3883557] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3883717] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3883717] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3884091] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3884091] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n482:721500] *** An error occurred in MPI_Irecv
[uc2n482:721500] *** reported by process [4095410177,5]
[uc2n482:721500] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n482:721500] *** MPI_ERR_COUNT: invalid count argument
[uc2n482:721500] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n482:721500] ***    and potentially your MPI job)
[uc2n481.localdomain:3884091] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3884241] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3884241] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n482:721658] *** An error occurred in MPI_Irecv
[uc2n482:721658] *** reported by process [4109434881,7]
[uc2n482:721658] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n482:721658] *** MPI_ERR_COUNT: invalid count argument
[uc2n482:721658] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n482:721658] ***    and potentially your MPI job)
[uc2n481.localdomain:3884241] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3884400] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3884400] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n483.localdomain:618478] CUDA: Error in cuMemcpy: res=1, dest=0x9dba771, src=0x14efbffe0700, size=131040
[uc2n483:618478] *** Process received signal ***
[uc2n483:618478] Signal: Aborted (6)
[uc2n483:618478] Signal code:  (-6)
[uc2n483:618478] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x14f431900dd0]
[uc2n483:618478] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x14f43156370f]
[uc2n483:618478] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x14f43154db25]
[uc2n483:618478] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x14f4304cd375]
[uc2n483:618478] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x14f4304c41e8]
[uc2n483:618478] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_openib_prepare_src+0x81)[0x14f43051f941]
[uc2n483:618478] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x14f43d47f22b]
[uc2n483:618478] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x14f43d48227c]
[uc2n483:618478] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda31f)[0x14f43052b31f]
[uc2n483:618478] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x14f43052c1a6]
[uc2n483:618478] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x14f4304b3a1b]
[uc2n483:618478] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x14f4304b9ef5]
[uc2n483:618478] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x14f43d2f68ea]
[uc2n483:618478] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x1db)[0x14f43d35b77b]
[uc2n483:618478] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x14f43d367702]
[uc2n483:618478] [15] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x14f43d30942b]
[uc2n483:618478] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE28All2All_Sync_SecondTransposeEPvb+0x47b)[0x14f447a4cd3b]
[uc2n483:618478] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x45e)[0x14f447a4966e]
[uc2n483:618478] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x14f447cab66e]
[uc2n483:618478] [19] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x14f447caa6af]
[uc2n483:618478] [20] pencil[0x40326b]
[uc2n483:618478] [21] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x14f43154f6a3]
[uc2n483:618478] [22] pencil[0x4035fe]
[uc2n483:618478] *** End of error message ***
[uc2n481.localdomain:3884417] CUDA: Error in cuMemcpy: res=1, dest=0x149210fea171, src=0x148db9fe0700, size=131040
[uc2n481:3884417] *** Process received signal ***
[uc2n481:3884417] Signal: Aborted (6)
[uc2n481:3884417] Signal code:  (-6)
[uc2n481:3884417] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x14922ac35dd0]
[uc2n481:3884417] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x14922a89870f]
[uc2n481:3884417] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x14922a882b25]
[uc2n481:3884417] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x149229802375]
[uc2n481:3884417] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x1492297f91e8]
[uc2n481:3884417] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_openib_prepare_src+0x81)[0x149229854941]
[uc2n481:3884417] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x1492367b422b]
[uc2n481:3884417] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x1492367b727c]
[uc2n481:3884417] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda31f)[0x14922986031f]
[uc2n481:3884417] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x1492298611a6]
[uc2n481:3884417] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x1492297e8a1b]
[uc2n481:3884417] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x1492297eeef5]
[uc2n481:3884417] [12] [uc2n481.localdomain:3884415] CUDA: Error in cuMemcpy: res=1, dest=0x14a40903d1f1, src=0x149fb3fe0700, size=131040
/opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x14923662b8ea]
[uc2n481:3884417] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x1db)[0x14923669077b]
[uc2n481:3884417] [14] [uc2n481:3884415] *** Process received signal ***
[uc2n481:3884415] Signal: Aborted (6)
[uc2n481:3884415] Signal code:  (-6)
/opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x14923669c702]
[uc2n481:3884417] [15] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x14923663e42b]
[uc2n481:3884417] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE28All2All_Sync_SecondTransposeEPvb+0x47b)[0x149240d81d3b]
[uc2n481:3884417] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x45e)[0x149240d7e66e]
[uc2n481:3884417] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x149240fe066e]
[uc2n481:3884417] [19] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x149240fdf6af]
[uc2n481:3884417] [20] pencil[0x40326b]
[uc2n481:3884417] [21] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x14922a8846a3]
[uc2n481:3884417] [22] pencil[0x4035fe]
[uc2n481:3884417] *** End of error message ***
[uc2n481:3884415] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x14a422c4fdd0]
[uc2n481:3884415] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x14a4228b270f]
[uc2n481:3884415] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x14a42289cb25]
[uc2n481:3884415] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x14a42181c375]
[uc2n481:3884415] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x14a4218131e8]
[uc2n481:3884415] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_openib_prepare_src+0x81)[0x14a42186e941]
[uc2n481:3884415] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x14a42e7ce22b]
[uc2n481:3884415] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x14a42e7d127c]
[uc2n481:3884415] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda31f)[0x14a42187a31f]
[uc2n481:3884415] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x14a42187b1a6]
[uc2n481:3884415] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x14a421802a1b]
[uc2n481:3884415] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x14a421808ef5]
[uc2n481:3884415] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x14a42e6458ea]
[uc2n481:3884415] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x1db)[0x14a42e6aa77b]
[uc2n481:3884415] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x14a42e6b6702]
[uc2n481:3884415] [15] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x14a42e65842b]
[uc2n481:3884415] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE28All2All_Sync_SecondTransposeEPvb+0x47b)[0x14a438d9bd3b]
[uc2n481:3884415] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x45e)[0x14a438d9866e]
[uc2n481:3884415] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x14a438ffa66e]
[uc2n481:3884415] [19] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x14a438ff96af]
[uc2n481:3884415] [20] pencil[0x40326b]
[uc2n481:3884415] [21] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x14a42289e6a3]
[uc2n481:3884415] [22] pencil[0x4035fe]
[uc2n481:3884415] *** End of error message ***
[uc2n483.localdomain:618476] CUDA: Error in cuMemcpy: res=1, dest=0x9ca46b1, src=0x14f7affe0700, size=131040
[uc2n483:618476] *** Process received signal ***
[uc2n483:618476] Signal: Aborted (6)
[uc2n483:618476] Signal code:  (-6)
[uc2n483:618476] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x14fc1d725dd0]
[uc2n483:618476] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x14fc1d38870f]
[uc2n483:618476] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x14fc1d372b25]
[uc2n483:618476] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x14fc1c2f2375]
[uc2n483:618476] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x14fc1c2e91e8]
[uc2n483:618476] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_openib_prepare_src+0x81)[0x14fc1c344941]
[uc2n483:618476] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x14fc292a422b]
[uc2n483:618476] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x14fc292a727c]
[uc2n483:618476] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda31f)[0x14fc1c35031f]
[uc2n483:618476] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x14fc1c3511a6]
[uc2n483:618476] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x14fc1c2d8a1b]
[uc2n483:618476] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x14fc1c2deef5]
[uc2n483:618476] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x14fc2911b8ea]
[uc2n483:618476] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x1db)[0x14fc2918077b]
[uc2n483:618476] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x14fc2918c702]
[uc2n483:618476] [15] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x14fc2912e42b]
[uc2n483:618476] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE28All2All_Sync_SecondTransposeEPvb+0x47b)[0x14fc33871d3b]
[uc2n483:618476] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x45e)[0x14fc3386e66e]
[uc2n483:618476] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x14fc33ad066e]
[uc2n483:618476] [19] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x14fc33acf6af]
[uc2n483:618476] [20] pencil[0x40326b]
[uc2n483:618476] [21] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x14fc1d3746a3]
[uc2n483:618476] [22] pencil[0x4035fe]
[uc2n483:618476] *** End of error message ***
[uc2n482.localdomain:721822] CUDA: Error in cuMemcpy: res=1, dest=0x14c8dcd86171, src=0x14c487fe0700, size=131040
[uc2n482:721822] *** Process received signal ***
[uc2n482:721822] Signal: Aborted (6)
[uc2n482:721822] Signal code:  (-6)
[uc2n482.localdomain:721820] CUDA: Error in cuMemcpy: res=1, dest=0x147334b8c171, src=0x146edffe0700, size=131040
[uc2n482:721820] *** Process received signal ***
[uc2n482:721820] Signal: Aborted (6)
[uc2n482:721820] Signal code:  (-6)
[uc2n482:721822] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x14c8f69f7dd0]
[uc2n482:721822] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x14c8f665a70f]
[uc2n482:721822] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x14c8f6644b25]
[uc2n482:721822] [ 3] [uc2n482:721820] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x14734e802dd0]
[uc2n482:721820] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x14734e46570f]
[uc2n482:721820] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x14734e44fb25]
[uc2n482:721820] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x14734d3cf375]
[uc2n482:721820] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x14734d3c61e8]
[uc2n482:721820] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x14c8f55c4375]
[uc2n482:721822] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x14c8f55bb1e8]
[uc2n482:721822] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_openib_prepare_src+0x81)[0x14c8f5616941]
[uc2n482:721822] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_openib_prepare_src+0x81)[0x14734d421941]
[uc2n482:721820] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x14c90257622b]
[uc2n482:721822] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x14735a38122b]
[uc2n482:721820] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x14735a38427c]
[uc2n482:721820] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x14c90257927c]
[uc2n482:721822] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda31f)[0x14734d42d31f]
[uc2n482:721820] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda31f)[0x14c8f562231f]
[uc2n482:721822] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x14c8f56231a6]
[uc2n482:721822] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x14734d42e1a6]
[uc2n482:721820] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x14734d3b5a1b]
[uc2n482:721820] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x14c8f55aaa1b]
[uc2n482:721822] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x14c8f55b0ef5]
[uc2n482:721822] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x14734d3bbef5]
[uc2n482:721820] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x14735a1f88ea]
[uc2n482:721820] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x14c9023ed8ea]
[uc2n482:721822] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x1db)[0x14735a25d77b]
[uc2n482:721820] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x1db)[0x14c90245277b]
[uc2n482:721822] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x14735a269702]
[uc2n482:721820] [15] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x14c90245e702]
[uc2n482:721822] [15] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x14735a20b42b]
[uc2n482:721820] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE28All2All_Sync_SecondTransposeEPvb+0x47b)[0x14736494ed3b]
/opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x14c90240042b]
[uc2n482:721822] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE28All2All_Sync_SecondTransposeEPvb+0x47b)[0x14c90cb43d3b]
[uc2n482:721822] [17] [uc2n482:721820] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x45e)[0x14736494b66e]
[uc2n482:721820] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x147364bad66e]
[uc2n482:721820] [19] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x147364bac6af]
[uc2n482:721820] [20] pencil[0x40326b]
[uc2n482:721820] [21] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x45e)[0x14c90cb4066e]
[uc2n482:721822] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x14c90cda266e]
[uc2n482:721822] [19] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x14c90cda16af]
[uc2n482:721822] [20] pencil[0x40326b]
[uc2n482:721822] [21] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x14734e4516a3]
[uc2n482:721820] [22] pencil[0x4035fe]
[uc2n482:721820] *** End of error message ***
/usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x14c8f66466a3]
[uc2n482:721822] [22] pencil[0x4035fe]
[uc2n482:721822] *** End of error message ***
[uc2n483:618477] *** An error occurred in MPI_Irecv
[uc2n483:618477] *** reported by process [4115660801,9]
[uc2n483:618477] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n483:618477] *** MPI_ERR_COUNT: invalid count argument
[uc2n483:618477] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n483:618477] ***    and potentially your MPI job)
--------------------------------------------------------------------------
The call to cuMemcpyAsync failed. This is a unrecoverable error and will
cause the program to abort.
  cuMemcpyAsync(0x1529ac0ec1f8, 0x152563fe0700, 131040) returned value 1
Check the cuda.h file for what the return value means.
--------------------------------------------------------------------------
[uc2n484.localdomain:150032] CUDA: Error in cuMemcpy: res=-1, dest=0x1529ac0ec1f8, src=0x152563fe0700, size=131040
[uc2n484:150032] *** Process received signal ***
[uc2n484:150032] Signal: Aborted (6)
[uc2n484:150032] Signal code:  (-6)
[uc2n484:150032] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x1529d3826dd0]
[uc2n484:150032] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x1529d348970f]
[uc2n484:150032] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x1529d3473b25]
[uc2n484:150032] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x1529d23f3375]
[uc2n484:150032] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x1529d23ea1e8]
[uc2n484:150032] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_smcuda_prepare_src+0x126)[0x1529d24420a6]
[uc2n484:150032] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x1529df3a522b]
[uc2n484:150032] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x1529df3a827c]
[uc2n484:150032] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_smcuda_component_progress+0x507)[0x1529d24444c7]
[uc2n484:150032] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x1529d23d9a1b]
[uc2n484:150032] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x1529d23dfef5]
[uc2n484:150032] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x1529df21c8ea]
[uc2n484:150032] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x1db)[0x1529df28177b]
[uc2n484:150032] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x1529df28d702]
[uc2n484:150032] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x1529df22f42b]
[uc2n484:150032] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE28All2All_Sync_SecondTransposeEPvb+0x47b)[0x1529e9972d3b]
[uc2n484:150032] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x45e)[0x1529e996f66e]
[uc2n484:150032] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x1529e9bd166e]
[uc2n484:150032] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x1529e9bd06af]
[uc2n484:150032] [19] pencil[0x40326b]
[uc2n484:150032] [20] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x1529d34756a3]
[uc2n484:150032] [21] pencil[0x4035fe]
[uc2n484:150032] *** End of error message ***
[uc2n481.localdomain:3884400] 7 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3884567] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3884567] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n482.localdomain:721997] CUDA: Error in cuMemcpy: res=1, dest=0xa7307f1, src=0x14c217fe0700, size=131040
[uc2n482:721997] *** Process received signal ***
[uc2n482:721997] Signal: Aborted (6)
[uc2n482:721997] Signal code:  (-6)
[uc2n482:721997] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x14c686344dd0]
[uc2n482:721997] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x14c685fa770f]
[uc2n482:721997] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x14c685f91b25]
[uc2n482:721997] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x14c684f11375]
[uc2n482:721997] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x14c684f081e8]
[uc2n482:721997] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_openib_prepare_src+0x81)[0x14c684f63941]
[uc2n482:721997] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x14c691ec322b]
[uc2n482:721997] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x14c691ec627c]
[uc2n482:721997] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda31f)[0x14c684f6f31f]
[uc2n482:721997] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x14c684f701a6]
[uc2n482:721997] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x14c684ef7a1b]
[uc2n482:721997] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x14c684efdef5]
[uc2n482:721997] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x14c691d3a8ea]
[uc2n482:721997] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_coll_basic_alltoallw_intra+0x252)[0x14c691ddeb32]
[uc2n482:721997] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallw+0x1eb)[0x14c691d4dccb]
[uc2n482:721997] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE31All2All_MPIType_SecondTransposeEPvb+0x393)[0x14c69c491443]
[uc2n482:721997] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x45e)[0x14c69c48d66e]
[uc2n482:721997] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x14c69c6ef66e]
[uc2n482:721997] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x14c69c6ee6af]
[uc2n482:721997] [19] pencil[0x40326b]
[uc2n482:721997] [20] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x14c685f936a3]
[uc2n482:721997] [21] pencil[0x4035fe]
[uc2n482:721997] *** End of error message ***
[uc2n481.localdomain:3884586] CUDA: Error in cuMemcpy: res=1, dest=0x155369e2c0b1, src=0x154f15fe0700, size=131040
[uc2n481:3884586] *** Process received signal ***
[uc2n481:3884586] Signal: Aborted (6)
[uc2n481:3884586] Signal code:  (-6)
[uc2n481:3884586] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x155383adadd0]
[uc2n481:3884586] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x15538373d70f]
[uc2n481:3884586] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x155383727b25]
[uc2n481:3884586] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x1553826a7375]
[uc2n481:3884586] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x15538269e1e8]
[uc2n481:3884586] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_openib_prepare_src+0x81)[0x1553826f9941]
[uc2n481:3884586] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x15538f65922b]
[uc2n481:3884586] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x15538f65c27c]
[uc2n481:3884586] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda31f)[0x15538270531f]
[uc2n481:3884586] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x1553827061a6]
[uc2n481:3884586] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x15538268da1b]
[uc2n481:3884586] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x155382693ef5]
[uc2n481:3884586] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x15538f4d08ea]
[uc2n481:3884586] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_coll_basic_alltoallw_intra+0x252)[0x15538f574b32]
[uc2n481:3884586] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallw+0x1eb)[0x15538f4e3ccb]
[uc2n481:3884586] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE31All2All_MPIType_SecondTransposeEPvb+0x393)[0x155399c27443]
[uc2n481:3884586] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x45e)[0x155399c2366e]
[uc2n481:3884586] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x155399e8566e]
[uc2n481:3884586] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x155399e846af]
[uc2n481:3884586] [19] pencil[0x40326b]
[uc2n481:3884586] [20] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x1553837296a3]
[uc2n481:3884586] [21] pencil[0x4035fe]
[uc2n481:3884586] *** End of error message ***
[uc2n481.localdomain:3884584] CUDA: Error in cuMemcpy: res=1, dest=0x15081559e031, src=0x1503bffe0700, size=131040
[uc2n481:3884584] *** Process received signal ***
[uc2n481:3884584] Signal: Aborted (6)
[uc2n481:3884584] Signal code:  (-6)
[uc2n481:3884584] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x15082f2c4dd0]
[uc2n481:3884584] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x15082ef2770f]
[uc2n481:3884584] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x15082ef11b25]
[uc2n481:3884584] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x15082de91375]
[uc2n481:3884584] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x15082de881e8]
[uc2n481:3884584] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_openib_prepare_src+0x81)[0x15082dee3941]
[uc2n481:3884584] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x15083ae4322b]
[uc2n481:3884584] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x15083ae4627c]
[uc2n481:3884584] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda31f)[0x15082deef31f]
[uc2n481:3884584] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x15082def01a6]
[uc2n481:3884584] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x15082de77a1b]
[uc2n481:3884584] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x15082de7def5]
[uc2n481:3884584] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x15083acba8ea]
[uc2n481:3884584] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_coll_basic_alltoallw_intra+0x252)[0x15083ad5eb32]
[uc2n481:3884584] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallw+0x1eb)[0x15083accdccb]
[uc2n481:3884584] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE31All2All_MPIType_SecondTransposeEPvb+0x393)[0x150845411443]
[uc2n481:3884584] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x45e)[0x15084540d66e]
[uc2n481:3884584] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x15084566f66e]
[uc2n481:3884584] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x15084566e6af]
[uc2n481:3884584] [19] pencil[0x40326b]
[uc2n481:3884584] [20] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x15082ef136a3]
[uc2n481:3884584] [21] pencil[0x4035fe]
[uc2n481:3884584] *** End of error message ***
[uc2n482.localdomain:721995] CUDA: Error in cuMemcpy: res=1, dest=0x14b34c0f51b1, src=0x14aeeffe0700, size=131040
[uc2n482:721995] *** Process received signal ***
[uc2n482:721995] Signal: Aborted (6)
[uc2n482:721995] Signal code:  (-6)
[uc2n482:721995] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x14b35fbb0dd0]
[uc2n482:721995] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x14b35f81370f]
[uc2n482:721995] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x14b35f7fdb25]
[uc2n482:721995] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x14b35e77d375]
[uc2n482:721995] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x14b35e7741e8]
[uc2n482:721995] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_openib_prepare_src+0x81)[0x14b35e7cf941]
[uc2n482:721995] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x14b36b72f22b]
[uc2n482:721995] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x14b36b73227c]
[uc2n482:721995] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda31f)[0x14b35e7db31f]
[uc2n482:721995] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x14b35e7dc1a6]
[uc2n482:721995] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x14b35e763a1b]
[uc2n482:721995] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x14b35e769ef5]
[uc2n482:721995] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x14b36b5a68ea]
[uc2n482:721995] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_coll_basic_alltoallw_intra+0x252)[0x14b36b64ab32]
[uc2n482:721995] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallw+0x1eb)[0x14b36b5b9ccb]
[uc2n482:721995] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE31All2All_MPIType_SecondTransposeEPvb+0x393)[0x14b375cfd443]
[uc2n482:721995] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x45e)[0x14b375cf966e]
[uc2n482:721995] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x14b375f5b66e]
[uc2n482:721995] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x14b375f5a6af]
[uc2n482:721995] [19] pencil[0x40326b]
[uc2n482:721995] [20] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x14b35f7ff6a3]
[uc2n482:721995] [21] pencil[0x4035fe]
[uc2n482:721995] *** End of error message ***
[uc2n483.localdomain:618663] CUDA: Error in cuMemcpy: res=1, dest=0x146c164c9071, src=0x1467bdfe0700, size=131040
[uc2n483:618663] *** Process received signal ***
[uc2n483:618663] Signal: Aborted (6)
[uc2n483:618663] Signal code:  (-6)
[uc2n483:618663] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x146c30236dd0]
[uc2n483:618663] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x146c2fe9970f]
[uc2n483:618663] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x146c2fe83b25]
[uc2n483:618663] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x146c2ee03375]
[uc2n483:618663] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x146c2edfa1e8]
[uc2n483:618663] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_openib_prepare_src+0x81)[0x146c2ee55941]
[uc2n483:618663] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x146c3bdb522b]
[uc2n483:618663] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x146c3bdb827c]
[uc2n483:618663] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda31f)[0x146c2ee6131f]
[uc2n483:618663] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x146c2ee621a6]
[uc2n483:618663] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x146c2ede9a1b]
[uc2n483:618663] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x146c2edefef5]
[uc2n483:618663] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x146c3bc2c8ea]
[uc2n483:618663] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_coll_basic_alltoallw_intra+0x252)[0x146c3bcd0b32]
[uc2n483:618663] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallw+0x1eb)[0x146c3bc3fccb]
[uc2n483:618663] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE31All2All_MPIType_SecondTransposeEPvb+0x393)[0x146c46383443]
[uc2n483:618663] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x45e)[0x146c4637f66e]
[uc2n483:618663] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x146c465e166e]
[uc2n483:618663] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x146c465e06af]
[uc2n483:618663] [19] pencil[0x40326b]
[uc2n483:618663] [20] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x146c2fe856a3]
[uc2n483:618663] [21] pencil[0x4035fe]
[uc2n483:618663] *** End of error message ***
[uc2n483.localdomain:618661] CUDA: Error in cuMemcpy: res=1, dest=0x14823d0ce0f1, src=0x147df7fe0700, size=131040
[uc2n483:618661] *** Process received signal ***
[uc2n483:618661] Signal: Aborted (6)
[uc2n483:618661] Signal code:  (-6)
[uc2n483:618661] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x148268d9fdd0]
[uc2n483:618661] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x148268a0270f]
[uc2n483:618661] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x1482689ecb25]
[uc2n483:618661] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x14826796c375]
[uc2n483:618661] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x1482679631e8]
[uc2n483:618661] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_openib_prepare_src+0x81)[0x1482679be941]
[uc2n483:618661] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x14827491e22b]
[uc2n483:618661] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x14827492127c]
[uc2n483:618661] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda31f)[0x1482679ca31f]
[uc2n483:618661] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x1482679cb1a6]
[uc2n483:618661] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x148267952a1b]
[uc2n483:618661] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x148267958ef5]
[uc2n483:618661] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x1482747958ea]
[uc2n483:618661] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_coll_basic_alltoallw_intra+0x252)[0x148274839b32]
[uc2n483:618661] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallw+0x1eb)[0x1482747a8ccb]
[uc2n483:618661] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE31All2All_MPIType_SecondTransposeEPvb+0x393)[0x14827eeec443]
[uc2n483:618661] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x45e)[0x14827eee866e]
[uc2n483:618661] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x14827f14a66e]
[uc2n483:618661] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x14827f1496af]
[uc2n483:618661] [19] pencil[0x40326b]
[uc2n483:618661] [20] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x1482689ee6a3]
[uc2n483:618661] [21] pencil[0x4035fe]
[uc2n483:618661] *** End of error message ***
[uc2n482:721996] *** An error occurred in MPI_Irecv
[uc2n482:721996] *** reported by process [4130799617,5]
[uc2n482:721996] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n482:721996] *** MPI_ERR_COUNT: invalid count argument
[uc2n482:721996] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n482:721996] ***    and potentially your MPI job)
--------------------------------------------------------------------------
The call to cuMemcpyAsync failed. This is a unrecoverable error and will
cause the program to abort.
  cuMemcpyAsync(0x145bd81f81f8, 0x14578ffe0700, 131040) returned value 1
Check the cuda.h file for what the return value means.
--------------------------------------------------------------------------
[uc2n484.localdomain:150197] CUDA: Error in cuMemcpy: res=-1, dest=0x145bd81f81f8, src=0x14578ffe0700, size=131040
[uc2n484:150197] *** Process received signal ***
[uc2n484:150197] Signal: Aborted (6)
[uc2n484:150197] Signal code:  (-6)
[uc2n484:150197] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x145bff071dd0]
[uc2n484:150197] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x145bfecd470f]
[uc2n484:150197] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x145bfecbeb25]
[uc2n484:150197] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x145bfdc3e375]
[uc2n484:150197] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x145bfdc351e8]
[uc2n484:150197] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_smcuda_prepare_src+0x126)[0x145bfdc8d0a6]
[uc2n484:150197] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x145c0abf022b]
[uc2n484:150197] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x145c0abf327c]
[uc2n484:150197] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_smcuda_component_progress+0x507)[0x145bfdc8f4c7]
[uc2n484:150197] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x145bfdc24a1b]
[uc2n484:150197] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x145bfdc2aef5]
[uc2n484:150197] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x145c0aa678ea]
[uc2n484:150197] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_coll_basic_alltoallw_intra+0x252)[0x145c0ab0bb32]
[uc2n484:150197] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallw+0x1eb)[0x145c0aa7accb]
[uc2n484:150197] [14] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE31All2All_MPIType_SecondTransposeEPvb+0x393)[0x145c151be443]
[uc2n484:150197] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x45e)[0x145c151ba66e]
[uc2n484:150197] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x145c1541c66e]
[uc2n484:150197] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu4/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x145c1541b6af]
[uc2n484:150197] [18] pencil[0x40326b]
[uc2n484:150197] [19] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x145bfecc06a3]
[uc2n484:150197] [20] pencil[0x4035fe]
[uc2n484:150197] *** End of error message ***
[uc2n481.localdomain:3884567] 7 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 11:18:56.131020
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 11:19:08.968610
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 11:19:14.997420
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 11:19:21.392662
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 11:19:31.877037
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 11:19:38.657419
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 11:19:44.603922
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 11:19:50.675196
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 11:19:56.718390
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 11:20:02.689994
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 11:20:08.698630
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 11:20:14.787867
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 11:20:21.312814
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 11:20:27.527876
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 11:20:33.947179
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 11:20:39.841966
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 11:20:45.900177
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 11:20:51.885946
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 11:20:57.846824
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 11:21:03.822982
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 11:21:09.907071
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 11:21:17.034005
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 11:21:23.065340
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 11:21:29.987457
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 11:21:35.961913
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 11:21:41.952595
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 11:21:48.043625
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 11:21:54.108226
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 11:22:00.145721
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 11:22:06.333194
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 11:22:14.388720
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 11:22:22.781775
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 11:22:30.757701
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 11:22:37.617048
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 11:22:43.784041
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 11:22:49.925068
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 11:22:56.081146
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 11:23:02.262881
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 11:23:08.731422
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 11:23:16.905664
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 11:23:26.471492
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 11:23:34.617633
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 11:23:41.037804
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 11:23:47.399340
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 11:23:53.671736
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 11:23:59.959033
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 11:24:06.317274
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 11:24:12.753538
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 11:24:23.263168
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 11:24:29.581892
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 11:24:39.777166
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 11:24:46.072105
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 11:24:52.517404
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 11:24:58.781488
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 11:25:05.299535
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 11:25:12.043033
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 11:25:18.771218
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 11:25:33.818492
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 11:25:40.630265
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 11:25:54.943592
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 11:26:01.774533
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 11:26:08.617600
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 11:26:15.401543
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 11:26:22.599643
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 11:26:30.175583
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 11:26:37.596615
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 11:26:55.573015
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 11:27:02.983085
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 11:27:20.205210
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 11:27:27.682729
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 11:27:35.439146
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 11:27:43.601424
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 11:27:52.292564
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 11:28:01.531626
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 11:28:12.739549
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 11:28:42.528794
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 11:28:51.377864
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 11:29:17.954972
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 11:29:26.843937
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 11:29:36.229182
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 11:29:45.055902
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 11:29:55.233577
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 11:30:07.287789
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 11:30:19.156403
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 11:31:14.910682
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 11:31:26.756370
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 11:32:15.322896
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 11:32:28.756124
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 11:32:42.857240
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 11:32:54.824243
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 11:33:09.574760
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 11:33:28.004311
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 11:33:46.498123
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 11:35:03.890496
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 11:35:22.226531
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 11:36:27.783167
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 11:36:45.335487
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 11:37:04.802688
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 11:37:22.308500
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 11:37:44.255375
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 11:38:13.241133
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 11:38:41.744610
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 11:41:13.475605
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 11:41:41.831437
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 11:43:44.966566
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 11:44:13.750459
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 11:44:45.178259
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 11:45:14.153939
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 11:45:51.851065
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 11:46:02.610638
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 11:46:12.377767
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 11:51:53.005308
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 11:52:04.501811
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 11:56:38.985071
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 11:56:51.551092
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 11:57:02.328806
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 11:57:10.787520
b''

--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3884735] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3884735] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3884891] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3884891] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3885162] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3885162] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3885304] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3885304] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3885453] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3885453] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3885600] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3885600] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3885880] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3885880] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3886025] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3886025] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3886169] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3886169] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3886314] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3886314] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3886477] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3886477] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3886749] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3886749] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3886893] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3886893] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3887043] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3887043] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3887189] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3887189] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3887473] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3887473] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3887616] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3887616] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3887761] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3887761] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3887910] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3887910] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3888067] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3888067] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3888336] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3888336] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3888484] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3888484] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3888627] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3888627] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3888785] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3888785] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3889056] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3889056] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3889201] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3889201] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3889346] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3889346] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3889490] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3889490] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3889647] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3889647] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3889917] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3889917] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3890062] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3890062] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3890207] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3890207] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3890362] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3890362] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3890675] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3890675] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3890818] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3890818] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3890964] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3890964] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3891110] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3891110] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3891269] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3891269] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3891539] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3891539] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3891687] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3891687] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3891832] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3891832] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3891986] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3891986] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3892254] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3892254] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3892399] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3892399] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3892546] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3892546] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3892705] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3892705] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3892850] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3892850] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3893120] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3893120] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3893266] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3893266] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3893429] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3893429] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3893572] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3893572] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3893843] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3893843] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3893998] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3893998] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3894145] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3894145] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3894293] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3894293] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3894438] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3894438] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3894715] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3894715] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3894862] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3894862] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3895009] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3895009] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3895170] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3895170] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3895441] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3895441] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3895592] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3895592] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3895737] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3895737] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3895894] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3895894] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3896039] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3896039] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3896309] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3896309] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3896466] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3896466] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3896611] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3896611] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3896775] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3896775] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3897045] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3897045] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3897193] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3897193] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3897350] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3897350] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3897504] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3897504] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3897659] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3897659] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3897931] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3897931] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3898079] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3898079] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3898238] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3898238] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3898393] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3898393] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3898672] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3898672] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3898826] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3898826] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3898988] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3898988] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3899159] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3899159] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3899307] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3899307] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3899590] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3899590] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3899744] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3899744] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3899901] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3899901] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3900072] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3900072] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3900345] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3900345] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3900510] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3900510] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3900665] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3900665] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3900843] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3900843] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3900992] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3900992] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3901274] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3901274] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3901443] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3901443] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3901607] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3901607] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3901799] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3901799] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3902075] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3902075] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3902262] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3902262] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3902422] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3902422] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3902622] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3902622] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3902785] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3902785] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3903077] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3903077] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3903259] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3903259] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3903424] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3903424] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n482
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3903642] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3903642] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3903937] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3903937] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3904158] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3904158] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3904324] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3904324] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3904589] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3904589] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n483:639088] *** An error occurred in MPI_Irecv
[uc2n483:639088] *** reported by process [611123201,11]
[uc2n483:639088] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n483:639088] *** MPI_ERR_COUNT: invalid count argument
[uc2n483:639088] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n483:639088] ***    and potentially your MPI job)
[uc2n481.localdomain:3904589] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3904734] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3904734] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n481:3904750] *** An error occurred in MPI_Irecv
[uc2n481:3904750] *** reported by process [620625921,1]
[uc2n481:3904750] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n481:3904750] *** MPI_ERR_COUNT: invalid count argument
[uc2n481:3904750] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n481:3904750] ***    and potentially your MPI job)
[uc2n481.localdomain:3904734] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3904888] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3904888] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n484:170937] *** An error occurred in MPI_Irecv
[uc2n484:170937] *** reported by process [626524161,13]
[uc2n484:170937] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n484:170937] *** MPI_ERR_COUNT: invalid count argument
[uc2n484:170937] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n484:170937] ***    and potentially your MPI job)
[uc2n481.localdomain:3904888] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3905044] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3905044] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n483:639558] *** An error occurred in MPI_Alltoallv
[uc2n483:639558] *** reported by process [640942081,8]
[uc2n483:639558] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n483:639558] *** MPI_ERR_COUNT: invalid count argument
[uc2n483:639558] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n483:639558] ***    and potentially your MPI job)
[uc2n481.localdomain:3905044] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3905190] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3905190] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n484:171240] *** An error occurred in MPI_Alltoallw
[uc2n484:171240] *** reported by process [646316033,15]
[uc2n484:171240] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n484:171240] *** MPI_ERR_COUNT: invalid count argument
[uc2n484:171240] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n484:171240] ***    and potentially your MPI job)
[uc2n481.localdomain:3905190] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3905339] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3905339] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n484:171405] *** An error occurred in MPI_Irecv
[uc2n484:171405] *** reported by process [656080897,12]
[uc2n484:171405] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n484:171405] *** MPI_ERR_COUNT: invalid count argument
[uc2n484:171405] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n484:171405] ***    and potentially your MPI job)
[uc2n481.localdomain:3905339] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n481.localdomain:3905507] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3905507] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n484:171565] *** An error occurred in MPI_Irecv
[uc2n484:171565] *** reported by process [667090945,15]
[uc2n484:171565] *** on communicator MPI COMMUNICATOR 3 SPLIT FROM 0
[uc2n484:171565] *** MPI_ERR_COUNT: invalid count argument
[uc2n484:171565] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n484:171565] ***    and potentially your MPI job)
[uc2n481.localdomain:3905507] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n484
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n483:640200:0:640200] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14afda000010)
[uc2n483:640199:0:640199] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x15184e500010)
[uc2n483:640197:0:640197] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1459d0400010)
[uc2n484:171712:0:171712] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14ba44000010)
[uc2n484:171713:0:171713] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14d43e700010)
[uc2n484:171711:0:171711] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x148de4600010)
[uc2n483:640198:0:640198] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1506a8000010)
[uc2n484:171714:0:171714] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x151e88000010)
==== backtrace (tid: 640197) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002d85d MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
18 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 640198) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002d85d MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
18 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 640200) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002d85d MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
18 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 640199) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002d85d MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
18 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 171714) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002d85d MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
18 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 171713) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002d85d MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
18 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 171712) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002d85d MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
18 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 171711) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002d85d MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
18 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[uc2n481.localdomain:3905654] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3905654] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec noticed that process rank 10 with PID 640199 on node uc2n483 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n481
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n483:640386:0:640386] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14f49a500000)
[uc2n484:171914:0:171914] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e1f8000000)
[uc2n484:171912:0:171912] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c54a000000)
[uc2n484:171911:0:171911] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e788600000)
[uc2n484:171913:0:171913] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14cc3e700000)
[uc2n483:640385:0:640385] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x148f18000000)
[uc2n483:640387:0:640387] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1468fa000000)
[uc2n483:640384:0:640384] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x146340400000)
==== backtrace (tid: 640386) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002ded3 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 171914) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002ded3 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 171913) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002ded3 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 171912) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002ded3 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 171911) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002ded3 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 640387) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002ded3 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 640385) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002ded3 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid: 640384) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002ded3 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d259 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e66e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d6af Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[uc2n481.localdomain:3905802] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n481.localdomain:3905802] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec noticed that process rank 14 with PID 171913 on node uc2n484 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 11:57:22.841713
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 11:57:29.660761
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 11:57:35.871464
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 11:57:42.571968
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 11:57:48.622770
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 11:57:56.728172
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 11:58:02.875615
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 11:58:09.126159
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-29 11:58:15.125782
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 11:58:21.563074
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 11:58:29.922479
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 11:58:36.405775
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 11:58:43.091196
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 11:58:49.210788
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 11:58:56.310339
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 11:59:03.491548
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 11:59:10.374329
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-29 11:59:16.327988
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 11:59:23.621514
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 11:59:34.289576
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 11:59:40.684485
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 11:59:47.120380
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 11:59:53.276620
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 11:59:59.694568
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 12:00:06.039194
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 12:00:13.506890
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-29 12:00:19.458418
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 12:00:26.928074
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 12:00:32.973138
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 12:00:39.830916
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 12:00:46.563271
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 12:00:52.684511
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 12:00:59.848192
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 12:01:05.936907
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 12:01:13.088485
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-29 12:01:19.163800
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 12:01:26.688873
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 12:01:32.817809
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 12:01:40.715787
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 12:01:48.005441
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 12:01:54.094286
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 12:02:02.548785
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 12:02:08.662770
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 12:02:16.991407
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-29 12:02:23.078794
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 12:02:32.963319
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 12:02:39.207565
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 12:02:45.488675
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 12:02:52.804802
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 12:03:03.904920
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 12:03:12.502277
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 12:03:18.988256
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 12:03:29.489496
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-29 12:03:35.835629
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 12:03:48.320767
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 12:03:55.215396
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 12:04:01.820673
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 12:04:11.689308
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 12:04:19.058229
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 12:04:30.585439
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 12:04:37.331967
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 12:04:48.097176
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-29 12:04:56.056479
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 12:05:08.770785
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 12:05:16.038689
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 12:05:23.434997
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 12:05:35.538467
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 12:05:43.594440
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 12:06:00.236639
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 12:06:07.702893
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 12:06:23.237917
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-29 12:06:30.691669
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 12:06:50.344792
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 12:06:59.229841
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 12:07:08.072702
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 12:07:21.522382
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 12:07:30.658397
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 12:07:50.696844
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 12:07:59.583269
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 12:08:24.545363
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-29 12:08:33.415288
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 12:09:06.784980
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 12:09:20.939816
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 12:09:33.265176
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 12:09:54.182010
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 12:10:06.295004
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 12:10:40.289575
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 12:10:51.904092
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 12:11:19.136004
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-29 12:11:30.870330
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 12:12:07.813103
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 12:12:25.308599
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 12:12:42.559494
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 12:13:18.227491
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 12:13:36.625575
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 12:14:38.386236
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 12:14:55.829438
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 12:15:44.200920
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-29 12:16:01.784983
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 12:17:08.427515
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 12:17:37.397003
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 12:18:05.978897
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 12:18:58.387730
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 12:19:29.125724
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 12:20:58.592874
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 12:21:27.548423
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 12:22:58.371372
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-29 12:23:27.453494
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 12:25:34.767560
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 12:25:44.976281
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 12:25:54.220817
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 12:26:04.513936
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 12:26:14.768355
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 12:26:25.054109
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 12:26:35.345825
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 12:26:47.377052
b'2 total processes killed (some possibly by mpiexec during cleanup)\n'

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 8 -p2 2 -b ../benchmarks/bwunicluster/gpu4/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-29 12:26:56.488763
b'2 total processes killed (some possibly by mpiexec during cleanup)\n'

all done

============================= JOB FEEDBACK =============================

NodeName=uc2n[481-484]
Job ID: 19960398
Cluster: uc2
User/Group: st_st160727/st_us-051200
State: COMPLETED (exit code 0)
Nodes: 4
Cores per node: 80
CPU Utilized: 5-07:52:12
CPU Efficiency: 3.84% of 138-17:57:20 core-walltime
Job Wall-clock time: 10:24:22
Memory Utilized: 35.21 GB
Memory Efficiency: 0.00% of 0.00 MB
