Modules loaded
uc2n510
uc2n510
uc2n510
uc2n510
uc2n510
uc2n510
uc2n510
uc2n510
uc2n511
uc2n511
uc2n511
uc2n511
uc2n511
uc2n511
uc2n511
uc2n511
uc2n514
uc2n514
uc2n514
uc2n514
uc2n514
uc2n514
uc2n514
uc2n514
uc2n517
uc2n517
uc2n517
uc2n517
uc2n517
uc2n517
uc2n517
uc2n517
32: uc2n510 uc2n510 uc2n510 uc2n510 uc2n510 uc2n510 uc2n510 uc2n510 uc2n511 uc2n511 uc2n511 uc2n511 uc2n511 uc2n511 uc2n511 uc2n511 uc2n514 uc2n514 uc2n514 uc2n514 uc2n514 uc2n514 uc2n514 uc2n514 uc2n517 uc2n517 uc2n517 uc2n517 uc2n517 uc2n517 uc2n517 uc2n517
16x0: uc2n510 uc2n510 uc2n510 uc2n510 uc2n510 uc2n510 uc2n510 uc2n510 uc2n511 uc2n511 uc2n511 uc2n511 uc2n511 uc2n511 uc2n511 uc2n511
16x1: uc2n514 uc2n514 uc2n514 uc2n514 uc2n514 uc2n514 uc2n514 uc2n514 uc2n517 uc2n517 uc2n517 uc2n517 uc2n517 uc2n517 uc2n517 uc2n517
start building
-- The CUDA compiler identification is NVIDIA 11.0.194
-- The CXX compiler identification is GNU 8.3.1
-- Detecting CUDA compiler ABI info
-- Detecting CUDA compiler ABI info - done
-- Check for working CUDA compiler: /opt/bwhpc/common/devel/cuda/11.0/bin/nvcc - skipped
-- Detecting CUDA compile features
-- Detecting CUDA compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /usr/bin/g++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Found MPI_CXX: /pfs/data5/software_uc2/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so (found version "3.1") 
-- Found MPI: TRUE (found version "3.1")  
-- Found CUDAToolkit: /opt/bwhpc/common/devel/cuda/11.0/include (found version "11.0.194") 
-- Looking for C++ include pthread.h
-- Looking for C++ include pthread.h - found
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed
-- Looking for pthread_create in pthreads
-- Looking for pthread_create in pthreads - not found
-- Looking for pthread_create in pthread
-- Looking for pthread_create in pthread - found
-- Found Threads: TRUE  
-- Configuring done
-- Generating done
-- Build files have been written to: /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8
Scanning dependencies of target test_base
[  3%] Building CUDA object CMakeFiles/test_base.dir/tests/src/base.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[  6%] Linking CUDA shared library libtest_base.so
[  6%] Built target test_base
Scanning dependencies of target mpicufft
[  9%] Building CXX object CMakeFiles/mpicufft.dir/src/mpicufft.cpp.o
[ 12%] Linking CXX shared library libmpicufft.so
[ 12%] Built target mpicufft
Scanning dependencies of target timer
[ 15%] Building CXX object CMakeFiles/timer.dir/src/timer.cpp.o
[ 18%] Linking CXX shared library libtimer.so
[ 18%] Built target timer
Scanning dependencies of target pencil_decomp
[ 21%] Building CXX object CMakeFiles/pencil_decomp.dir/src/pencil/mpicufft_pencil.cpp.o
[ 24%] Building CXX object CMakeFiles/pencil_decomp.dir/src/pencil/mpicufft_pencil_opt1.cpp.o
[ 27%] Linking CXX shared library libpencil_decomp.so
[ 27%] Built target pencil_decomp
Scanning dependencies of target pencil_tests
[ 30%] Building CUDA object CMakeFiles/pencil_tests.dir/tests/src/pencil/base.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 33%] Building CUDA object CMakeFiles/pencil_tests.dir/tests/src/pencil/random_dist_1D.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 36%] Building CUDA object CMakeFiles/pencil_tests.dir/tests/src/pencil/random_dist_2D.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 39%] Building CUDA object CMakeFiles/pencil_tests.dir/tests/src/pencil/random_dist_3D.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 42%] Linking CUDA shared library libpencil_tests.so
[ 42%] Built target pencil_tests
Scanning dependencies of target pencil
[ 45%] Building CXX object CMakeFiles/pencil.dir/tests/src/pencil/main.cpp.o
[ 48%] Linking CXX executable pencil
[ 48%] Built target pencil
Scanning dependencies of target slab_decomp
[ 51%] Building CXX object CMakeFiles/slab_decomp.dir/src/slab/default/mpicufft_slab.cpp.o
[ 54%] Building CXX object CMakeFiles/slab_decomp.dir/src/slab/default/mpicufft_slab_opt1.cpp.o
[ 57%] Building CXX object CMakeFiles/slab_decomp.dir/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp.o
[ 60%] Building CXX object CMakeFiles/slab_decomp.dir/src/slab/z_then_yx/mpicufft_slab_z_then_yx_opt1.cpp.o
[ 63%] Building CXX object CMakeFiles/slab_decomp.dir/src/slab/y_then_zx/mpicufft_slab_y_then_zx.cpp.o
[ 66%] Linking CXX shared library libslab_decomp.so
[ 66%] Built target slab_decomp
Scanning dependencies of target slab_tests
[ 69%] Building CUDA object CMakeFiles/slab_tests.dir/tests/src/slab/base.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 72%] Building CUDA object CMakeFiles/slab_tests.dir/tests/src/slab/random_dist_default.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 75%] Building CUDA object CMakeFiles/slab_tests.dir/tests/src/slab/random_dist_y_then_zx.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 78%] Building CUDA object CMakeFiles/slab_tests.dir/tests/src/slab/random_dist_z_then_yx.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 81%] Linking CUDA shared library libslab_tests.so
[ 81%] Built target slab_tests
Scanning dependencies of target slab
[ 84%] Building CXX object CMakeFiles/slab.dir/tests/src/slab/main.cpp.o
[ 87%] Linking CXX executable slab
[ 87%] Built target slab
Scanning dependencies of target reference_tests
[ 90%] Building CUDA object CMakeFiles/reference_tests.dir/tests/src/reference/reference.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 93%] Linking CUDA shared library libreference_tests.so
[ 93%] Built target reference_tests
Scanning dependencies of target reference
[ 96%] Building CXX object CMakeFiles/reference.dir/tests/src/reference/main.cpp.o
[100%] Linking CXX executable reference
[100%] Built target reference
finished building
start python script
Starting on HOST48
-----------------------------------------------------------------------------
Slab 2D->1D default
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1014174] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1014174] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1014447] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1014447] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1014717] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1014717] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1015234] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1015234] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1015762] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1015762] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1016032] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1016032] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1016315] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1016315] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1016583] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1016583] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1016853] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1016853] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1017134] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1017134] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1017406] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1017406] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1017670] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1017670] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1017952] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1017952] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1018471] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1018471] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1018987] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1018987] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1019270] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1019270] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1019541] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1019541] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1019809] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1019809] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1020089] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1020089] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1020357] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1020357] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1020640] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1020640] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1020904] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1020904] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1021176] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1021176] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1021706] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1021706] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1022222] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1022222] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1022490] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1022490] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1022769] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1022769] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1023036] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1023036] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1023305] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1023305] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1023584] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1023584] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1023853] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1023853] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1024120] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1024120] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1024408] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1024408] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1024927] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1024927] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1025442] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1025442] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1025721] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1025721] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1025992] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1025992] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1026261] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1026261] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1026544] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1026544] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1026809] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1026809] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1027078] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1027078] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1027362] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1027362] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1027629] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1027629] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1028146] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1028146] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1028664] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1028664] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1028945] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1028945] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1029213] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1029213] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1029493] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1029493] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1029761] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1029761] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1030031] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1030031] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1030300] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1030300] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1030583] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1030583] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1030853] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1030853] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1031370] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1031370] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1031896] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1031896] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1032166] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1032166] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1032434] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1032434] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1032716] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1032716] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1032985] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1032985] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1033261] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1033261] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1033536] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1033536] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1033805] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1033805] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1034084] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1034084] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1034597] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1034597] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1035117] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1035117] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1035397] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1035397] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1035667] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1035667] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1035935] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1035935] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1036221] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1036221] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1036493] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1036493] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1036760] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1036760] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1037040] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1037040] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1037311] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1037311] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1037825] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1037825] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1038351] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1038351] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1038620] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1038620] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1038892] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1038892] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1039174] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1039174] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1039444] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1039444] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1039725] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1039725] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1039993] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1039993] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1040268] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1040268] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1040548] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1040548] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1041066] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1041066] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1041596] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1041596] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1041868] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1041868] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1042136] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1042136] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1042418] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1042418] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1042688] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1042688] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1042971] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1042971] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1043239] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1043239] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1043525] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1043525] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1043800] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1043800] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1044330] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1044330] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1044849] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1044849] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1045134] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1045134] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1045405] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1045405] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1045696] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1045696] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1045968] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1045968] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1046249] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1046249] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1046519] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1046519] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1046806] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1046806] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1047091] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1047091] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1047629] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1047629] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1048146] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1048146] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1048436] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1048436] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1048722] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1048722] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1049007] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1049007] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1049281] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1049281] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1049570] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1049570] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1049858] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1049858] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1050157] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1050157] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1050446] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1050446] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1050990] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1050990] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1051523] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1051523] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1051815] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1051815] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1052109] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1052109] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1052413] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1052413] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1052706] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1052706] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1053000] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1053000] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1053289] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1053289] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1053616] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1053616] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1053932] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1053932] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1054494] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1054494] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1055038] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1055038] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1055366] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1055366] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1055659] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1055659] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1055995] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1055995] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1056290] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1056290] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1056616] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1056616] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1056923] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1056923] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1057192] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1057192] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1057476] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1057476] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1057765] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1057765] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1058050] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1058050] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1058331] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1058331] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1058598] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1058598] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1058872] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1058872] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1059156] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1059156] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1059423] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1059423] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1059692] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1059692] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1059970] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1059970] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1060237] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1060237] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1060536] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1060536] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1060834] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1060834] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1061103] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1061103] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1061374] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1061374] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1061658] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1061658] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1061929] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1061929] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1062196] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1062196] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1062476] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1062476] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1062746] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1062746] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1063015] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1063015] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1063321] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1063321] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1063606] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1063606] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1063916] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1063916] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1064204] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1064204] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1064472] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1064472] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1064739] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1064739] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1065020] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1065020] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1065289] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1065289] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1065570] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1065570] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1065840] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1065840] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1066149] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1066149] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1066439] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1066439] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1066726] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1066726] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1066996] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1066996] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1067278] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1067278] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1067550] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1067550] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1067834] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1067834] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1068103] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1068103] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1068415] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1068415] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1068727] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1068727] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1069071] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1069071] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1069400] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1069400] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1069719] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1069719] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1070017] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1070017] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1070332] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1070332] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1070645] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1070645] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1070954] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1070954] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
Starting computation for size 128
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128
2021-09-29 21:19:30.165265
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128
2021-09-29 21:19:46.141808
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128
2021-09-29 21:19:56.275192
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128
2021-09-29 21:20:05.571019
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128
2021-09-29 21:20:16.345186
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128
2021-09-29 21:20:26.256098
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128
2021-09-29 21:20:39.504974
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128
2021-09-29 21:20:49.293521
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128
2021-09-29 21:20:59.838151
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128
2021-09-29 21:21:09.835335
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 256
2021-09-29 21:21:21.780187
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 256
2021-09-29 21:21:31.619973
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 256
2021-09-29 21:21:42.258915
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 256
2021-09-29 21:21:52.619808
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 256
2021-09-29 21:22:03.274889
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 256
2021-09-29 21:22:13.163667
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 256
2021-09-29 21:22:23.901692
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 256
2021-09-29 21:22:35.075974
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 256
2021-09-29 21:22:45.791393
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 256
2021-09-29 21:22:55.934502
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 256 -nz 256
2021-09-29 21:23:06.965555
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 256 -nz 256
2021-09-29 21:23:16.697083
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 256 -nz 256
2021-09-29 21:23:27.365025
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 256 -nz 256
2021-09-29 21:23:38.332941
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 256 -nz 256
2021-09-29 21:23:48.344429
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 256 -nz 256
2021-09-29 21:23:57.881119
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 256 -nz 256
2021-09-29 21:24:08.766396
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 256 -nz 256
2021-09-29 21:24:18.384426
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 256 -nz 256
2021-09-29 21:24:28.651592
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 256 -nz 256
2021-09-29 21:24:40.586112
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256
2021-09-29 21:24:50.870706
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256
2021-09-29 21:25:00.413896
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256
2021-09-29 21:25:11.319735
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256
2021-09-29 21:25:20.742693
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256
2021-09-29 21:25:30.650397
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256
2021-09-29 21:25:40.560423
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256
2021-09-29 21:25:50.355048
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256
2021-09-29 21:25:59.487847
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256
2021-09-29 21:26:09.313551
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256
2021-09-29 21:26:18.363944
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 512
2021-09-29 21:26:28.164205
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 512
2021-09-29 21:26:37.509338
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 512
2021-09-29 21:26:47.386813
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 512
2021-09-29 21:26:56.683021
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 512
2021-09-29 21:27:06.455514
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 512
2021-09-29 21:27:18.177310
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 512
2021-09-29 21:27:28.237335
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 512
2021-09-29 21:27:37.471967
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 512
2021-09-29 21:27:47.359452
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 512
2021-09-29 21:27:56.686773
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 512 -nz 512
2021-09-29 21:28:06.560930
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 512 -nz 512
2021-09-29 21:28:16.054805
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 512 -nz 512
2021-09-29 21:28:26.063603
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 512 -nz 512
2021-09-29 21:28:35.873404
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 512 -nz 512
2021-09-29 21:28:45.991629
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 512 -nz 512
2021-09-29 21:28:55.359664
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 512 -nz 512
2021-09-29 21:29:05.392414
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 512 -nz 512
2021-09-29 21:29:17.339154
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 512 -nz 512
2021-09-29 21:29:27.538067
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 512 -nz 512
2021-09-29 21:29:37.177782
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512
2021-09-29 21:29:48.945283
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512
2021-09-29 21:29:59.137536
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512
2021-09-29 21:30:09.634546
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512
2021-09-29 21:30:20.673197
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512
2021-09-29 21:30:30.883072
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512
2021-09-29 21:30:40.805067
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512
2021-09-29 21:30:50.994198
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512
2021-09-29 21:31:01.093092
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512
2021-09-29 21:31:11.278908
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512
2021-09-29 21:31:21.737672
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 1024
2021-09-29 21:31:32.084931
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 1024
2021-09-29 21:31:43.218188
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 1024
2021-09-29 21:31:53.778987
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 1024
2021-09-29 21:32:04.382165
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 1024
2021-09-29 21:32:15.021826
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 1024
2021-09-29 21:32:25.732822
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 1024
2021-09-29 21:32:36.480354
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 1024
2021-09-29 21:32:48.060235
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 1024
2021-09-29 21:32:58.684602
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 1024
2021-09-29 21:33:10.181616
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 21:33:21.027464
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 21:33:34.189227
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 21:33:45.936384
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 21:33:58.364967
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 21:34:10.023348
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 21:34:22.544256
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 21:34:34.090541
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 21:34:47.373637
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 21:34:59.041336
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 1024 -nz 1024
2021-09-29 21:35:12.018300
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 21:35:24.119253
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 21:35:42.000017
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 21:35:56.678453
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 21:36:13.338422
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 21:36:28.245191
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 21:36:45.125457
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 21:36:59.835830
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 21:37:17.632683
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 21:37:32.557554
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024
2021-09-29 21:37:50.126661
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 21:38:04.414225
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 21:38:30.746688
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 21:38:48.524268
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 21:39:12.317352
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 21:39:30.311739
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 21:39:57.212697
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 21:40:15.151991
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 21:40:41.227142
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 21:40:59.555484
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 2048
2021-09-29 21:41:25.376973
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 21:41:44.123619
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 21:42:27.630883
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 21:42:53.885957
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 21:43:33.004078
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 21:43:58.533944
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 21:44:36.637515
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 21:45:02.313128
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 21:45:46.379347
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 21:46:12.413296
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 2048 -nz 2048
2021-09-29 21:46:54.193254
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 21:47:20.498433
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 21:48:37.002941
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 21:49:18.441983
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 21:50:26.022841
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 21:51:07.453031
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 21:52:14.545122
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 21:52:54.791870
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 21:54:12.696013
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 21:54:54.892833
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048
2021-09-29 21:56:08.590427
b''

Starting computation for size 128
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 21:56:50.661462
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 21:57:01.750423
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 21:57:11.908821
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 21:57:21.441281
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 21:57:31.164688
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 21:57:40.436394
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 21:57:50.126249
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 21:58:02.317581
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 21:58:12.178178
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 21:58:21.742775
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

Starting computation for size 256
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 21:58:32.102467
b'Result (avg): 5.01735e-09\nResult (max): 5.42241e-08\n'

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 21:58:41.435737
b'Result (avg): 5.01735e-09\nResult (max): 5.42241e-08\n'

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 21:58:51.370490
b'Result (avg): 5.01735e-09\nResult (max): 5.42241e-08\n'

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 21:59:01.904032
b'Result (avg): 5.01735e-09\nResult (max): 5.42241e-08\n'

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 21:59:12.161836
b'Result (avg): 5.01735e-09\nResult (max): 5.42241e-08\n'

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 21:59:21.991785
b'Result (avg): 5.01735e-09\nResult (max): 5.42241e-08\n'

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 21:59:32.521679
b'Result (avg): 5.01735e-09\nResult (max): 5.42241e-08\n'

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 21:59:43.417096
b'Result (avg): 5.01735e-09\nResult (max): 5.42241e-08\n'

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 21:59:53.600759
b'Result (avg): 5.01735e-09\nResult (max): 5.42241e-08\n'

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 22:00:04.177521
b'Result (avg): 5.01735e-09\nResult (max): 5.42241e-08\n'

Starting computation for size 512
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 22:00:14.398024
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 22:00:24.489279
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 22:00:35.154251
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 22:00:45.289537
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 22:00:55.885668
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 22:01:06.573750
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 22:01:17.094276
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 22:01:27.221198
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 22:01:37.875742
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 22:01:48.286239
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

Starting computation for size 1024
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 22:01:59.014198
b'Result (avg): 7.38396e-07\nResult (max): 9.23959e-06\n'

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 22:02:14.272165
b'Result (avg): 7.38396e-07\nResult (max): 9.23959e-06\n'

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 22:02:29.572905
b'Result (avg): 7.38396e-07\nResult (max): 9.23959e-06\n'

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 22:02:44.581307
b'Result (avg): 7.38396e-07\nResult (max): 9.23959e-06\n'

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 22:02:59.735370
b'Result (avg): 7.38396e-07\nResult (max): 9.23959e-06\n'

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 22:03:15.182584
b'Result (avg): 1.68891e-06\nResult (max): 4.78518e-05\n'

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 22:03:30.051785
b'Result (avg): 7.38396e-07\nResult (max): 9.23959e-06\n'

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 22:03:45.048504
b'Result (avg): 7.38396e-07\nResult (max): 9.23959e-06\n'

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 22:04:00.628963
b'Result (avg): 7.38396e-07\nResult (max): 9.23959e-06\n'

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 22:04:15.839331
b'Result (avg): 7.38396e-07\nResult (max): 9.23959e-06\n'

Starting computation for size 2048
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 22:04:30.648832
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 22:05:27.631119
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 22:06:20.922267
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 22:07:17.763708
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 22:08:11.704655
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 22:09:10.257889
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 22:10:04.131524
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 22:11:02.324646
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 22:11:55.224349
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 22:12:53.417591
b'Result (avg): -nan\nResult (max): -nan\n'

Slab 2D->1D opt1
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1071270] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1071270] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1071539] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1071539] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1071806] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1071806] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1072337] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1072337] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1072606] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1072606] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1072873] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1072873] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1073157] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1073157] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1073426] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1073426] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1073693] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1073693] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1073974] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1073974] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1074247] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1074247] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1074514] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1074514] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1074792] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1074792] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1075309] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1075309] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1075575] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1075575] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1075858] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1075858] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1076128] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1076128] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1076408] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1076408] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1076677] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1076677] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1076945] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1076945] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1077232] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1077232] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1077503] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1077503] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1077770] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1077770] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1078301] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1078301] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1078575] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1078575] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1078843] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1078843] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1079127] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1079127] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1079395] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1079395] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1079676] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1079676] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1079944] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1079944] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1080218] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1080218] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1080506] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1080506] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1080776] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1080776] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1081292] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1081292] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1081573] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1081573] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1081842] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1081842] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1082126] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1082126] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1082395] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1082395] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1082663] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1082663] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1082947] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1082947] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1083221] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1083221] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1083503] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1083503] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1083774] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1083774] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1084294] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1084294] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1084573] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1084573] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1084842] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1084842] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1085129] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1085129] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1085402] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1085402] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1085683] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1085683] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1085951] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1085951] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1086241] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1086241] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1086512] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1086512] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1086780] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1086780] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1087310] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1087310] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1087579] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1087579] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1087847] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1087847] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1088151] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1088151] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1088422] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1088422] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1088691] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1088691] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1088978] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1088978] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1089271] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1089271] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1089540] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1089540] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1089819] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1089819] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1090338] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1090338] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1090624] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1090624] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1090891] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1090891] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1091187] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1091187] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1091457] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1091457] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1091740] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1091740] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1092011] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1092011] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1092308] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1092308] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1092588] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1092588] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1092860] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1092860] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1093379] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1093379] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1093660] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1093660] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1093932] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1093932] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1094248] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1094248] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1094527] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1094527] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1094796] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1094796] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1095076] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1095076] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1095398] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1095398] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1095668] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1095668] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1095945] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1095945] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1096472] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1096472] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1096743] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1096743] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1097024] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1097024] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1097389] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1097389] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1097657] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1097657] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1097926] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1097926] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1098217] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1098217] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1098578] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1098578] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1098853] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1098853] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1099139] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1099139] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1099669] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1099669] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1099950] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1099950] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1100235] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1100235] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1100595] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1100595] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1100868] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1100868] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1101154] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1101154] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1101428] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1101428] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1101789] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1101789] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1102079] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1102079] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1102365] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1102365] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1102902] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1102902] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1103177] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1103177] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1103464] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1103464] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1103930] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1103930] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1104219] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1104219] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1104491] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1104491] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1104784] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1104784] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1105237] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1105237] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1105539] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1105539] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1105829] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1105829] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1106367] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1106367] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1106659] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1106659] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1106964] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1106964] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1107674] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1107674] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1107979] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1107979] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1108262] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1108262] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1108569] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1108569] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1109206] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1109206] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1109530] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1109530] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1109842] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1109842] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1110410] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1110410] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1110721] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1110721] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1111060] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1111060] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1111703] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1111703] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1112028] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1112028] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1112336] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1112336] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1112670] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1112670] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1113319] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1113319] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1113592] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1113592] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1113875] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1113875] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1114166] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1114166] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1114453] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1114453] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1114734] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1114734] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1115005] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1115005] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1115286] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1115286] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1115557] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1115557] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1115826] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1115826] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1116111] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1116111] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1116381] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1116381] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1116650] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1116650] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1116955] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1116955] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1117240] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1117240] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1117511] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1117511] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1117796] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1117796] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1118068] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1118068] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1118335] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1118335] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1118621] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1118621] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1118891] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1118891] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1119169] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1119169] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1119436] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1119436] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1119730] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1119730] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1120026] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1120026] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1120296] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1120296] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1120566] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1120566] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1120851] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1120851] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1121123] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1121123] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1121404] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1121404] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1121674] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1121674] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1121948] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1121948] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1122231] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1122231] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1122543] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1122543] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1122832] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1122832] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1123117] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1123117] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1123391] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1123391] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1123673] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1123673] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1123948] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1123948] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1124236] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1124236] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1124508] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1124508] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1124825] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1124825] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1125140] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1125140] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1125480] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1125480] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1125807] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1125807] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1126121] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1126121] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1126443] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1126443] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1126758] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1126758] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1127068] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1127068] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1127385] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1127385] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
Starting computation for size 128
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 22:13:47.286094
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 22:13:56.897789
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 22:14:06.888443
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 22:14:16.328867
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 22:14:26.413397
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 22:14:36.016339
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 22:14:47.950700
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 22:14:57.261954
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 22:15:07.381921
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-29 22:15:16.732196
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 22:15:28.587605
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 22:15:38.224878
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 22:15:48.334956
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 22:15:57.689470
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 22:16:07.926074
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 22:16:17.633154
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 22:16:31.059846
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 22:16:40.869477
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 22:16:52.168268
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-29 22:17:01.667631
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 22:17:15.176096
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 22:17:24.665827
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 22:17:34.771105
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 22:17:44.650606
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 22:17:55.696056
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 22:18:04.760447
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 22:18:21.326724
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 22:18:30.515126
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 22:18:40.267385
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-29 22:18:49.301526
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 22:19:06.073469
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 22:19:15.170459
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 22:19:25.102169
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 22:19:36.822380
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 22:19:47.250514
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 22:19:56.652384
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 22:20:16.090205
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 22:20:25.620867
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 22:20:35.885491
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-29 22:20:45.765845
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 22:21:03.570303
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 22:21:14.709206
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 22:21:24.973667
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 22:21:34.835050
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 22:21:46.016257
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 22:21:56.054239
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 22:22:20.250324
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 22:22:30.424669
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 22:22:40.989235
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-29 22:22:51.092141
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 22:23:15.979041
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 22:23:25.804796
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 22:23:36.133446
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 22:23:45.924576
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 22:23:56.249385
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 22:24:06.371857
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 22:24:47.125027
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 22:24:58.991089
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 22:25:09.446701
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-29 22:25:19.373574
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 22:25:58.218188
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 22:26:09.702698
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 22:26:19.997387
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 22:26:29.804304
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 22:26:40.932370
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 22:26:51.359239
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 22:27:28.812717
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 22:27:38.851791
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 22:27:49.066598
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-29 22:27:59.404451
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 22:28:36.811350
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 22:28:48.052448
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 22:28:59.541608
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 22:29:10.383758
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 22:29:21.014177
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 22:29:33.253131
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 22:30:37.622918
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 22:30:48.750413
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 22:30:59.460862
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-29 22:31:10.899518
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 22:32:15.786168
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 22:32:29.172043
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 22:32:40.990325
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 22:32:53.595315
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 22:33:05.414052
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 22:33:19.343792
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 22:35:14.277540
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 22:35:27.689634
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 22:35:39.487898
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-29 22:35:53.440750
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 22:37:50.741112
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 22:38:09.658095
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 22:38:24.374547
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 22:38:41.407564
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 22:38:56.358257
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 22:39:14.803185
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 22:41:13.163086
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 22:41:31.417464
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 22:41:45.156446
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-29 22:42:03.666131
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 22:44:04.469037
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 22:44:31.994668
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 22:44:50.983744
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 22:45:15.564388
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 22:45:33.889756
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 22:46:01.895321
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 22:49:44.912200
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 22:50:12.399786
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 22:50:30.510447
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-29 22:50:58.500121
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 22:54:46.060164
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 22:55:30.544986
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 22:55:58.388327
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 22:56:38.117661
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 22:57:04.679635
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 22:57:50.867504
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 23:04:55.922090
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 23:05:42.918347
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 23:06:11.445543
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-29 23:06:58.531686
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 23:14:17.399715
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 23:15:39.280291
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 23:16:25.429943
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 23:17:37.995492
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 23:18:21.790511
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 23:19:45.130344
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 23:27:14.778066
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 23:28:37.131026
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 23:29:21.828316
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-29 23:30:47.023798
b''

Starting computation for size 128
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 23:38:31.461612
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 23:38:43.979225
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 23:38:54.472236
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 23:39:04.278269
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 23:39:14.589217
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 23:39:24.716757
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 23:39:35.220575
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 23:39:48.745477
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 23:39:59.477973
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-29 23:40:10.017912
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

Starting computation for size 256
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 23:40:20.500716
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 23:40:30.574317
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 23:40:41.080910
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 23:40:50.787542
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 23:41:01.247849
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 23:41:11.527963
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 23:41:22.363567
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 23:41:33.450988
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 23:41:43.883996
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-29 23:41:54.271308
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

Starting computation for size 512
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 23:42:05.399196
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 23:42:15.960002
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 23:42:26.952119
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 23:42:37.490734
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 23:42:49.200446
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 23:43:00.943426
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 23:43:13.012267
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 23:43:23.707111
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 23:43:34.604270
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-29 23:43:45.544890
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

Starting computation for size 1024
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 23:43:57.922856
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 23:44:14.131991
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 23:44:29.389988
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 23:44:45.880122
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 23:45:01.137173
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 23:45:17.128423
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 23:45:37.116702
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 23:45:52.457541
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 23:46:07.726840
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-29 23:46:23.641210
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

Starting computation for size 2048
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 23:46:43.804621
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 23:47:41.339792
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 23:48:36.316594
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 23:49:33.156151
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 23:50:32.511205
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 23:51:31.495761
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 23:52:44.509136
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 23:53:42.437673
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 23:54:37.660047
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-29 23:55:36.438646
b'Result (avg): -nan\nResult (max): -nan\n'

Slab 1D->2D default
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1127722] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1127722] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1127985] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1127985] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1128254] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1128254] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1128786] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1128786] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1129304] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1129304] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1129571] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1129571] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1129850] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1129850] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1130121] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1130121] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1130391] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1130391] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1130674] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1130674] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1130944] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1130944] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1131225] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1131225] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1131494] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1131494] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1132012] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1132012] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1132527] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1132527] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1132808] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1132808] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1133078] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1133078] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1133361] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1133361] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1133630] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1133630] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1133903] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1133903] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1134182] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1134182] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1134449] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1134449] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1134718] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1134718] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1135245] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1135245] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1135760] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1135760] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1136074] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1136074] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1136362] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1136362] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1136633] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1136633] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1136901] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1136901] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1137181] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1137181] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1137451] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1137451] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1137719] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1137719] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1138000] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1138000] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1138519] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1138519] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1139036] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1139036] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1139322] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1139322] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1139591] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1139591] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1139874] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1139874] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1140143] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1140143] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1140412] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1140412] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1140694] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1140694] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1140962] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1140962] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1141248] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1141248] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1141763] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1141763] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1142282] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1142282] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1142553] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1142553] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1142834] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1142834] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1143104] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1143104] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1143385] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1143385] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1143653] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1143653] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1143940] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1143940] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1144207] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1144207] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1144476] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1144476] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1145004] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1145004] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1145521] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1145521] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1145790] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1145790] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1146074] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1146074] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1146343] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1146343] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1146633] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1146633] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1146899] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1146899] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1147186] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1147186] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1147455] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1147455] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1147725] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1147725] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1148252] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1148252] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1148769] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1148769] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1149037] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1149037] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1149327] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1149327] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1149608] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1149608] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1149877] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1149877] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1150156] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1150156] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1150450] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1150450] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1150720] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1150720] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1150999] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1150999] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1151517] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1151517] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1152034] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1152034] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1152317] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1152317] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1152612] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1152612] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1152879] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1152879] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1153157] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1153157] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1153425] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1153425] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1153717] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1153717] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1154002] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1154002] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1154270] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1154270] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1154791] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1154791] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1155320] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1155320] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1155589] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1155589] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1155904] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1155904] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1156187] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1156187] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1156454] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1156454] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1156727] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1156727] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1157041] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1157041] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1157325] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1157325] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1157597] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1157597] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1158131] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1158131] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1158652] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1158652] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1158940] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1158940] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1159283] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1159283] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1159562] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1159562] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1159835] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1159835] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1160120] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1160120] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1160485] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1160485] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1160769] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1160769] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1161042] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1161042] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1161574] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1161574] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1162111] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1162111] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1162387] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1162387] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1162740] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1162740] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1163027] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1163027] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1163301] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1163301] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1163593] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1163593] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1163961] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1163961] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1164270] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1164270] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1164549] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1164549] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1165100] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1165100] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1165643] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1165643] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1165939] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1165939] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1166373] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1166373] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1166671] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1166671] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1166959] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1166959] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1167271] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1167271] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1167710] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1167710] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1168035] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1168035] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1168342] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1168342] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1168909] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1168909] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1169466] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1169466] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1169786] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1169786] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1170380] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1170380] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1170719] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1170719] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1171016] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1171016] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1171355] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1171355] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1172010] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1172010] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1172271] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1172271] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1172552] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1172552] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1172844] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1172844] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1173129] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1173129] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1173409] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1173409] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1173676] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1173676] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1173944] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1173944] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1174226] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1174226] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1174490] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1174490] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1174759] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1174759] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1175050] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1175050] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1175317] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1175317] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1175610] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1175610] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1175908] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1175908] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1176176] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1176176] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1176447] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1176447] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1176732] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1176732] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1176998] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1176998] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1177268] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1177268] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1177550] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1177550] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1177818] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1177818] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1178090] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1178090] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1178393] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1178393] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1178677] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1178677] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1178946] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1178946] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1179234] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1179234] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1179507] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1179507] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1179775] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1179775] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1180057] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1180057] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1180330] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1180330] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1180614] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1180614] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1180886] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1180886] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1181198] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1181198] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1181485] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1181485] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1181773] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1181773] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1182058] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1182058] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1182328] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1182328] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1182617] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1182617] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1182900] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1182900] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1183173] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1183173] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1183502] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1183502] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1183798] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1183798] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1184140] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1184140] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1184470] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1184470] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1184783] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1184783] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1185144] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1185144] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1185454] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1185454] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1185771] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1185771] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1186088] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1186088] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
Starting computation for size 128
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128
2021-09-29 23:56:51.372549
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128
2021-09-29 23:57:02.995143
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128
2021-09-29 23:57:13.263256
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128
2021-09-29 23:57:22.734251
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128
2021-09-29 23:57:34.662054
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128
2021-09-29 23:57:44.097154
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128
2021-09-29 23:57:56.527883
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128
2021-09-29 23:58:05.812582
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128
2021-09-29 23:58:16.008367
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128
2021-09-29 23:58:25.325500
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 256
2021-09-29 23:58:36.979851
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 256
2021-09-29 23:58:46.422743
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 256
2021-09-29 23:58:56.585149
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 256
2021-09-29 23:59:05.696442
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 256
2021-09-29 23:59:15.692504
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 256
2021-09-29 23:59:25.243802
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 256
2021-09-29 23:59:36.822177
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 256
2021-09-29 23:59:49.085668
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 256
2021-09-29 23:59:59.169545
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 256
2021-09-30 00:00:08.451228
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 256 -nz 256
2021-09-30 00:00:20.216265
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 256 -nz 256
2021-09-30 00:00:30.501329
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 256 -nz 256
2021-09-30 00:00:40.888670
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 256 -nz 256
2021-09-30 00:00:50.371613
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 256 -nz 256
2021-09-30 00:01:00.555990
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 256 -nz 256
2021-09-30 00:01:10.002158
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 256 -nz 256
2021-09-30 00:01:22.959527
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 256 -nz 256
2021-09-30 00:01:32.577683
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 256 -nz 256
2021-09-30 00:01:42.648386
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 256 -nz 256
2021-09-30 00:01:52.133229
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256
2021-09-30 00:02:05.365469
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256
2021-09-30 00:02:14.798983
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256
2021-09-30 00:02:24.882887
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256
2021-09-30 00:02:34.355476
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256
2021-09-30 00:02:45.277756
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256
2021-09-30 00:02:54.790306
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256
2021-09-30 00:03:10.422989
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256
2021-09-30 00:03:20.343720
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256
2021-09-30 00:03:30.550326
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256
2021-09-30 00:03:40.317702
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 512
2021-09-30 00:03:56.251820
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 512
2021-09-30 00:04:05.773309
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 512
2021-09-30 00:04:17.092177
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 512
2021-09-30 00:04:26.545196
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 512
2021-09-30 00:04:36.539678
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 512
2021-09-30 00:04:46.177740
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 512
2021-09-30 00:05:01.882615
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 512
2021-09-30 00:05:11.859876
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 512
2021-09-30 00:05:21.952684
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 512
2021-09-30 00:05:31.587088
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 512 -nz 512
2021-09-30 00:05:47.668039
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 512 -nz 512
2021-09-30 00:05:57.472393
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 512 -nz 512
2021-09-30 00:06:07.518151
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 512 -nz 512
2021-09-30 00:06:17.564320
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 512 -nz 512
2021-09-30 00:06:28.021819
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 512 -nz 512
2021-09-30 00:06:37.845485
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 512 -nz 512
2021-09-30 00:06:59.501584
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 512 -nz 512
2021-09-30 00:07:10.128957
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 512 -nz 512
2021-09-30 00:07:20.383619
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 512 -nz 512
2021-09-30 00:07:30.359975
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512
2021-09-30 00:07:52.212857
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512
2021-09-30 00:08:02.118609
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512
2021-09-30 00:08:12.395406
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512
2021-09-30 00:08:22.083932
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512
2021-09-30 00:08:32.296346
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512
2021-09-30 00:08:42.200451
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512
2021-09-30 00:09:14.099264
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512
2021-09-30 00:09:24.357948
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512
2021-09-30 00:09:34.923888
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512
2021-09-30 00:09:47.793932
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 1024
2021-09-30 00:10:23.035454
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 1024
2021-09-30 00:10:35.034804
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 1024
2021-09-30 00:10:47.337983
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 1024
2021-09-30 00:10:58.489183
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 1024
2021-09-30 00:11:09.498941
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 1024
2021-09-30 00:11:21.493763
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 1024
2021-09-30 00:11:54.560771
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 1024
2021-09-30 00:12:06.479111
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 1024
2021-09-30 00:12:17.695374
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 1024
2021-09-30 00:12:29.523182
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 1024 -nz 1024
2021-09-30 00:13:03.988525
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 1024 -nz 1024
2021-09-30 00:13:17.968167
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 1024 -nz 1024
2021-09-30 00:13:30.072152
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 1024 -nz 1024
2021-09-30 00:13:42.999645
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 1024 -nz 1024
2021-09-30 00:13:55.126520
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 1024 -nz 1024
2021-09-30 00:14:09.119991
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 1024 -nz 1024
2021-09-30 00:15:04.010987
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 1024 -nz 1024
2021-09-30 00:15:17.657911
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 1024 -nz 1024
2021-09-30 00:15:29.233661
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 1024 -nz 1024
2021-09-30 00:15:43.046438
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024
2021-09-30 00:16:41.655632
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024
2021-09-30 00:16:59.377916
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024
2021-09-30 00:17:13.425644
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024
2021-09-30 00:17:30.504888
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024
2021-09-30 00:17:44.704162
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024
2021-09-30 00:18:02.277052
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024
2021-09-30 00:19:43.093684
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024
2021-09-30 00:20:01.155924
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024
2021-09-30 00:20:14.959575
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024
2021-09-30 00:20:34.636155
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048
2021-09-30 00:22:23.046389
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048
2021-09-30 00:22:49.193211
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048
2021-09-30 00:23:07.485957
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048
2021-09-30 00:23:31.517891
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048
2021-09-30 00:23:50.854111
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048
2021-09-30 00:24:17.527042
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048
2021-09-30 00:26:00.574887
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048
2021-09-30 00:26:27.593089
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048
2021-09-30 00:26:45.835046
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048
2021-09-30 00:27:14.033370
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048
2021-09-30 00:29:05.897924
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048
2021-09-30 00:29:50.303229
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048
2021-09-30 00:30:17.097629
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048
2021-09-30 00:30:57.270218
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048
2021-09-30 00:31:25.457545
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048
2021-09-30 00:32:08.222048
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048
2021-09-30 00:35:24.347720
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048
2021-09-30 00:36:10.521618
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048
2021-09-30 00:36:37.608638
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048
2021-09-30 00:37:25.137789
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048
2021-09-30 00:40:57.213002
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048
2021-09-30 00:42:16.213892
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048
2021-09-30 00:43:00.252086
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048
2021-09-30 00:44:11.419185
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048
2021-09-30 00:44:57.294359
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048
2021-09-30 00:46:14.779396
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048
2021-09-30 00:52:35.307623
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048
2021-09-30 00:53:56.825617
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048
2021-09-30 00:54:40.798822
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048
2021-09-30 00:56:06.340171
b''

Starting computation for size 128
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 01:03:03.177417
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 01:03:13.648483
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 01:03:23.937824
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 01:03:33.125659
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 01:03:42.829005
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 01:03:52.722184
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 01:04:02.715683
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 01:04:12.170810
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 01:04:22.151437
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 01:04:31.439939
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

Starting computation for size 256
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 01:04:41.542311
b'Result (avg): 5.01733e-09\nResult (max): 5.42241e-08\n'

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 01:04:50.889442
b'Result (avg): 5.01733e-09\nResult (max): 5.42241e-08\n'

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 01:05:00.745515
b'Result (avg): 5.01733e-09\nResult (max): 5.42241e-08\n'

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 01:05:10.031816
b'Result (avg): 5.01733e-09\nResult (max): 5.42241e-08\n'

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 01:05:20.493423
b'Result (avg): 5.01733e-09\nResult (max): 5.42241e-08\n'

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 01:05:30.703136
b'Result (avg): 5.01733e-09\nResult (max): 5.42241e-08\n'

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 01:05:41.453551
b'Result (avg): 5.01733e-09\nResult (max): 5.42241e-08\n'

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 01:05:51.166247
b'Result (avg): 5.01733e-09\nResult (max): 5.42241e-08\n'

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 01:06:01.603705
b'Result (avg): 5.01733e-09\nResult (max): 5.42241e-08\n'

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 01:06:11.429376
b'Result (avg): 5.01733e-09\nResult (max): 5.42241e-08\n'

Starting computation for size 512
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 01:06:22.526655
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 01:06:32.573105
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 01:06:43.191314
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 01:06:53.950823
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 01:07:04.424782
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 01:07:14.874476
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 01:07:28.101567
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 01:07:38.904408
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 01:07:49.612335
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 01:08:00.674372
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

Starting computation for size 1024
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 01:08:14.744887
b'Result (avg): 7.38396e-07\nResult (max): 8.69717e-06\n'

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 01:08:30.571437
b'Result (avg): 7.38396e-07\nResult (max): 8.69717e-06\n'

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 01:08:46.627359
b'Result (avg): 7.38396e-07\nResult (max): 8.69717e-06\n'

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 01:09:03.378302
b'Result (avg): 7.38396e-07\nResult (max): 8.69717e-06\n'

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 01:09:19.456560
b'Result (avg): 7.38396e-07\nResult (max): 8.69717e-06\n'

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 01:09:35.868236
b'Result (avg): 7.38396e-07\nResult (max): 8.69717e-06\n'

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 01:10:03.950781
b'Result (avg): 7.38396e-07\nResult (max): 8.69717e-06\n'

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 01:10:20.371709
b'Result (avg): 7.38396e-07\nResult (max): 8.69717e-06\n'

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 01:10:36.918909
b'Result (avg): 7.38396e-07\nResult (max): 8.69717e-06\n'

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 01:10:53.514932
b'Result (avg): 7.38396e-07\nResult (max): 8.69717e-06\n'

Starting computation for size 2048
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 01:11:19.789935
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 01:12:20.814262
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 01:13:18.451915
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 01:14:18.790252
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 01:15:15.288410
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 01:16:17.299426
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 01:17:52.289693
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 01:18:53.038681
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 01:19:55.148780
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 01:20:56.963230
b'Result (avg): -nan\nResult (max): -nan\n'

Slab 1D->2D opt1
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1186434] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1186434] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1186702] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1186702] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1186982] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1186982] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1187497] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1187497] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1187767] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1187767] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1188050] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1188050] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1188321] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1188321] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1188589] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1188589] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1188875] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1188875] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1189143] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1189143] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1189410] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1189410] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1189691] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1189691] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1189960] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1189960] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1190475] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1190475] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1190756] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1190756] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1191026] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1191026] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1191294] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1191294] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1191581] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1191581] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1191853] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1191853] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1192134] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1192134] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1192403] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1192403] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1192673] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1192673] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1192954] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1192954] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1193470] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1193470] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1193741] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1193741] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1194024] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1194024] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1194292] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1194292] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1194561] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1194561] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1194845] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1194845] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1195112] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1195112] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1195386] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1195386] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1195669] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1195669] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1195938] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1195938] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1196458] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1196458] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1196744] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1196744] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1197013] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1197013] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1197284] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1197284] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1197564] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1197564] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1197831] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1197831] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1198100] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1198100] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1198383] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1198383] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1198649] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1198649] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510:1198918:0:1198918] Caught signal 11 (Segmentation fault: address not mapped to object at address (nil))
==== backtrace (tid:1198918) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x0000000000158b62 __strcmp_avx2()  :0
 3 0x0000000000036d9d show_help.isra.2()  show_help.c:0
 4 0x0000000000037227 orte_show_help_recv()  ???:0
 5 0x00000000000c395b orte_rml_base_process_msg()  ???:0
 6 0x000000000001f9b5 event_priority_init()  ???:0
 7 0x00000000000203b7 event_base_loop()  ???:0
 8 0x0000000000400fca orterun()  ???:0
 9 0x00000000000236a3 __libc_start_main()  ???:0
10 0x0000000000400dce _start()  ???:0
=================================
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1199193] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1199193] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1199475] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1199475] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1199745] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1199745] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1200028] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1200028] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1200294] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1200294] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1200563] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1200563] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1200842] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1200842] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1201112] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1201112] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1201379] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1201379] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1201662] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1201662] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1202180] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1202180] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1202447] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1202447] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1202727] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1202727] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1203000] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1203000] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1203270] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1203270] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1203549] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1203549] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1203822] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1203822] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1204099] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1204099] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1204374] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1204374] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1204645] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1204645] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1205174] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1205174] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1205443] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1205443] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1205714] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1205714] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1205993] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1205993] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1206260] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1206260] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1206532] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1206532] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1206817] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1206817] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1207084] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1207084] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1207353] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1207353] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1207636] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1207636] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1208153] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1208153] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1208437] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1208437] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1208706] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1208706] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1208976] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1208976] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1209259] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1209259] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1209529] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1209529] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1209797] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1209797] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1210082] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1210082] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1210352] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1210352] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1210634] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1210634] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1211155] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1211155] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1211446] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1211446] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1211718] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1211718] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1211986] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1211986] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1212267] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1212267] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1212540] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1212540] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1212821] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1212821] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1213092] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1213092] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1213379] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1213379] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1213653] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1213653] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1214183] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1214183] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1214457] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1214457] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1214738] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1214738] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1215006] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1215006] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1215293] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1215293] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1215560] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1215560] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1215842] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1215842] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1216115] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1216115] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1216405] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1216405] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1216696] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1216696] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1217231] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1217231] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1217504] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1217504] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1217794] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1217794] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1218083] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1218083] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1218369] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1218369] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1218642] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1218642] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1218933] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1218933] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1219219] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1219219] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1219514] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1219514] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1219800] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1219800] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1220355] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1220355] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1220632] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1220632] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1220944] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1220944] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1221234] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1221234] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1221527] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1221527] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1221821] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1221821] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1222126] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1222126] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1222419] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1222419] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1222741] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1222741] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1223049] [[25579,0],0] ORTE_ERROR_LOG: Out of resource in file util/show_help.c at line 501
[uc2n510.localdomain:1223049] 30 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1223049] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1223622] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1223622] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1223927] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1223927] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1224253] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1224253] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1224560] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1224560] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1224884] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1224884] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1225192] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1225192] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1225517] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1225517] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1225870] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1225870] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1226138] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1226138] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1226423] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1226423] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1226714] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1226714] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1227001] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1227001] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1227280] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1227280] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1227547] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1227547] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1227820] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1227820] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1228099] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1228099] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1228369] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1228369] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1228637] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1228637] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1228907] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1228907] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1229191] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1229191] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1229487] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1229487] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1229771] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1229771] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1230055] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1230055] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1230330] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1230330] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1230596] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1230596] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1230878] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1230878] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1231150] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1231150] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1231416] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1231416] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1231699] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1231699] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1231971] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1231971] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1232262] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1232262] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1232557] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1232557] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1232828] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1232828] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1233095] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1233095] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1233377] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1233377] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1233647] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1233647] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1233917] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1233917] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1234203] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1234203] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1234474] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1234474] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1234757] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1234757] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1235052] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1235052] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1235351] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1235351] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1235625] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1235625] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1235915] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1235915] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1236186] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1236186] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1236469] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1236469] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1236742] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1236742] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1237022] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1237022] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1237337] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1237337] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1237654] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1237654] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1237996] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1237996] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1238325] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1238325] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1238644] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1238644] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1238955] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1238955] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1239273] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1239273] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1239585] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1239585] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1239904] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1239904] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
Starting computation for size 128
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128
2021-09-30 01:22:33.561911
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128
2021-09-30 01:22:43.846623
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128
2021-09-30 01:22:54.950506
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128
2021-09-30 01:23:04.711448
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128
2021-09-30 01:23:15.794305
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128
2021-09-30 01:23:25.795940
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128
2021-09-30 01:23:37.386436
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128
2021-09-30 01:23:47.411450
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128
2021-09-30 01:23:58.133348
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128
2021-09-30 01:24:07.890687
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256
2021-09-30 01:24:18.686830
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256
2021-09-30 01:24:28.583966
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256
2021-09-30 01:24:39.870080
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256
2021-09-30 01:24:49.649556
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256
2021-09-30 01:25:00.231444
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256
2021-09-30 01:25:09.962092
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256
2021-09-30 01:25:20.643236
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256
2021-09-30 01:25:30.671654
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256
2021-09-30 01:25:41.880156
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256
2021-09-30 01:25:51.816300
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256
2021-09-30 01:26:02.985823
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256
2021-09-30 01:26:12.938950
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256
2021-09-30 01:26:23.137024
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256
2021-09-30 01:26:32.622704
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256
2021-09-30 01:26:43.820646
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256
2021-09-30 01:26:53.326574
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256
2021-09-30 01:27:03.560398
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256
2021-09-30 01:27:13.059468
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256
2021-09-30 01:27:23.110385
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256
2021-09-30 01:27:33.630515
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256
2021-09-30 01:27:43.869503
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256
2021-09-30 01:27:53.432893
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256
2021-09-30 01:28:04.401906
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256
2021-09-30 01:28:14.279247
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256
2021-09-30 01:28:24.630520
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256
2021-09-30 01:28:34.202865
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256
2021-09-30 01:28:44.388447
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256
2021-09-30 01:28:54.040466
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256
2021-09-30 01:29:04.437957
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256
2021-09-30 01:29:13.785235
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512
2021-09-30 01:29:24.466729
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512
2021-09-30 01:29:34.394816
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512
2021-09-30 01:29:49.225248
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512
2021-09-30 01:29:53.130659
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512
2021-09-30 01:30:06.404156
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512
2021-09-30 01:30:16.007377
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512
2021-09-30 01:30:26.994474
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512
2021-09-30 01:30:36.757203
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512
2021-09-30 01:30:47.464392
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512
2021-09-30 01:30:57.263895
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512
2021-09-30 01:31:08.512563
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512
2021-09-30 01:31:18.324663
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512
2021-09-30 01:31:28.787731
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512
2021-09-30 01:31:38.605859
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512
2021-09-30 01:31:49.169397
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512
2021-09-30 01:31:59.066816
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512
2021-09-30 01:32:10.123221
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512
2021-09-30 01:32:20.983003
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512
2021-09-30 01:32:31.554928
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512
2021-09-30 01:32:41.510601
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512
2021-09-30 01:32:52.033287
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512
2021-09-30 01:33:02.432253
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512
2021-09-30 01:33:13.206995
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512
2021-09-30 01:33:23.590469
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512
2021-09-30 01:33:34.285081
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512
2021-09-30 01:33:44.814395
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512
2021-09-30 01:33:55.430951
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512
2021-09-30 01:34:05.934306
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512
2021-09-30 01:34:16.512695
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512
2021-09-30 01:34:27.084832
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-30 01:34:37.817100
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-30 01:34:49.244587
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-30 01:35:00.282660
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-30 01:35:11.456335
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-30 01:35:22.731450
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-30 01:35:34.268585
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-30 01:35:45.639732
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-30 01:35:57.137362
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-30 01:36:08.773164
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-30 01:36:20.706470
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-30 01:36:31.964924
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-30 01:36:45.678413
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-30 01:36:57.958548
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-30 01:37:11.828660
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-30 01:37:24.115291
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-30 01:37:38.149889
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-30 01:37:50.314141
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-30 01:38:04.126320
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-30 01:38:16.507076
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-30 01:38:29.786241
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-30 01:38:41.751682
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-30 01:38:59.356252
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-30 01:39:13.100788
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-30 01:39:29.514618
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-30 01:39:45.107104
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-30 01:40:03.005954
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-30 01:40:16.724536
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-30 01:40:35.556385
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-30 01:40:49.946129
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-30 01:41:07.325490
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-30 01:41:21.982720
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-30 01:41:49.044413
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-30 01:42:07.182261
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-30 01:42:31.391181
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-30 01:42:49.636148
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-30 01:43:15.478416
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-30 01:43:33.413035
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-30 01:43:59.970080
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-30 01:44:18.564780
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-30 01:44:44.799479
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-30 01:45:03.465303
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-30 01:45:48.043634
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-30 01:46:15.284254
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-30 01:46:55.170798
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-30 01:47:22.191449
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-30 01:48:06.688187
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-30 01:48:33.447292
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-30 01:49:18.240763
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-30 01:49:45.423775
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-30 01:50:27.898181
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-30 01:50:54.655744
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-30 01:52:15.843162
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-30 01:53:00.049735
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-30 01:54:11.822243
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-30 01:54:55.984436
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-30 01:56:15.758510
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-30 01:56:59.654578
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-30 01:58:22.061746
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-30 01:59:05.035699
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-30 02:00:21.800727
b''

Starting computation for size 128
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 02:01:06.756831
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 02:01:16.719231
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 02:01:26.535524
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 02:01:36.309457
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 02:01:45.891742
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 02:01:55.375179
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 02:02:05.020802
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 02:02:14.368566
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 02:02:24.501236
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 02:02:34.008286
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

Starting computation for size 256
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 02:02:43.795372
b'Result (avg): 5.19268e-09\nResult (max): 5.08699e-08\n'

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 02:02:52.961553
b'Result (avg): 5.19268e-09\nResult (max): 5.08699e-08\n'

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 02:03:02.830280
b'Result (avg): 5.19268e-09\nResult (max): 5.08699e-08\n'

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 02:03:12.160971
b'Result (avg): 5.19268e-09\nResult (max): 5.08699e-08\n'

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 02:03:22.897608
b'Result (avg): 5.19268e-09\nResult (max): 5.08699e-08\n'

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 02:03:32.487993
b'Result (avg): 5.19268e-09\nResult (max): 5.08699e-08\n'

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 02:03:42.120211
b'Result (avg): 5.19268e-09\nResult (max): 5.08699e-08\n'

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 02:03:51.388640
b'Result (avg): 5.19268e-09\nResult (max): 5.08699e-08\n'

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 02:04:01.147722
b'Result (avg): 5.19268e-09\nResult (max): 5.08699e-08\n'

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 02:04:10.603945
b'Result (avg): 5.19268e-09\nResult (max): 5.08699e-08\n'

Starting computation for size 512
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 02:04:21.058989
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 02:04:30.785679
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 02:04:41.126775
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 02:04:50.796446
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 02:05:01.000719
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 02:05:11.053368
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 02:05:21.354083
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 02:05:31.862191
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 02:05:42.150543
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 02:05:52.113474
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

Starting computation for size 1024
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 02:06:03.148517
b'Result (avg): 7.69765e-07\nResult (max): 9.22816e-06\n'

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 02:06:18.674877
b'Result (avg): 7.69765e-07\nResult (max): 9.22816e-06\n'

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 02:06:34.146300
b'Result (avg): 7.69765e-07\nResult (max): 9.22816e-06\n'

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 02:06:49.161740
b'Result (avg): 7.69765e-07\nResult (max): 9.22816e-06\n'

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 02:07:04.918908
b'Result (avg): 7.69765e-07\nResult (max): 9.22816e-06\n'

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 02:07:20.477219
b'Result (avg): 7.69765e-07\nResult (max): 9.22816e-06\n'

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 02:07:35.557606
b'Result (avg): 7.69765e-07\nResult (max): 9.22816e-06\n'

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 02:07:50.888313
b'Result (avg): 7.69765e-07\nResult (max): 9.22816e-06\n'

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 02:08:06.543226
b'Result (avg): 7.69765e-07\nResult (max): 9.22816e-06\n'

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 02:08:22.376907
b'Result (avg): 7.69765e-07\nResult (max): 9.22816e-06\n'

Starting computation for size 2048
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 02:08:37.693702
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 02:09:37.807162
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 02:10:35.315799
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 02:11:35.339796
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 02:12:31.426725
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 02:13:31.945636
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 02:14:28.160492
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 02:15:28.780929
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 02:16:24.997530
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 02:17:26.890499
b'Result (avg): -nan\nResult (max): -nan\n'

Slab 2D->1D default (inverse)
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1240209] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1240209] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1240486] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1240486] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1240755] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1240755] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1241269] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1241269] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1241550] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1241550] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1241825] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1241825] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1242090] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1242090] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1242377] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1242377] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1242646] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1242646] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1242914] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1242914] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1243192] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1243192] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1243460] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1243460] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1243740] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1243740] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1244258] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1244258] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1244529] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1244529] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1244814] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1244814] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1245083] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1245083] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1245356] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1245356] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1245641] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1245641] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1245910] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1245910] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1246181] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1246181] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1246463] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1246463] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1246736] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1246736] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1247251] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1247251] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1247536] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1247536] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1247809] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1247809] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1248077] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1248077] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1248359] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1248359] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1248628] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1248628] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1248900] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1248900] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1249181] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1249181] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1249454] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1249454] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1249720] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1249720] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1250253] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1250253] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1250524] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1250524] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1250795] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1250795] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1251075] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1251075] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1251346] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1251346] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1251625] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1251625] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1251894] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1251894] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1252165] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1252165] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1252451] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1252451] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1252721] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1252721] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1253241] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1253241] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1253521] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1253521] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1253789] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1253789] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1254061] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1254061] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1254344] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1254344] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1254614] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1254614] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1254883] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1254883] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1255168] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1255168] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1255436] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1255436] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1255705] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1255705] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1256238] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1256238] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1256511] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1256511] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1256779] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1256779] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1257057] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1257057] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1257328] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1257328] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1257613] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1257613] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1257882] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1257882] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1258155] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1258155] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1258436] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1258436] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1258706] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1258706] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1259227] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1259227] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1259511] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1259511] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1259782] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1259782] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1260052] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1260052] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1260336] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1260336] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1260606] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1260606] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1260874] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1260874] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1261154] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1261154] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1261424] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1261424] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1261709] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1261709] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1262227] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1262227] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1262496] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1262496] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1262786] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1262786] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1263057] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1263057] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1263335] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1263335] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1263609] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1263609] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1263878] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1263878] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1264160] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1264160] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1264432] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1264432] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1264702] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1264702] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1265236] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1265236] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1265507] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1265507] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1265791] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1265791] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1266061] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1266061] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1266343] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1266343] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1266613] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1266613] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1266883] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1266883] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1267169] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1267169] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1267445] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1267445] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1267720] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1267720] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1268253] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1268253] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1268525] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1268525] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1268816] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1268816] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1269086] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1269086] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1269372] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1269372] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1269644] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1269644] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1269927] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1269927] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1270201] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1270201] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1270497] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1270497] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1270779] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1270779] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1271304] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1271304] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1271586] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1271586] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1271876] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1271876] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1272148] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1272148] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1272438] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1272438] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1272722] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1272722] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1273016] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1273016] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1273288] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1273288] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1273594] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1273594] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1273886] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1273886] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1274431] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1274431] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1274715] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1274715] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1275013] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1275013] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1275301] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1275301] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1275610] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1275610] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1275888] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1275888] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1276191] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1276191] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1276478] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1276478] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1276800] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1276800] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1277108] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1277108] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1277678] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1277678] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1277974] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1277974] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1278305] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1278305] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1278597] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1278597] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1278921] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1278921] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1279231] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1279231] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1279545] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1279545] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
Starting computation for size 128
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 02:18:23.886709
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 02:18:33.921133
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 02:18:43.988051
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 02:18:53.549484
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 02:19:04.381185
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 02:19:13.878043
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 02:19:23.911699
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 02:19:33.771048
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 02:19:43.913431
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 02:19:53.852640
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 02:20:04.526428
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 02:20:16.294485
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 02:20:27.538996
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 02:20:37.304558
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 02:20:48.449897
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 02:20:58.344419
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 02:21:09.043977
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 02:21:19.007270
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 02:21:29.586267
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 02:21:39.493693
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 02:21:50.185712
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 02:22:00.218271
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 02:22:10.956024
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 02:22:20.833298
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 02:22:31.384794
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 02:22:41.687928
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 02:22:52.488308
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 02:23:02.396395
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 02:23:13.067184
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 02:23:22.971439
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 02:23:33.765015
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 02:23:43.649882
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 02:23:54.083810
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 02:24:03.961831
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 02:24:14.715023
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 02:24:24.550264
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 02:24:35.051641
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 02:24:45.156594
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 02:24:55.814064
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 02:25:05.972390
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 02:25:16.747074
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 02:25:26.824413
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 02:25:37.221996
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 02:25:47.400305
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 02:25:58.090532
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 02:26:08.092955
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 02:26:18.775808
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 02:26:28.900905
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 02:26:39.477139
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 02:26:49.416242
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 02:27:00.165279
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 02:27:10.483835
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 02:27:21.379903
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 02:27:31.616472
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 02:27:43.444896
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 02:27:53.735040
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 02:28:04.743388
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 02:28:15.047198
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 02:28:26.560881
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 02:28:36.427008
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 02:28:46.919044
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 02:28:57.312923
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 02:29:08.770427
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 02:29:19.858271
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 02:29:31.148611
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 02:29:42.128812
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 02:29:52.820765
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 02:30:03.195225
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 02:30:13.929983
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 02:30:24.348365
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 02:30:35.186301
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 02:30:46.734286
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 02:30:57.809222
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 02:31:08.850384
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 02:31:20.302570
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 02:31:32.254131
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 02:31:43.663203
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 02:31:55.619126
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 02:32:06.665161
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 02:32:18.109031
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 02:32:29.472215
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 02:32:43.019423
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 02:32:55.012766
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 02:33:08.326375
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 02:33:20.431754
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 02:33:33.887114
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 02:33:45.877698
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 02:33:59.494721
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 02:34:11.536223
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 02:34:25.035137
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 02:34:37.384126
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 02:34:55.684783
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 02:35:09.493899
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 02:35:26.093082
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 02:35:39.995823
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 02:35:57.420034
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 02:36:11.482327
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 02:36:29.666290
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 02:36:43.659164
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 02:37:01.617284
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 02:37:15.883705
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 02:37:42.156640
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 02:38:00.006921
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 02:38:23.605246
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 02:38:41.622169
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 02:39:06.960839
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 02:39:24.808968
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 02:39:51.453966
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 02:40:09.939360
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 02:40:35.685041
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 02:40:54.490170
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 02:41:39.009815
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 02:42:04.661096
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 02:42:42.675707
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 02:43:07.083018
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 02:43:48.183838
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 02:44:13.670055
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 02:44:57.050426
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 02:45:22.639270
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 02:46:03.742279
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 02:46:29.085434
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 02:47:46.473208
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 02:48:26.622120
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 02:49:33.331491
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 02:50:14.472055
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 02:51:27.333237
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 02:52:08.443962
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 02:53:26.477718
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 02:54:07.437218
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 02:55:20.918161
b''

Slab 2D->1D opt1 (inverse)
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1279857] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1279857] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1280125] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1280125] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1280394] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1280394] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1280921] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1280921] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1281438] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1281438] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1281707] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1281707] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1281992] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1281992] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1282260] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1282260] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1282532] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1282532] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1282802] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1282802] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1283087] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1283087] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1283358] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1283358] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1283627] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1283627] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1284157] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1284157] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1284673] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1284673] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1284942] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1284942] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1285230] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1285230] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1285500] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1285500] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1285771] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1285771] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1286052] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1286052] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1286320] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1286320] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1286592] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1286592] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1286873] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1286873] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1287391] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1287391] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1287908] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1287908] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1288192] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1288192] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1288464] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1288464] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1288733] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1288733] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1289013] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1289013] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1289282] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1289282] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1289555] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1289555] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1289880] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1289880] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1290152] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1290152] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1290667] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1290667] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1291200] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1291200] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1291465] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1291465] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1291739] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1291739] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1292019] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1292019] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1292292] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1292292] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1292560] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1292560] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1292842] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1292842] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1293112] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1293112] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1293381] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1293381] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1293916] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1293916] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1294432] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1294432] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1294702] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1294702] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1294985] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1294985] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1295256] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1295256] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1295534] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1295534] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1295804] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1295804] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1296076] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1296076] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1296361] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1296361] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1296632] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1296632] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1297150] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1297150] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1297678] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1297678] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1297945] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1297945] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1298235] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1298235] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1298502] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1298502] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1298771] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1298771] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1299054] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1299054] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1299331] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1299331] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1299612] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1299612] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1299882] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1299882] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1300398] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1300398] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1300928] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1300928] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1301196] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1301196] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1301488] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1301488] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1301756] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1301756] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1302036] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1302036] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1302304] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1302304] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1302592] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1302592] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1302862] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1302862] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1303134] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1303134] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1303669] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1303669] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1304186] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1304186] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1304456] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1304456] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1304763] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1304763] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1305033] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1305033] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1305304] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1305304] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1305588] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1305588] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1305877] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1305877] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1306151] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1306151] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1306435] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1306435] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1306954] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1306954] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1307487] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1307487] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1307761] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1307761] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1308065] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1308065] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1308336] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1308336] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1308622] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1308622] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1308898] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1308898] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1309209] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1309209] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1309495] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1309495] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1309767] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1309767] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1310300] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1310300] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1310817] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1310817] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1311101] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1311101] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1311413] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1311413] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1311698] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1311698] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1311972] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1311972] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1312258] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1312258] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1312565] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1312565] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1312856] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1312856] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1313126] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1313126] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1313661] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1313661] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1314192] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1314192] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1314482] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1314482] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1314824] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1314824] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1315113] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1315113] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1315398] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1315398] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1315691] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1315691] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1316041] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1316041] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1316345] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1316345] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1316635] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1316635] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1317181] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1317181] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1317718] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1317718] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1318025] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1318025] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1318451] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1318451] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1318761] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1318761] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1319045] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1319045] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1319345] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1319345] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1319790] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1319790] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1320123] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1320123] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1320422] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1320422] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1321084] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1321084] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1321631] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1321631] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1321961] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1321961] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1322405] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1322405] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1322735] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1322735] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1323045] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1323045] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1323383] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1323383] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
Starting computation for size 128
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 02:56:03.484780
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 02:56:12.470748
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 02:56:22.169968
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 02:56:30.735673
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 02:56:40.076365
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 02:56:48.647146
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 02:56:58.607173
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 02:57:07.617845
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 02:57:17.277841
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 02:57:25.695529
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 02:57:35.769731
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 02:57:44.408786
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 02:57:53.725351
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 02:58:02.611266
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 02:58:11.933555
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 02:58:20.532197
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 02:58:31.681052
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 02:58:40.353170
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 02:58:49.970653
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 02:58:59.785868
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 02:59:10.703124
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 02:59:19.749663
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 02:59:29.717578
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 02:59:38.800537
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 02:59:51.065467
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 03:00:00.063809
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 03:00:12.791720
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 03:00:21.894332
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 03:00:31.656962
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 03:00:40.931595
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 03:00:53.536472
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 03:01:02.650691
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 03:01:13.261477
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 03:01:22.273775
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 03:01:32.033196
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 03:01:41.572611
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 03:01:54.158477
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 03:02:03.239569
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 03:02:12.892800
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 03:02:21.904694
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 03:02:34.588776
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 03:02:44.536714
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 03:02:54.435405
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 03:03:03.619586
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 03:03:13.514424
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 03:03:22.703813
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 03:03:38.587148
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 03:03:47.858348
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 03:03:57.816777
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 03:04:07.167393
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 03:04:23.639168
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 03:04:33.197819
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 03:04:43.176306
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 03:04:52.855589
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 03:05:02.701660
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 03:05:12.272596
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 03:05:33.317653
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 03:05:42.980078
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 03:05:52.840634
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 03:06:02.548214
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 03:06:24.426445
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 03:06:35.468712
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 03:06:45.816846
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 03:06:55.995846
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 03:07:06.271550
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 03:07:16.516298
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 03:07:37.754310
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 03:07:47.831968
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 03:07:58.703133
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 03:08:08.786094
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 03:08:30.808621
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 03:08:41.904984
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 03:08:53.516241
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 03:09:04.193286
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 03:09:15.682264
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 03:09:26.957496
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 03:09:59.861404
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 03:10:11.721582
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 03:10:23.442273
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 03:10:35.028182
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 03:11:09.617867
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 03:11:23.456408
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 03:11:35.681824
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 03:11:48.809956
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 03:12:01.057896
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 03:12:14.949493
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 03:13:10.706791
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 03:13:24.803001
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 03:13:37.565101
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 03:13:52.252095
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 03:14:51.868382
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 03:15:10.334290
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 03:15:24.936377
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 03:15:42.004202
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 03:15:56.690912
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 03:16:14.757832
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 03:17:11.870068
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 03:17:30.648660
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 03:17:45.809663
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 03:18:04.924130
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 03:19:06.540465
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 03:19:33.527054
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 03:19:52.350030
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 03:20:16.957389
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 03:20:36.404116
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 03:21:03.121248
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 03:22:46.809923
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 03:23:14.440990
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 03:23:32.970919
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 03:24:01.713416
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 03:25:53.297455
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 03:26:38.700778
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 03:27:07.010743
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 03:27:47.676302
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 03:28:16.543406
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 03:28:59.984274
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 03:32:17.042614
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 03:33:02.328397
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 03:33:29.423017
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 03:34:16.757791
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 03:37:49.133434
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 03:39:08.998433
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 03:39:52.208620
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 03:41:04.168397
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 03:41:52.017285
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 03:43:09.276839
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 03:46:37.745902
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 03:47:59.262457
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 03:48:44.959345
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 03:50:09.930733
b''

Slab 1D->2D default (inverse)
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1323828] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1323828] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1324112] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1324112] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1324382] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1324382] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1324902] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1324902] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1325185] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1325185] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1325453] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1325453] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1325726] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1325726] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1326005] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1326005] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1326273] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1326273] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1326539] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1326539] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1326826] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1326826] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1327096] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1327096] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1327376] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1327376] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1327889] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1327889] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1328160] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1328160] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1328439] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1328439] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1328711] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1328711] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1328979] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1328979] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1329262] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1329262] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1329529] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1329529] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1329800] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1329800] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1330084] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1330084] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1330354] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1330354] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1330870] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1330870] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1331150] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1331150] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1331420] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1331420] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1331707] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1331707] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1331977] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1331977] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1332248] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1332248] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1332526] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1332526] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1332798] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1332798] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1333080] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1333080] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1333349] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1333349] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1333869] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1333869] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1334152] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1334152] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1334419] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1334419] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1334704] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1334704] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1334976] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1334976] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1335242] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1335242] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1335566] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1335566] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1335857] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1335857] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1336127] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1336127] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1336398] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1336398] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1336928] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1336928] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1337195] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1337195] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1337464] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1337464] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1337749] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1337749] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1338018] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1338018] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1338302] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1338302] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1338569] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1338569] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1338860] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1338860] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1339130] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1339130] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1339408] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1339408] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1339924] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1339924] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1340194] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1340194] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1340473] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1340473] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1340773] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1340773] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1341044] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1341044] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1341325] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1341325] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1341596] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1341596] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1341895] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1341895] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1342163] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1342163] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1342445] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1342445] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1342962] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1342962] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1343230] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1343230] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1343510] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1343510] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1343830] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1343830] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1344102] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1344102] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1344385] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1344385] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1344655] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1344655] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1344977] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1344977] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1345245] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1345245] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1345526] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1345526] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1346046] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1346046] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1346330] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1346330] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1346600] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1346600] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1346916] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1346916] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1347186] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1347186] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1347472] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1347472] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1347742] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1347742] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1348055] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1348055] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1348341] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1348341] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1348614] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1348614] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1349128] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1349128] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1349409] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1349409] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1349683] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1349683] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1350044] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1350044] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1350332] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1350332] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1350603] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1350603] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1350877] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1350877] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1351248] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1351248] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1351532] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1351532] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1351801] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1351801] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1352336] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1352336] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1352605] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1352605] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1352893] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1352893] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1353335] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1353335] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1353627] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1353627] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1353899] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1353899] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1354184] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1354184] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1354623] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1354623] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1354914] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1354914] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1355199] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1355199] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1355734] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1355734] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1356010] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1356010] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1356305] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1356305] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1356759] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1356759] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1357050] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1357050] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1357325] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1357325] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1357612] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1357612] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1358071] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1358071] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1358368] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1358368] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1358657] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1358657] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1359202] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1359202] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1359491] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1359491] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1359802] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1359802] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1360420] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1360420] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1360732] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1360732] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1361008] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1361008] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1361320] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1361320] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1361960] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1361960] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1362281] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1362281] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1362593] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1362593] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1363206] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1363206] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1363507] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1363507] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1363850] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1363850] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1364803] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1364803] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1365140] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1365140] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1365449] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1365449] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1365776] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1365776] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
Starting computation for size 128
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 03:53:54.651905
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 03:54:04.425542
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 03:54:15.082649
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 03:54:24.695019
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 03:54:35.146969
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 03:54:44.928108
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 03:54:58.512356
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 03:55:08.108581
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 03:55:18.909341
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 03:55:28.527371
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 03:55:42.380868
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 03:55:51.873775
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 03:56:02.213840
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 03:56:11.619516
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 03:56:21.885469
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 03:56:31.323145
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 03:56:44.768453
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 03:56:54.379689
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 03:57:04.573938
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 03:57:14.317695
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 03:57:28.140152
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 03:57:38.082540
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 03:57:48.657282
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 03:57:58.146802
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 03:58:08.494596
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 03:58:17.963571
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 03:58:35.040486
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 03:58:44.733530
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 03:58:54.933042
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 03:59:05.107875
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 03:59:22.379070
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 03:59:32.127139
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 03:59:42.930807
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 03:59:52.843684
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 04:00:03.194162
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 04:00:13.470964
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 04:00:37.465669
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 04:00:47.078376
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 04:00:57.359617
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 04:01:06.994210
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 04:01:31.802575
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 04:01:41.542448
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 04:01:52.007847
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 04:02:02.172786
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 04:02:12.418657
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 04:02:22.055203
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 04:02:46.162168
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 04:02:55.989302
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 04:03:06.377311
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 04:03:16.063665
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 04:03:40.978130
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 04:03:50.798828
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 04:04:01.367784
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 04:04:11.132660
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 04:04:21.486212
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 04:04:31.527508
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 04:05:10.929251
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 04:05:20.878883
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 04:05:31.349612
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 04:05:41.245849
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 04:06:19.462544
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 04:06:29.589760
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 04:06:39.902944
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 04:06:49.608491
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 04:06:59.975679
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 04:07:10.301258
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 04:08:14.696187
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 04:08:24.834957
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 04:08:35.104281
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 04:08:45.436273
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 04:09:49.235341
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 04:10:00.497229
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 04:10:11.227592
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 04:10:22.320267
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 04:10:33.000226
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 04:10:44.918231
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 04:11:48.358550
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 04:11:59.463777
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 04:12:10.191394
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 04:12:21.235377
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 04:13:25.407678
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 04:13:38.136019
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 04:13:49.350981
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 04:14:01.475810
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 04:14:12.903756
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 04:14:26.696559
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 04:16:21.577611
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 04:16:34.651372
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 04:16:45.992841
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 04:16:59.481258
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 04:18:56.677484
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 04:19:13.901547
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 04:19:27.804989
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 04:19:43.801114
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 04:19:57.504737
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 04:20:16.505487
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 04:23:53.878245
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 04:24:11.809038
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 04:24:25.363297
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 04:24:44.991253
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 04:28:28.731134
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 04:28:55.292027
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 04:29:13.408898
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 04:29:37.285210
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 04:29:59.900219
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 04:30:28.413441
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 04:34:10.669462
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 04:34:38.511640
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 04:34:56.289606
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 04:35:24.399340
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 04:39:12.241418
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 04:39:56.193622
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 04:40:22.790915
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 04:41:01.628055
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 04:41:27.609934
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 04:42:15.913629
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 04:49:22.572551
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 04:50:06.884714
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 04:50:33.660054
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 04:51:21.050319
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 04:58:41.227007
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 05:00:00.574405
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 05:00:43.988070
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 05:01:53.788009
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 05:02:38.309597
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 05:04:06.242143
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 05:18:02.898223
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 05:19:22.505928
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 05:20:05.393428
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 05:21:31.833255
b''

Slab 1D->2D opt1 (inverse)
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1366762] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1366762] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1367027] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1367027] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1367312] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1367312] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1367827] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1367827] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1368346] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1368346] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1368628] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1368628] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1368898] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1368898] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1369168] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1369168] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1369449] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1369449] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1369716] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1369716] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1369988] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1369988] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1370275] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1370275] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1370546] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1370546] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1371063] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1371063] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1371591] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1371591] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1371862] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1371862] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1372132] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1372132] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1372399] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1372399] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1372679] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1372679] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1372946] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1372946] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1373216] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1373216] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1373501] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1373501] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1373771] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1373771] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1374288] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1374288] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1374817] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1374817] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1375088] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1375088] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1375354] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1375354] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1375634] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1375634] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1375905] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1375905] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1376172] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1376172] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1376455] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1376455] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1376727] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1376727] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1376999] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1376999] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1377527] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1377527] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1378045] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1378045] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1378315] 31 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1378315] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49987,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49992,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[50006,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[50012,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[50010,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49952,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49966,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49972,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49970,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49976,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49926,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49932,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49930,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49936,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49950,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[50148,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[50146,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[50152,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[50166,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[50172,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[50170,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[50112,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[50126,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[50132,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[50130,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[50136,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[50086,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[50092,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[50090,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[50096,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[50110,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[50052,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[50050,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[50056,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[50070,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[50076,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[50074,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49248,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49262,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49268,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49266,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49272,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49222,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49228,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49226,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49232,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49246,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49188,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49186,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49192,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49206,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49212,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49210,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49152,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49166,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49172,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49170,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49176,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49382,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49388,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49386,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49392,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49406,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49348,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49346,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49352,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49366,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49372,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49370,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49312,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49321,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49334,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49340,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49285,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49283,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49289,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49303,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49309,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49307,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49505,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49519,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49525,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49523,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49529,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49479,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49485,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49483,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49489,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49503,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49445,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49443,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49451,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49457,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
A hostfile was provided that contains at least one node not
present in the allocation:

  hostfile:  ../mpi/hostfile_0
  node:      uc2n484

If you are operating in a resource-managed environment, then only
nodes that are in the allocation can be used in the hostfile. You
may find relative node syntax to be a useful alternative to
specifying absolute node names see the orte_hosts man page for
further information.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An internal error has occurred in ORTE:

[[49471,0],0] FORCE-TERMINATE AT (null):1 - error plm_slurm_module.c(474)

This is something that should be reported to the developers.
--------------------------------------------------------------------------
Starting computation for size 128
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 05:35:53.499121
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 05:36:02.567599
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 05:36:12.577569
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 05:36:21.455268
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 05:36:31.630718
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 05:36:40.671035
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 05:36:50.526575
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 05:36:59.624424
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 05:37:09.516155
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 05:37:18.604965
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 05:37:28.533134
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 05:37:37.418344
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 05:37:47.372260
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 05:37:56.625102
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 05:38:07.085183
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 05:38:16.072954
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 05:38:26.068878
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 05:38:35.297523
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 05:38:45.109916
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 05:38:54.122436
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 05:39:03.981981
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 05:39:14.226950
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 05:39:24.790500
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 05:39:34.275191
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 05:39:44.479841
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 05:39:54.134950
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 05:40:04.395404
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 05:40:13.773862
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 05:40:24.111567
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 05:40:33.825678
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 05:40:44.082988
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 05:40:53.708950
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 05:41:04.306002
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 05:41:14.380025
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 05:41:24.941276
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 05:41:34.740054
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 05:41:45.437190
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 05:41:45.583898
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 05:41:45.676165
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 05:41:45.762512
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 05:41:45.848558
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 05:41:45.938626
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 05:41:46.024818
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 05:41:46.114322
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 05:41:46.202231
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 05:41:46.289553
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 05:41:46.376913
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 05:41:46.467784
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 05:41:46.554362
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 05:41:46.644384
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 05:41:46.730835
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 05:41:46.817818
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 05:41:46.904635
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 05:41:46.993144
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 05:41:47.081184
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 05:41:47.168602
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 05:41:47.255899
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 05:41:47.344650
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 05:41:47.434496
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 05:41:47.524682
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 05:41:47.612563
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 05:41:47.701604
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 05:41:47.788972
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 05:41:47.876499
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 05:41:47.962712
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 05:41:48.049377
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 05:41:48.137328
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 05:41:48.226252
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 05:41:48.314930
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 05:41:48.401448
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 05:41:48.490092
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 05:41:48.576953
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 05:41:48.662513
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 05:41:48.750181
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 05:41:48.837363
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 05:41:48.925589
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 05:41:49.014294
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 05:41:49.103075
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 05:41:49.189218
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 05:41:49.279492
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 05:41:49.367784
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 05:41:49.455689
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 05:41:49.542750
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 05:41:49.631829
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 05:41:49.717654
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 05:41:49.803880
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 05:41:49.893379
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 05:41:49.981899
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 05:41:50.070309
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 05:41:50.158422
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 05:41:50.246725
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 05:41:50.334211
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 05:41:50.433524
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 05:41:50.521054
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 05:41:50.608887
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 05:41:50.695500
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 05:41:50.781123
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 05:41:50.869401
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 05:41:50.956251
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 05:41:51.042506
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 05:41:51.129824
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 05:41:51.217616
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 05:41:51.304035
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 05:41:51.393425
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 05:41:51.482485
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 05:41:51.570883
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 05:41:51.657345
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 05:41:51.746366
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 05:41:51.834869
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 05:41:51.921871
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 05:41:52.010611
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 05:41:52.099183
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 05:41:52.187735
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 05:41:52.274219
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 05:41:52.361625
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 05:41:52.451279
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 05:41:52.539977
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 05:41:52.626891
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 05:41:52.714954
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 05:41:52.803810
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 05:41:52.891095
b''

-> Executing test 1
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 05:41:52.978572
b''

-> Executing test 2
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 05:41:53.067667
b''

-> Executing test 3
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 05:41:53.154828
b''

-> Executing test 4
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 05:41:53.240864
b''

-> Executing test 5
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 05:41:53.329420
b''

-> Executing test 6
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 05:41:53.415877
b''

-> Executing test 7
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 05:41:53.504281
b''

-> Executing test 8
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 05:41:53.591573
b''

-> Executing test 9
mpiexec -n 32 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 32 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 05:41:53.678457
b''

Starting on HOST16
-----------------------------------------------------------------------------
Slab 2D->1D default/opt1
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1379170] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1379170] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1379173] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1379173] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1379448] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1379448] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1379466] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1379466] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1379741] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1379741] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1379762] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1379762] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1380023] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1380023] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1380292] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1380292] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1380554] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1380554] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1380823] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1380823] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1381084] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1381084] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1381114] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1381114] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1381365] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1381365] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1381394] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1381394] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1381646] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1381646] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1381674] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1381674] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1381934] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1381934] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1381964] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1381964] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1382086] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1382086] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1382244] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1382244] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1382496] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1382496] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1382525] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1382525] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1382682] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1382682] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1382823] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1382823] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1382979] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1382979] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1383106] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1383106] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1383201] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1383201] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1383730] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1383730] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1383634] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1383634] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1384167] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1384167] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1384188] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1384188] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1384446] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1384446] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1384548] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1384548] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1384730] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1384730] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1384825] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1384825] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1385022] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1385022] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1385119] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1385119] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1385297] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1385297] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1385318] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1385318] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1385582] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1385582] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1385706] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1385706] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1385878] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1385878] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1385976] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1385976] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1386158] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1386158] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1386258] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1386258] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1386437] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1386437] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1386455] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1386455] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1386980] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1386980] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1386998] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1386998] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1387510] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1387510] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1387527] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1387527] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1387794] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1387794] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1388048] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1388048] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1388086] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1388086] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1388342] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1388342] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1388368] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1388368] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1388625] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1388625] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1388651] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1388651] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1388907] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1388907] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1388949] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1388949] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1389224] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1389224] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1389216] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1389216] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1389496] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1389496] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1389508] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1389508] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1389787] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1389787] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1389805] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1389805] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1390318] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1390318] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1390336] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1390336] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1390848] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1390848] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1390866] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1390866] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1391142] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1391142] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1391162] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1391162] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1391426] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1391426] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1391684] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1391684] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1391710] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1391710] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1391964] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1391964] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1392006] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1392006] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1392251] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1392251] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1392285] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1392285] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1392459] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1392459] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1392567] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1392567] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1392856] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1392856] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1392848] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1392848] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1393136] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1393136] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1393124] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1393124] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1393658] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1393658] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1393753] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1393753] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1394197] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1394197] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1394293] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1394293] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1394476] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1394476] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1394573] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1394573] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1394757] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1394757] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1394854] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1394854] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1395053] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1395053] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1395326] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1395326] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1395423] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1395423] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1395607] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1395607] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1395704] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1395704] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1395900] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1395900] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1396010] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1396010] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1396179] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1396179] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1396276] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1396276] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1396460] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1396460] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1396987] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1396987] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1397237] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1397237] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1397516] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1397516] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1397767] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1397767] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1397795] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1397795] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1398063] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1398063] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1398092] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1398092] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1398341] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1398341] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1398372] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1398372] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1398626] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1398626] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1398655] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1398655] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1398920] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1398920] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1398951] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1398951] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1399219] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1399219] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1399494] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1399494] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1399757] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1399757] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1399775] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1399775] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1400039] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1400039] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1400305] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1400305] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1400558] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1400558] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1400848] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1400848] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1401105] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1401105] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1401130] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1401130] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1401401] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1401401] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1401678] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1401678] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1401939] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1401939] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1401959] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1401959] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1402222] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1402222] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1402240] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1402240] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1402516] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1402516] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1402534] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1402534] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1402795] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1402795] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1402815] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1402815] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1403071] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1403071] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1403113] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1403113] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1403367] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1403367] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1403643] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1403643] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1404159] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1404159] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1404439] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1404439] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1404695] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1404695] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1404723] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1404723] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1404977] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1404977] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1405018] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1405018] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1405136] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1405136] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1405299] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1405299] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1405396] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1405396] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1405580] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1405580] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1405866] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1405866] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1406135] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1406135] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1406232] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1406232] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1406425] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1406425] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1406443] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1406443] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1406876] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1406876] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1406976] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1406976] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1407286] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1407286] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1407515] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1407515] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1407775] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1407775] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1407796] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1407796] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1408052] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1408052] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1408099] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1408099] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1408366] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1408366] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1408649] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1408649] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1408917] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1408917] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1409191] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1409191] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1409214] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1409214] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1409476] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1409476] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1409499] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1409499] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1409517] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1409517] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1409799] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1409799] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1409819] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1409819] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1410349] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1410349] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1410864] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1410864] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1411143] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1411143] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1411163] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1411163] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1411441] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1411441] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1411459] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1411459] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1411723] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1411723] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1411746] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1411746] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1412000] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1412000] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1412041] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1412041] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1412136] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1412136] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1412363] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1412363] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1412396] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1412396] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1412662] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1412662] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1412957] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1412957] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1413242] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1413242] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1413777] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1413777] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1413792] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1413792] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1414226] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1414226] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1414343] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1414343] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1414595] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1414595] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1414638] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1414638] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1414661] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1414661] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1414946] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1414946] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1415237] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1415237] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1415520] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1415520] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1415800] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1415800] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1415828] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1415828] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1416106] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1416106] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1416128] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1416128] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1416132] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1416132] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1416416] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1416416] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1416446] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1416446] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1416474] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1416474] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1416735] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1416735] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1416785] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1416785] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1417343] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1417343] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1417789] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1417789] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1417912] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1417912] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1418174] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1418174] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1418205] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1418205] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1418232] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1418232] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1418261] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1418261] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1418550] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1418550] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1418864] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1418864] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1419141] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1419141] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1419167] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1419167] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1419443] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1419443] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1419483] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1419483] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1419525] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1419525] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1419786] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1419786] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1419819] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1419819] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1419842] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1419842] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1420131] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1420131] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1420215] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1420215] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1420531] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1420531] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1421052] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1421052] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1421154] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1421154] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1421431] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1421431] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1421562] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1421562] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1421745] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1421745] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1421997] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1421997] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1422117] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1422117] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1422436] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1422436] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n511:1790109:0:1790109] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14f9742c0000)
[uc2n511:1790106:0:1790106] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14557c200000)
[uc2n511:1790113:0:1790113] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14bf283c0000)
[uc2n511:1790111:0:1790111] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14b4a8340000)
[uc2n511:1790108:0:1790108] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14b314280000)
[uc2n511:1790112:0:1790112] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14bb84380000)
[uc2n511:1790110:0:1790110] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x152a20300000)
[uc2n511:1790107:0:1790107] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14826c240000)
==== backtrace (tid:1790107) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001069f MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
 9 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
10 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
11 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1790106) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001069f MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
 9 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
10 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
11 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1790112) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001069f MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
 9 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
10 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
11 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1790113) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001069f MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
 9 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
10 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
11 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1790108) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001069f MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
 9 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
10 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
11 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1790109) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001069f MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
 9 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
10 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
11 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1790110) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001069f MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
 9 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
10 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
11 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1790111) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001069f MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
 9 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
10 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
11 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 12 with PID 1790110 on node uc2n511 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1422720] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1422720] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n511:1790465:0:1790465] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x145f7e300010)
[uc2n511:1790468:0:1790468] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14d8403c0010)
[uc2n511:1790466:0:1790466] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1505b2340010)
[uc2n511:1790467:0:1790467] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14708a380010)
[uc2n511:1790464:0:1790464] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1544fe2c0010)
[uc2n511:1790462:0:1790462] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x154920240010)
[uc2n511:1790463:0:1790463] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x151b40280010)
[uc2n511:1790461:0:1790461] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x149f6a200010)
==== backtrace (tid:1790465) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000001069f MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
18 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
19 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
20 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
21 0x000000000040332f main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1790466) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000001069f MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
18 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
19 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
20 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
21 0x000000000040332f main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1790468) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000001069f MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
18 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
19 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
20 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
21 0x000000000040332f main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1790461) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000001069f MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
18 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
19 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
20 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
21 0x000000000040332f main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1790463) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000001069f MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
18 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
19 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
20 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
21 0x000000000040332f main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1790464) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000001069f MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
18 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
19 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
20 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
21 0x000000000040332f main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1790462) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000001069f MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
18 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
19 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
20 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
21 0x000000000040332f main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1790467) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000001069f MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
18 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
19 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
20 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
21 0x000000000040332f main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 13 with PID 1790466 on node uc2n511 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1422993] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1422993] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n511:1790799:0:1790799] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1528e8300000)
[uc2n511:1790798:0:1790798] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1502602c0000)
[uc2n511:1790802:0:1790802] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14bb463c0000)
[uc2n511:1790801:0:1790801] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1479ae380000)
[uc2n511:1790800:0:1790800] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x151034340000)
[uc2n511:1790796:0:1790796] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14ef84240000)
[uc2n511:1790795:0:1790795] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x153bc0200000)
[uc2n511:1790797:0:1790797] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c620280000)
==== backtrace (tid:1790799) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010d69 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
 9 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
10 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1790798) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010d69 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
 9 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
10 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1790802) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010d69 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
 9 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
10 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1790801) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010d69 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
 9 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
10 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1790800) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010d69 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
 9 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
10 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1790796) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010d69 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
 9 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
10 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1790797) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010d69 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
 9 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
10 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1790795) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010d69 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
 9 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
10 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 12 with PID 1790799 on node uc2n511 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1423268] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1423268] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n511:1791148:0:1791148] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1452de340000)
[uc2n511:1791150:0:1791150] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14bece3c0000)
[uc2n511:1791144:0:1791144] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1479f6240000)
[uc2n511:1791145:0:1791145] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x145ada280000)
[uc2n511:1791147:0:1791147] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x153b9e300000)
[uc2n511:1791146:0:1791146] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e9002c0000)
[uc2n511:1791149:0:1791149] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x150fb6380000)
[uc2n511:1791143:0:1791143] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e6d2200000)
==== backtrace (tid:1791145) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010d69 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
 9 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
10 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1791146) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010d69 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
 9 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
10 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1791144) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010d69 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
 9 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
10 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1791147) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010d69 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
 9 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
10 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1791150) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010d69 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
 9 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
10 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1791143) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010d69 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
 9 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
10 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1791149) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010d69 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
 9 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
10 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1791148) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010d69 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
 9 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
10 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[uc2n510.localdomain:1423446] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1423446] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec noticed that process rank 11 with PID 1791146 on node uc2n511 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1423566] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1423566] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1423832] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1423832] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1424099] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1424099] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1424396] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1424396] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1424687] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1424687] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1424956] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1424956] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1425219] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1425219] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1425237] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1425237] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1425517] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1425517] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1425786] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1425786] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1426052] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1426052] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1426330] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1426330] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1426427] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1426427] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1426611] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1426611] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1426879] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1426879] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1427184] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1427184] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1427464] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1427464] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1427731] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1427731] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1428014] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1428014] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1428264] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1428264] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1428290] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1428290] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1428557] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1428557] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1428832] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1428832] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1429101] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1429101] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1429362] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1429362] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1429382] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1429382] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1429666] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1429666] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1429958] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1429958] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1430244] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1430244] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1430521] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1430521] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1430792] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1430792] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1431059] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1431059] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1431339] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1431339] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1431347] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1431347] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1431621] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1431621] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1431888] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1431888] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1432173] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1432173] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1432455] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1432455] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1432752] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1432752] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1433049] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1433049] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1433338] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1433338] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1433609] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1433609] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1433893] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1433893] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1434174] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1434174] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1434447] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1434447] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1434734] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1434734] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1435079] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1435079] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[12194,1],7]
  Exit code:    1
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1435407] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1435407] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1435701] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1435701] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1435796] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1435796] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1436065] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1436065] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1436110] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1436110] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[8945,1],14]
  Exit code:    1
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1436151] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1436151] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1436451] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1436451] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1436530] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1436530] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1436870] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1436870] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n511:1804865:0:1804865] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14cc7e380000)
==== backtrace (tid:1804865) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001069f MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
 9 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
10 0x0000000000019685 Tests_Slab_Random_Default<double>::testcase4()  ???:0
11 0x0000000000016ced Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
[uc2n511:1804866:0:1804866] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1495503c0000)
==== backtrace (tid:1804866) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001069f MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
 9 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
10 0x0000000000019685 Tests_Slab_Random_Default<double>::testcase4()  ???:0
11 0x0000000000016ced Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
[uc2n511:1804860:0:1804860] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e126240000)
[uc2n511:1804859:0:1804859] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x152140200000)
==== backtrace (tid:1804859) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001069f MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
 9 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
10 0x0000000000019685 Tests_Slab_Random_Default<double>::testcase4()  ???:0
11 0x0000000000016ced Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1804860) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001069f MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
 9 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
10 0x0000000000019685 Tests_Slab_Random_Default<double>::testcase4()  ???:0
11 0x0000000000016ced Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 14 with PID 1804865 on node uc2n511 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1437201] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1437201] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[9332,1],7]
  Exit code:    1
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1437528] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1437528] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n511:1805572:0:1805572] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14b6cc380000)
==== backtrace (tid:1805572) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010d69 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
 9 0x0000000000019685 Tests_Slab_Random_Default<double>::testcase4()  ???:0
10 0x0000000000016ced Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
[uc2n511:1805573:0:1805573] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14ef483c0000)
==== backtrace (tid:1805573) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010d69 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
 9 0x0000000000019685 Tests_Slab_Random_Default<double>::testcase4()  ???:0
10 0x0000000000016ced Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
[uc2n511:1805566:0:1805566] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14a4f6200000)
[uc2n511:1805567:0:1805567] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1499d6240000)
==== backtrace (tid:1805567) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010d69 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
 9 0x0000000000019685 Tests_Slab_Random_Default<double>::testcase4()  ???:0
10 0x0000000000016ced Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1805566) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010d69 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
 9 0x0000000000019685 Tests_Slab_Random_Default<double>::testcase4()  ???:0
10 0x0000000000016ced Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 14 with PID 1805572 on node uc2n511 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1437871] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1437871] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1438179] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1438179] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n511:1805955:0:1805955] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x148412380000)
==== backtrace (tid:1805955) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010d69 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
 9 0x0000000000019685 Tests_Slab_Random_Default<double>::testcase4()  ???:0
10 0x0000000000016ced Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
[uc2n511:1805956:0:1805956] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x145e7e3c0000)
==== backtrace (tid:1805956) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010d69 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
 9 0x0000000000019685 Tests_Slab_Random_Default<double>::testcase4()  ???:0
10 0x0000000000016ced Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[uc2n511:1805950:0:1805950] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x151aa8240000)
==== backtrace (tid:1805950) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010d69 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
 9 0x0000000000019685 Tests_Slab_Random_Default<double>::testcase4()  ???:0
10 0x0000000000016ced Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
[uc2n511:1805949:0:1805949] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e5d2200000)
==== backtrace (tid:1805949) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010d69 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000017c2b MPIcuFFT_Slab<double>::execR2C()  ???:0
 9 0x0000000000019685 Tests_Slab_Random_Default<double>::testcase4()  ???:0
10 0x0000000000016ced Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
mpiexec noticed that process rank 14 with PID 1805955 on node uc2n511 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128
2021-09-30 05:41:53.868205
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128
2021-09-30 05:42:03.146023
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128
2021-09-30 05:42:13.375402
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128
2021-09-30 05:42:23.079855
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128
2021-09-30 05:42:33.222746
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128
2021-09-30 05:42:43.006876
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128
2021-09-30 05:42:53.424006
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128
2021-09-30 05:43:02.859548
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128
2021-09-30 05:43:12.939018
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128
2021-09-30 05:43:22.820947
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 256
2021-09-30 05:43:33.136097
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 256
2021-09-30 05:43:42.516832
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 256
2021-09-30 05:43:52.767811
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 256
2021-09-30 05:44:02.477771
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 256
2021-09-30 05:44:12.726451
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 256
2021-09-30 05:44:22.246836
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 256
2021-09-30 05:44:32.492962
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 256
2021-09-30 05:44:41.772731
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 256
2021-09-30 05:44:51.921898
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 256
2021-09-30 05:45:01.422142
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 256 -nz 256
2021-09-30 05:45:11.535572
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 256 -nz 256
2021-09-30 05:45:21.178070
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 256 -nz 256
2021-09-30 05:45:31.202342
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 256 -nz 256
2021-09-30 05:45:40.700939
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 256 -nz 256
2021-09-30 05:45:50.796029
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 256 -nz 256
2021-09-30 05:46:00.020697
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 256 -nz 256
2021-09-30 05:46:09.941252
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 256 -nz 256
2021-09-30 05:46:19.662946
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 256 -nz 256
2021-09-30 05:46:29.934973
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 256 -nz 256
2021-09-30 05:46:39.778736
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256
2021-09-30 05:46:49.961564
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256
2021-09-30 05:47:00.205202
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256
2021-09-30 05:47:10.442933
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256
2021-09-30 05:47:19.784640
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256
2021-09-30 05:47:30.149984
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256
2021-09-30 05:47:40.207899
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256
2021-09-30 05:47:50.412999
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256
2021-09-30 05:48:00.015006
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256
2021-09-30 05:48:10.362424
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256
2021-09-30 05:48:20.045406
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 512
2021-09-30 05:48:30.282300
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 512
2021-09-30 05:48:40.093757
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 512
2021-09-30 05:48:51.211921
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 512
2021-09-30 05:49:01.060957
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 512
2021-09-30 05:49:11.106547
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 512
2021-09-30 05:49:21.019041
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 512
2021-09-30 05:49:31.404422
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 512
2021-09-30 05:49:41.120012
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 512
2021-09-30 05:49:53.962387
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 512
2021-09-30 05:50:03.610363
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 512 -nz 512
2021-09-30 05:50:13.736211
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 512 -nz 512
2021-09-30 05:50:23.603955
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 512 -nz 512
2021-09-30 05:50:33.979652
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 512 -nz 512
2021-09-30 05:50:43.863216
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 512 -nz 512
2021-09-30 05:50:54.315691
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 512 -nz 512
2021-09-30 05:51:04.769443
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 512 -nz 512
2021-09-30 05:51:15.405200
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 512 -nz 512
2021-09-30 05:51:25.569661
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 512 -nz 512
2021-09-30 05:51:36.120260
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 512 -nz 512
2021-09-30 05:51:46.458549
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512
2021-09-30 05:51:57.110802
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512
2021-09-30 05:52:07.889087
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512
2021-09-30 05:52:19.039164
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512
2021-09-30 05:52:29.879408
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512
2021-09-30 05:52:40.603878
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512
2021-09-30 05:52:51.588816
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512
2021-09-30 05:53:02.663359
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512
2021-09-30 05:53:13.721041
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512
2021-09-30 05:53:24.652797
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512
2021-09-30 05:53:35.793789
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 1024
2021-09-30 05:53:46.814254
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 1024
2021-09-30 05:53:59.370572
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 1024
2021-09-30 05:54:11.124141
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 1024
2021-09-30 05:54:23.533951
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 1024
2021-09-30 05:54:35.453999
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 1024
2021-09-30 05:54:48.257266
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 1024
2021-09-30 05:55:00.079397
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 1024
2021-09-30 05:55:12.231411
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 1024
2021-09-30 05:55:23.795201
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 1024
2021-09-30 05:55:36.627801
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 1024 -nz 1024
2021-09-30 05:55:48.340601
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 1024 -nz 1024
2021-09-30 05:56:03.700635
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 1024 -nz 1024
2021-09-30 05:56:17.176989
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 1024 -nz 1024
2021-09-30 05:56:32.015508
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 1024 -nz 1024
2021-09-30 05:56:45.206743
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 1024 -nz 1024
2021-09-30 05:57:01.207721
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 1024 -nz 1024
2021-09-30 05:57:14.499615
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 1024 -nz 1024
2021-09-30 05:57:29.975889
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 1024 -nz 1024
2021-09-30 05:57:43.400351
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 1024 -nz 1024
2021-09-30 05:58:00.282942
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024
2021-09-30 05:58:13.963882
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024
2021-09-30 05:58:35.256372
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024
2021-09-30 05:58:52.304301
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024
2021-09-30 05:59:13.548483
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024
2021-09-30 05:59:30.145515
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024
2021-09-30 05:59:52.379590
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024
2021-09-30 06:00:09.332709
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024
2021-09-30 06:00:31.058439
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024
2021-09-30 06:00:47.951227
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024
2021-09-30 06:01:12.014003
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 2048
2021-09-30 06:01:29.816346
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 2048
2021-09-30 06:02:02.625439
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 2048
2021-09-30 06:02:27.891220
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 2048
2021-09-30 06:03:01.034131
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 2048
2021-09-30 06:03:24.606863
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 2048
2021-09-30 06:03:59.349676
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 2048
2021-09-30 06:04:23.537065
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 2048
2021-09-30 06:04:58.466978
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 2048
2021-09-30 06:05:23.048663
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 2048
2021-09-30 06:06:02.237078
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 2048 -nz 2048
2021-09-30 06:06:29.229330
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 2048 -nz 2048
2021-09-30 06:07:27.032656
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 2048 -nz 2048
2021-09-30 06:08:06.659257
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 2048 -nz 2048
2021-09-30 06:09:04.788042
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 2048 -nz 2048
2021-09-30 06:09:46.263406
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 2048 -nz 2048
2021-09-30 06:10:46.942956
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 2048 -nz 2048
2021-09-30 06:11:25.625020
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 2048 -nz 2048
2021-09-30 06:12:25.800855
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 2048 -nz 2048
2021-09-30 06:13:06.437458
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 2048 -nz 2048
2021-09-30 06:14:14.706162
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048
2021-09-30 06:14:58.970269
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048
2021-09-30 06:16:46.055992
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048
2021-09-30 06:17:57.959863
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048
2021-09-30 06:19:45.183620
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048
2021-09-30 06:20:58.239944
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048
2021-09-30 06:22:50.882007
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048
2021-09-30 06:24:02.990529
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048
2021-09-30 06:24:21.420828
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048
2021-09-30 06:24:36.743528
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048
2021-09-30 06:24:54.481709
b''

Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 06:25:10.700975
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 06:25:19.983215
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 06:25:29.545854
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 06:25:38.740603
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 06:25:48.668139
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 06:25:58.031705
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 06:26:07.985602
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 06:26:17.003518
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 06:26:26.879333
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 06:26:35.914157
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 06:26:45.318347
b'Result (avg): 5.01735e-09\nResult (max): 5.42241e-08\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 06:26:54.283427
b'Result (avg): 5.01735e-09\nResult (max): 5.42241e-08\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 06:27:03.915927
b'Result (avg): 5.01735e-09\nResult (max): 5.42241e-08\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 06:27:12.856238
b'Result (avg): 5.01735e-09\nResult (max): 5.42241e-08\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 06:27:22.238214
b'Result (avg): 5.01735e-09\nResult (max): 5.42241e-08\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 06:27:31.274591
b'Result (avg): 5.03284e-09\nResult (max): 5.42714e-08\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 06:27:41.692606
b'Result (avg): 5.01735e-09\nResult (max): 5.42241e-08\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 06:27:50.744455
b'Result (avg): 5.01735e-09\nResult (max): 5.42241e-08\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 06:28:00.444868
b'Result (avg): 5.01735e-09\nResult (max): 5.42241e-08\n'

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 06:28:09.580824
b'Result (avg): 5.01735e-09\nResult (max): 5.42241e-08\n'

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 06:28:18.867785
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 06:28:28.948549
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 06:28:39.239039
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 06:28:49.295971
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 06:28:59.821107
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 06:29:09.731410
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 06:29:19.804785
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 06:29:29.498324
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 06:29:39.377376
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 06:29:53.563918
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 06:30:03.484074
b'Result (avg): 7.38396e-07\nResult (max): 9.23959e-06\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 06:30:23.405436
b'Result (avg): 7.38396e-07\nResult (max): 9.23959e-06\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 06:30:42.661719
b'Result (avg): 7.38396e-07\nResult (max): 9.23959e-06\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 06:31:02.595898
b'Result (avg): 7.38396e-07\nResult (max): 9.23959e-06\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 06:31:21.869128
b'Result (avg): 7.38396e-07\nResult (max): 9.23959e-06\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 06:31:41.985169
b'Result (avg): 2.26753e-06\nResult (max): 0.000158864\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 06:32:01.379765
b'Result (avg): 7.38396e-07\nResult (max): 9.23959e-06\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 06:32:21.388155
b'Result (avg): 7.38396e-07\nResult (max): 9.23959e-06\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 06:32:40.521988
b'Result (avg): 7.38396e-07\nResult (max): 9.23959e-06\n'

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 06:33:00.625964
b'Result (avg): 7.38396e-07\nResult (max): 9.23959e-06\n'

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 06:33:19.930688
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 06:35:01.628383
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 06:36:17.442663
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 06:38:05.996197
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 06:39:21.652673
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 06:41:12.350369
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 06:42:47.854854
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 06:44:10.782569
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 06:45:37.424435
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 06:47:06.267872
b''

--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1438300] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1438300] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1438365] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1438365] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1438478] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1438478] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1438545] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1438545] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1438675] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1438675] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439130] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439130] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n517:1279278:0:1279278] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x15389c240000)
[uc2n517:1279282:0:1279282] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x154218340000)
[uc2n517:1279281:0:1279281] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e5ec300000)
[uc2n517:1279277:0:1279277] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14cf5c200000)
[uc2n517:1279279:0:1279279] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x152198280000)
[uc2n517:1279280:0:1279280] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14fc602c0000)
[uc2n517:1279283:0:1279283] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14b75e380000)
[uc2n517:1279284:0:1279284] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14ae2c3c0000)
[uc2n514:1058150:0:1058150] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x148be6200000)
[uc2n514:1058148:0:1058148] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14dc30200000)
[uc2n514:1058151:0:1058151] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x148c98200000)
[uc2n514:1058144:0:1058144] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1518b6200000)
[uc2n514:1058149:0:1058149] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x151a7e200000)
[uc2n514:1058147:0:1058147] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1487a8200000)
[uc2n514:1058145:0:1058145] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x150d24200000)
[uc2n514:1058146:0:1058146] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e210200000)
==== backtrace (tid:1279277) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001eb28 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
 9 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
10 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
11 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1279281) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001eb28 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
 9 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
10 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
11 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1279283) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001eb28 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
 9 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
10 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
11 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1279279) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001eb28 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
 9 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
10 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
11 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1279278) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001eb28 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
 9 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
10 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
11 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1279280) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001eb28 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
 9 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
10 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
11 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1279282) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001eb28 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
 9 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
10 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
11 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1279284) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001eb28 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
 9 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
10 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
11 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1058150) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000001eb28 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
11 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
12 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
13 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
14 0x000000000040332f main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1058148) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000001eb28 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
11 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
12 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
13 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
14 0x000000000040332f main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1058151) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000001eb28 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
11 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
12 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
13 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
14 0x000000000040332f main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1058149) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000001eb28 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
11 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
12 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
13 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
14 0x000000000040332f main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1058144) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000001eb28 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
11 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
12 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
13 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
14 0x000000000040332f main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1058147) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000001eb28 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
11 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
12 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
13 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
14 0x000000000040332f main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1058145) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000001eb28 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
11 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
12 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
13 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
14 0x000000000040332f main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1058146) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000001eb28 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
11 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
12 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
13 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
14 0x000000000040332f main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 0 with PID 1058144 on node uc2n514 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439148] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439148] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
The call to cuMemcpyAsync failed. This is a unrecoverable error and will
cause the program to abort.
  cuMemcpyAsync(0x1458ef000000, 0x145af6c00000, 131072) returned value 1
Check the cuda.h file for what the return value means.
--------------------------------------------------------------------------
[uc2n517.localdomain:1279636] CUDA: Error in cuMemcpy: res=-1, dest=0x1458ef000000, src=0x145af6c00000, size=131072
[uc2n517:1279636] *** Process received signal ***
[uc2n517:1279636] Signal: Aborted (6)
[uc2n517:1279636] Signal code:  (-6)
[uc2n517:1279636] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x145d6643add0]
[uc2n517:1279636] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x145d6609d70f]
[uc2n517:1279636] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x145d66087b25]
[uc2n517:1279636] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c58f)[0x145d6500758f]
[uc2n517:1279636] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x77119)[0x145d65002119]
[uc2n517:1279636] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_datatype_sndrcv+0x50a)[0x145d71e40b2a]
[uc2n517:1279636] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x26e)[0x145d71e9580e]
[uc2n517:1279636] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x145d71ea1702]
[uc2n517:1279636] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x145d71e4342b]
[uc2n517:1279636] [ 9] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_decomp.so(_ZN18MPIcuFFT_Slab_Opt1IdE12All2All_SyncEPvb+0xf8)[0x145d7c590b28]
[uc2n517:1279636] [10] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_decomp.so(_ZN18MPIcuFFT_Slab_Opt1IdE7execR2CEPvPKv+0x122)[0x145d7c590352]
[uc2n517:1279636] [11] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_tests.so(_ZN25Tests_Slab_Random_DefaultIdE9testcase0Eii+0x518)[0x145d7c7dd20e]
[uc2n517:1279636] [12] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_tests.so(_ZN25Tests_Slab_Random_DefaultIdE3runEiii+0x2f)[0x145d7c7dcc7d]
[uc2n517:1279636] [13] slab[0x40332f]
[uc2n517:1279636] [14] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x145d660896a3]
[uc2n517:1279636] [15] slab[0x4039fe]
[uc2n517:1279636] *** End of error message ***
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 15 with PID 1279636 on node uc2n517 exited on signal 6 (Aborted).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439186] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439186] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n517:1279921:0:1279921] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x147654380000)
[uc2n517:1279919:0:1279919] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x150cae300000)
[uc2n517:1279915:0:1279915] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14b884200000)
[uc2n517:1279917:0:1279917] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x149980280000)
[uc2n517:1279916:0:1279916] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14dace240000)
[uc2n517:1279920:0:1279920] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1492b4340000)
[uc2n517:1279922:0:1279922] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x15075c3c0000)
[uc2n517:1279918:0:1279918] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x154bfc2c0000)
==== backtrace (tid:1279921) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000001f2c9 MPIcuFFT_Slab_Opt1<double>::All2All_MPIType()  ???:0
 8 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
 9 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
10 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1279919) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000001f2c9 MPIcuFFT_Slab_Opt1<double>::All2All_MPIType()  ???:0
 8 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
 9 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
10 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1279915) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000001f2c9 MPIcuFFT_Slab_Opt1<double>::All2All_MPIType()  ???:0
 8 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
 9 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
10 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1279917) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000001f2c9 MPIcuFFT_Slab_Opt1<double>::All2All_MPIType()  ???:0
 8 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
 9 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
10 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1279916) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000001f2c9 MPIcuFFT_Slab_Opt1<double>::All2All_MPIType()  ???:0
 8 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
 9 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
10 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1279922) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000001f2c9 MPIcuFFT_Slab_Opt1<double>::All2All_MPIType()  ???:0
 8 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
 9 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
10 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1279920) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000001f2c9 MPIcuFFT_Slab_Opt1<double>::All2All_MPIType()  ???:0
 8 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
 9 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
10 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1279918) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000001f2c9 MPIcuFFT_Slab_Opt1<double>::All2All_MPIType()  ???:0
 8 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
 9 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
10 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
[uc2n514:1058784:0:1058784] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x153f58200000)
[uc2n514:1058789:0:1058789] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x153200200000)
[uc2n514:1058785:0:1058785] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1476d4200000)
[uc2n514:1058783:0:1058783] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x145d2c200000)
[uc2n514:1058790:0:1058790] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x153b5c200000)
[uc2n514:1058787:0:1058787] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x152236200000)
[uc2n514:1058788:0:1058788] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14ab9c200000)
[uc2n514:1058786:0:1058786] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1542f4200000)
==== backtrace (tid:1058784) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000001f2c9 MPIcuFFT_Slab_Opt1<double>::All2All_MPIType()  ???:0
10 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
11 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
12 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
13 0x000000000040332f main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1058789) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000001f2c9 MPIcuFFT_Slab_Opt1<double>::All2All_MPIType()  ???:0
10 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
11 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
12 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
13 0x000000000040332f main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1058785) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000001f2c9 MPIcuFFT_Slab_Opt1<double>::All2All_MPIType()  ???:0
10 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
11 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
12 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
13 0x000000000040332f main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1058783) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000001f2c9 MPIcuFFT_Slab_Opt1<double>::All2All_MPIType()  ???:0
10 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
11 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
12 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
13 0x000000000040332f main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1058790) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000001f2c9 MPIcuFFT_Slab_Opt1<double>::All2All_MPIType()  ???:0
10 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
11 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
12 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
13 0x000000000040332f main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1058787) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000001f2c9 MPIcuFFT_Slab_Opt1<double>::All2All_MPIType()  ???:0
10 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
11 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
12 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
13 0x000000000040332f main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1058788) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000001f2c9 MPIcuFFT_Slab_Opt1<double>::All2All_MPIType()  ???:0
10 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
11 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
12 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
13 0x000000000040332f main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1058786) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000001f2c9 MPIcuFFT_Slab_Opt1<double>::All2All_MPIType()  ???:0
10 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
11 0x000000000001720e Tests_Slab_Random_Default<double>::testcase0()  ???:0
12 0x0000000000016c7d Tests_Slab_Random_Default<double>::run()  ???:0
13 0x000000000040332f main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 12 with PID 1279919 on node uc2n517 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439208] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439208] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
The call to cuMemcpyAsync failed. This is a unrecoverable error and will
cause the program to abort.
  cuMemcpyAsync(0x9bf1110, 0x153baa800000, 65536) returned value 1
Check the cuda.h file for what the return value means.
--------------------------------------------------------------------------
[uc2n517.localdomain:1280275] CUDA: Error in cuMemcpy: res=-1, dest=0x9bf1110, src=0x153baa800000, size=65536
[uc2n517:1280275] *** Process received signal ***
[uc2n517:1280275] Signal: Aborted (6)
[uc2n517:1280275] Signal code:  (-6)
[uc2n517:1280275] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x153e1d6b1dd0]
[uc2n517:1280275] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x153e1d31470f]
[uc2n517:1280275] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x153e1d2feb25]
[uc2n517:1280275] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x153e1c27e375]
[uc2n517:1280275] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x153e1c2751e8]
[uc2n517:1280275] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_datatype_sndrcv+0x1e3)[0x153e290b7803]
[uc2n517:1280275] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_coll_basic_alltoallw_intra+0xa4)[0x153e2914b984]
[uc2n517:1280275] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallw+0x1eb)[0x153e290baccb]
[uc2n517:1280275] [ 8] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_decomp.so(_ZN18MPIcuFFT_Slab_Opt1IdE15All2All_MPITypeEPvb+0x149)[0x153e338082c9]
[uc2n517:1280275] [ 9] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_decomp.so(_ZN18MPIcuFFT_Slab_Opt1IdE7execR2CEPvPKv+0x122)[0x153e33807352]
[uc2n517:1280275] [10] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_tests.so(_ZN25Tests_Slab_Random_DefaultIdE9testcase0Eii+0x518)[0x153e33a5420e]
[uc2n517:1280275] [11] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_tests.so(_ZN25Tests_Slab_Random_DefaultIdE3runEiii+0x2f)[0x153e33a53c7d]
[uc2n517:1280275] [12] slab[0x40332f]
[uc2n517:1280275] [13] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x153e1d3006a3]
[uc2n517:1280275] [14] slab[0x4039fe]
[uc2n517:1280275] *** End of error message ***
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 15 with PID 1280275 on node uc2n517 exited on signal 6 (Aborted).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439238] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439238] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439257] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439257] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439274] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439274] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439305] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439305] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439322] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439322] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439340] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439340] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439373] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439373] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439390] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439390] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439409] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439409] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439438] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439438] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439455] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439455] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439474] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439474] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439502] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439502] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439521] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439521] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439540] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439540] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439577] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439577] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439593] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439593] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439612] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439612] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439639] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439639] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439658] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439658] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439678] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439678] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439707] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439707] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439725] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439725] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439744] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439744] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439778] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439778] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439795] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439795] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439814] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439814] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439847] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439847] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439866] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439866] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439895] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439895] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439914] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439914] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439952] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439952] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1439973] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1439973] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1440007] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1440007] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1440041] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1440041] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1440079] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1440079] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1440104] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1440104] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1440138] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1440138] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1440172] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1440172] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1440194] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1440194] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1440236] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1440236] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1440342] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1440342] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[12339,1],15]
  Exit code:    1
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1440412] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1440412] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1440525] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1440525] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[12648,1],14]
  Exit code:    1
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1440606] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1440606] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1440721] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1440721] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1440833] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1440833] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n517:1294010:0:1294010] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1451b0380000)
==== backtrace (tid:1294010) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001eb28 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
 9 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
10 0x0000000000019685 Tests_Slab_Random_Default<double>::testcase4()  ???:0
11 0x0000000000016ced Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
[uc2n514:1072934:0:1072934] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14b10e200000)
[uc2n517:1294011:0:1294011] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c4103c0000)
==== backtrace (tid:1294011) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001eb28 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
 9 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
10 0x0000000000019685 Tests_Slab_Random_Default<double>::testcase4()  ???:0
11 0x0000000000016ced Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1072934) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000001eb28 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
11 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
12 0x0000000000019685 Tests_Slab_Random_Default<double>::testcase4()  ???:0
13 0x0000000000016ced Tests_Slab_Random_Default<double>::run()  ???:0
14 0x000000000040332f main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
[uc2n514:1072933:0:1072933] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x149324200000)
==== backtrace (tid:1072933) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000001eb28 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
11 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
12 0x0000000000019685 Tests_Slab_Random_Default<double>::testcase4()  ???:0
13 0x0000000000016ced Tests_Slab_Random_Default<double>::run()  ???:0
14 0x000000000040332f main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
[uc2n517:1294005:0:1294005] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x153a2e240000)
[uc2n517:1294004:0:1294004] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x149ff6200000)
==== backtrace (tid:1294004) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001eb28 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
 9 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
10 0x0000000000019685 Tests_Slab_Random_Default<double>::testcase4()  ???:0
11 0x0000000000016ced Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1294005) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001eb28 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
 9 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
10 0x0000000000019685 Tests_Slab_Random_Default<double>::testcase4()  ???:0
11 0x0000000000016ced Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[uc2n514:1072927:0:1072927] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e894200000)
==== backtrace (tid:1072927) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000001eb28 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
11 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
12 0x0000000000019685 Tests_Slab_Random_Default<double>::testcase4()  ???:0
13 0x0000000000016ced Tests_Slab_Random_Default<double>::run()  ???:0
14 0x000000000040332f main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
mpiexec noticed that process rank 7 with PID 1072934 on node uc2n514 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1440902] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1440902] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[14051,1],14]
  Exit code:    1
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1440995] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1440995] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n517:1294733:0:1294733] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14ac82380000)
==== backtrace (tid:1294733) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000001f2c9 MPIcuFFT_Slab_Opt1<double>::All2All_MPIType()  ???:0
 8 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
 9 0x0000000000019685 Tests_Slab_Random_Default<double>::testcase4()  ???:0
10 0x0000000000016ced Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
[uc2n517:1294734:0:1294734] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x15081c3c0000)
==== backtrace (tid:1294734) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000001f2c9 MPIcuFFT_Slab_Opt1<double>::All2All_MPIType()  ???:0
 8 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
 9 0x0000000000019685 Tests_Slab_Random_Default<double>::testcase4()  ???:0
10 0x0000000000016ced Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
[uc2n514:1073656:0:1073656] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x146988200000)
==== backtrace (tid:1073656) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000001f2c9 MPIcuFFT_Slab_Opt1<double>::All2All_MPIType()  ???:0
10 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
11 0x0000000000019685 Tests_Slab_Random_Default<double>::testcase4()  ???:0
12 0x0000000000016ced Tests_Slab_Random_Default<double>::run()  ???:0
13 0x000000000040332f main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
[uc2n514:1073655:0:1073655] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x15170e200000)
==== backtrace (tid:1073655) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000001f2c9 MPIcuFFT_Slab_Opt1<double>::All2All_MPIType()  ???:0
10 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
11 0x0000000000019685 Tests_Slab_Random_Default<double>::testcase4()  ???:0
12 0x0000000000016ced Tests_Slab_Random_Default<double>::run()  ???:0
13 0x000000000040332f main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
[uc2n517:1294728:0:1294728] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x148b1c240000)
[uc2n517:1294727:0:1294727] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14553c200000)
==== backtrace (tid:1294728) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000001f2c9 MPIcuFFT_Slab_Opt1<double>::All2All_MPIType()  ???:0
 8 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
 9 0x0000000000019685 Tests_Slab_Random_Default<double>::testcase4()  ???:0
10 0x0000000000016ced Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1294727) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000001f2c9 MPIcuFFT_Slab_Opt1<double>::All2All_MPIType()  ???:0
 8 0x000000000001e352 MPIcuFFT_Slab_Opt1<double>::execR2C()  ???:0
 9 0x0000000000019685 Tests_Slab_Random_Default<double>::testcase4()  ???:0
10 0x0000000000016ced Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 7 with PID 1073656 on node uc2n514 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1441101] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1441101] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
The call to cuMemcpyAsync failed. This is a unrecoverable error and will
cause the program to abort.
  cuMemcpyAsync(0x145a440b6178, 0x14561dff03c0, 131040) returned value 1
Check the cuda.h file for what the return value means.
--------------------------------------------------------------------------
[uc2n517.localdomain:1295124] CUDA: Error in cuMemcpy: res=-1, dest=0x145a440b6178, src=0x14561dff03c0, size=131040
[uc2n517:1295124] *** Process received signal ***
[uc2n517:1295124] Signal: Aborted (6)
[uc2n517:1295124] Signal code:  (-6)
[uc2n517:1295124] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x145a86539dd0]
[uc2n517:1295124] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x145a8619c70f]
[uc2n517:1295124] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x145a86186b25]
[uc2n517:1295124] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x145a85106375]
[uc2n517:1295124] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x145a850fd1e8]
[uc2n517:1295124] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_smcuda_prepare_src+0x126)[0x145a851550a6]
[uc2n517:1295124] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x145a920b822b]
[uc2n517:1295124] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x145a920bb27c]
[uc2n517:1295124] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_smcuda_component_progress+0x507)[0x145a851574c7]
[uc2n517:1295124] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x145a850eca1b]
[uc2n517:1295124] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x145a850f2ef5]
[uc2n517:1295124] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x145a91f2f8ea]
[uc2n517:1295124] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_coll_basic_alltoallw_intra+0x252)[0x145a91fd3b32]
[uc2n517:1295124] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallw+0x1eb)[0x145a91f42ccb]
[uc2n517:1295124] [14] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_decomp.so(_ZN18MPIcuFFT_Slab_Opt1IdE15All2All_MPITypeEPvb+0x149)[0x145a9c6902c9]
[uc2n517:1295124] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_decomp.so(_ZN18MPIcuFFT_Slab_Opt1IdE7execR2CEPvPKv+0x122)[0x145a9c68f352]
[uc2n517:1295124] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_tests.so(_ZN25Tests_Slab_Random_DefaultIdE9testcase4Eii+0xed9)[0x145a9c8de685]
[uc2n517:1295124] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_tests.so(_ZN25Tests_Slab_Random_DefaultIdE3runEiii+0x9f)[0x145a9c8dbced]
[uc2n517:1295124] [18] slab[0x40332f]
[uc2n517:1295124] [19] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x145a861886a3]
[uc2n517:1295124] [20] slab[0x4039fe]
[uc2n517:1295124] *** End of error message ***
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[uc2n514.localdomain:1074025] CUDA: Error in cuMemcpy: res=1, dest=0x14fe70b1c0f1, src=0x14fa31ff03c0, size=131040
[uc2n514:1074025] *** Process received signal ***
[uc2n514:1074025] Signal: Aborted (6)
[uc2n514:1074025] Signal code:  (-6)
[uc2n514:1074025] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x14fe9a66add0]
[uc2n514:1074025] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x14fe9a2cd70f]
[uc2n514:1074025] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x14fe9a2b7b25]
[uc2n514:1074025] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x14fe99237375]
[uc2n514:1074025] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x14fe9922e1e8]
[uc2n514:1074025] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_openib_prepare_src+0x81)[0x14fe99289941]
[uc2n514:1074025] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x14fea61e922b]
[uc2n514:1074025] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x14fea61ec27c]
[uc2n514:1074025] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda31f)[0x14fe9929531f]
[uc2n514:1074025] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x14fe992961a6]
[uc2n514:1074025] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x14fe9921da1b]
[uc2n514:1074025] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x14fe99223ef5]
[uc2n514:1074025] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x14fea60608ea]
[uc2n514:1074025] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_coll_basic_alltoallw_intra+0x252)[0x14fea6104b32]
[uc2n514:1074025] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallw+0x1eb)[0x14fea6073ccb]
[uc2n514:1074025] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_decomp.so(_ZN18MPIcuFFT_Slab_Opt1IdE15All2All_MPITypeEPvb+0x149)[0x14feb07c12c9]
[uc2n514:1074025] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_decomp.so(_ZN18MPIcuFFT_Slab_Opt1IdE7execR2CEPvPKv+0x122)[0x14feb07c0352]
[uc2n514:1074025] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_tests.so(_ZN25Tests_Slab_Random_DefaultIdE9testcase4Eii+0xed9)[0x14feb0a0f685]
[uc2n514:1074025] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_tests.so(_ZN25Tests_Slab_Random_DefaultIdE3runEiii+0x9f)[0x14feb0a0cced]
[uc2n514:1074025] [19] slab[0x40332f]
[uc2n514:1074025] [20] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x14fe9a2b96a3]
[uc2n514:1074025] [21] slab[0x4039fe]
[uc2n514:1074025] *** End of error message ***
--------------------------------------------------------------------------
mpiexec noticed that process rank 14 with PID 1295124 on node uc2n517 exited on signal 6 (Aborted).
--------------------------------------------------------------------------
Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-30 05:41:53.856226
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-30 05:42:02.291627
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-30 05:42:11.620511
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-30 05:42:20.432506
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-30 05:42:29.709632
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-30 05:42:38.386385
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-30 05:42:49.258114
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-30 05:42:57.841715
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-30 05:43:07.101602
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-30 05:43:15.622270
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-30 05:43:26.798710
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-30 05:43:35.554030
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-30 05:43:44.936796
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-30 05:43:53.508664
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-30 05:44:02.996427
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-30 05:44:11.580579
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-30 05:44:24.313201
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-30 05:44:33.063895
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-30 05:44:42.253384
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-30 05:44:50.942254
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-30 05:45:03.797898
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-30 05:45:12.437825
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-30 05:45:22.356838
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-30 05:45:30.951265
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-30 05:45:40.254412
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-30 05:45:49.283375
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-30 05:46:05.636988
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-30 05:46:14.748401
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-30 05:46:24.584525
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-30 05:46:33.656909
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-30 05:46:50.684014
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-30 05:46:59.773529
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-30 05:47:10.005807
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-30 05:47:19.092028
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-30 05:47:28.739912
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-30 05:47:37.992642
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-30 05:47:54.577878
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-30 05:48:03.872576
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-30 05:48:13.725951
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-30 05:48:23.130135
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-30 05:48:40.322016
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-30 05:48:50.571355
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-30 05:49:01.624338
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-30 05:49:11.651430
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-30 05:49:21.992897
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-30 05:49:31.800897
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-30 05:49:55.567094
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-30 05:50:05.489568
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-30 05:50:15.733454
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-30 05:50:25.481883
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-30 05:50:49.479581
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-30 05:50:59.275490
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-30 05:51:09.431588
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-30 05:51:19.186439
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-30 05:51:29.425541
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-30 05:51:39.582161
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-30 05:52:15.884923
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-30 05:52:25.498308
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-30 05:52:35.725615
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-30 05:52:45.697020
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-30 05:53:22.805312
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-30 05:53:33.344289
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-30 05:53:43.693738
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-30 05:53:54.130354
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-30 05:54:04.940745
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-30 05:54:15.956705
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-30 05:54:53.390240
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-30 05:55:03.893283
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-30 05:55:14.328642
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-30 05:55:25.584682
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-30 05:56:04.458896
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-30 05:56:16.746684
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-30 05:56:28.215014
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-30 05:56:40.124340
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-30 05:56:51.739452
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-30 05:57:04.914554
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-30 05:58:08.244258
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-30 05:58:20.570391
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-30 05:58:32.203285
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-30 05:58:45.494033
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-30 05:59:51.633477
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-30 06:00:07.909655
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-30 06:00:21.069055
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-30 06:00:35.980492
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-30 06:00:49.007140
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-30 06:01:06.459421
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-30 06:03:01.346110
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-30 06:03:16.947052
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-30 06:03:30.207565
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-30 06:03:48.165949
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-30 06:05:49.652153
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-30 06:06:12.360653
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-30 06:06:29.189739
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-30 06:06:50.700704
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-30 06:07:07.979657
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-30 06:07:33.440985
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-30 06:09:32.699953
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-30 06:09:55.334523
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-30 06:10:12.508674
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-30 06:10:38.161147
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-30 06:12:45.706011
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-30 06:13:23.760499
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-30 06:13:49.635740
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-30 06:14:24.405073
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-30 06:14:49.687624
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-30 06:15:31.805052
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-30 06:19:17.907741
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-30 06:19:54.035765
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-30 06:20:19.086380
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-30 06:21:02.080911
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-30 06:25:01.316334
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-30 06:26:06.849682
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-30 06:26:46.700495
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-30 06:27:46.604027
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-30 06:28:26.448383
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-30 06:29:41.441594
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-30 06:37:07.604771
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-30 06:38:11.281227
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-30 06:38:51.805462
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-30 06:40:08.993641
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-30 06:47:55.546086
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-30 06:49:56.230626
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-30 06:51:04.872611
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-30 06:52:56.525999
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-30 06:54:05.848808
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-30 06:56:19.135169
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-30 07:04:11.827634
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-30 07:04:28.885551
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-30 07:04:44.386701
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-30 07:05:03.947639
b''

Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 07:05:19.570147
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 07:05:29.760269
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 07:05:39.597263
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 07:05:49.038018
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 07:05:58.656451
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 07:06:07.963100
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 07:06:18.021015
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 07:06:27.301914
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 07:06:37.152986
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 07:06:46.443979
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 07:06:56.331310
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 07:07:05.648508
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 07:07:15.489258
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 07:07:25.121710
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 07:07:35.091747
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 07:07:44.628741
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 07:07:54.737355
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 07:08:04.116661
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 07:08:13.822519
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 07:08:23.263084
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 07:08:34.019971
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 07:08:44.611181
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 07:08:55.693443
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 07:09:06.214024
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 07:09:17.199412
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 07:09:27.966418
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 07:09:40.077287
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 07:09:53.822492
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 07:10:05.133903
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 07:10:15.802973
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 07:10:28.148100
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 07:10:49.121971
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 07:11:09.531353
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 07:11:30.344630
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 07:11:50.800351
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 07:12:12.311838
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 07:12:37.683323
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 07:12:58.746950
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 07:13:19.018271
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 07:13:40.339557
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 07:14:06.082500
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 07:15:49.421825
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 07:17:04.516429
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 07:19:02.016381
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 07:20:16.779128
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 07:22:16.988044
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 07:24:14.759252
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 07:25:36.274048
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/default/mpicufft_slab.cpp:231\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 07:27:08.160344
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 07:28:44.303978
b''

Slab 1D->2D default/opt1
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1441195] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1441195] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1441458] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1441458] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1441194] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1441194] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1441741] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1441741] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1441916] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1441916] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1442268] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1442268] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1442523] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1442523] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1442799] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1442799] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1443052] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1443052] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1443078] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1443078] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1443341] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1443341] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1443370] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1443370] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1443522] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1443522] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1443649] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1443649] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1443900] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1443900] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1443930] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1443930] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1444182] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1444182] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1444226] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1444226] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1444479] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1444479] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1444509] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1444509] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1444681] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1444681] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1444791] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1444791] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1445044] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1445044] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1445083] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1445083] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1445337] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1445337] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1445614] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1445614] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1445869] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1445869] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1446144] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1446144] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1446399] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1446399] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1446426] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1446426] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1446688] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1446688] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1446717] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1446717] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1446878] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1446878] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1446997] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1446997] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1447247] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1447247] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1447277] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1447277] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1447531] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1447531] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1447573] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1447573] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1447826] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1447826] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1447853] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1447853] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1448028] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1448028] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1448135] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1448135] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1448386] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1448386] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1448427] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1448427] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1448678] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1448678] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1448955] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1448955] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1449207] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1449207] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1449482] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1449482] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1449739] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1449739] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1449766] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1449766] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1450037] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1450037] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1450058] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1450058] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1450155] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1450155] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1450339] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1450339] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1450516] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1450516] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1450621] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1450621] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1450742] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1450742] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1450915] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1450915] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1451091] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1451091] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1451193] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1451193] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1451211] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1451211] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1451476] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1451476] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1451495] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1451495] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1451766] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1451766] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1451784] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1451784] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1452146] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1452146] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1452316] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1452316] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1452584] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1452584] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1452846] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1452846] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1453105] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1453105] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1453123] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1453123] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1453399] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1453399] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1453416] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1453416] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1453434] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1453434] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1453696] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1453696] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1453714] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1453714] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1453991] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1453991] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1454009] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1454009] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1454274] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1454274] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1454292] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1454292] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1454557] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1454557] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1454574] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1454574] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1454592] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1454592] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1454866] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1454866] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1454884] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1454884] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1455144] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1455144] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1455163] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1455163] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1455675] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1455675] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1455693] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1455693] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1456212] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1456212] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1456232] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1456232] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1456498] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1456498] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1456516] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1456516] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1456780] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1456780] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1456803] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1456803] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1456799] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1456799] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1457098] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1457098] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1457195] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1457195] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1457379] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1457379] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1457530] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1457530] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1457659] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1457659] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1457822] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1457822] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1457947] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1457947] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1457967] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1457967] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1458220] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1458220] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1458251] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1458251] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1458501] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1458501] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1458529] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1458529] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1458791] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1458791] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1459067] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1459067] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1459319] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1459319] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1459594] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1459594] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1459857] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1459857] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1459876] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1459876] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1460153] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1460153] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1460172] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1460172] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1460195] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1460195] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1460292] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1460292] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1460477] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1460477] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1460502] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1460502] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1460771] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1460771] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1460866] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1460866] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1461053] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1461053] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1461174] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1461174] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1461341] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1461341] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1461360] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1461360] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1461379] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1461379] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1461644] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1461644] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1461663] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1461663] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1461938] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1461938] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1461959] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1461959] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1462324] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1462324] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1462487] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1462487] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1462943] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1462943] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1463017] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1463017] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1463289] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1463289] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1463309] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1463309] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1463571] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1463571] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1463591] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1463591] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1463622] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1463622] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1463643] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1463643] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1463895] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1463895] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1463925] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1463925] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1464203] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1464203] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1464223] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1464223] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1464485] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1464485] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1464504] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1464504] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1464770] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1464770] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1464799] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1464799] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1464816] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1464816] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1464835] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1464835] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1464859] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1464859] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1465135] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1465135] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1465386] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1465386] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1465417] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1465417] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1465679] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1465679] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1465963] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1465963] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1466443] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1466443] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1466493] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1466493] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1466758] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1466758] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1466775] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1466775] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1467051] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1467051] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1467070] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1467070] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1467103] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1467103] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1467348] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1467348] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1467383] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1467383] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1467639] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1467639] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1467668] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1467668] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1467945] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1467945] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1467964] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1467964] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1468227] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1468227] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1468262] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1468262] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1468287] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1468287] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1468552] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1468552] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1468583] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1468583] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1468849] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1468849] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1468867] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1468867] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1469395] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1469395] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1469413] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1469413] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1469928] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1469928] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1470202] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1470202] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1470222] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1470222] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1470486] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1470486] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1470521] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1470521] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1470544] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1470544] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1470583] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1470583] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1470601] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1470601] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1470883] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1470883] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1471040] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1471040] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1471165] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1471165] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1471446] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1471446] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1471698] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1471698] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1471748] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1471748] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1471786] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1471786] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1471822] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1471822] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1472085] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1472085] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1472108] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1472108] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1472392] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1472392] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1472773] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1472773] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1472943] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1472943] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1473457] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1473457] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1473475] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1473475] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1473761] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1473761] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1474025] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1474025] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1474065] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1474065] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1474118] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1474118] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1474143] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1474143] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1474202] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1474202] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1474485] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1474485] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1474747] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1474747] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1474779] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1474779] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1475070] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1475070] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1475165] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1475165] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1475388] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1475388] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1475434] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1475434] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1475497] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1475497] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1475784] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1475784] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1475807] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1475807] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1476089] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1476089] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1476376] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1476376] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1476642] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1476642] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1477177] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1477177] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1477456] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1477456] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1477536] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1477536] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1477804] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1477804] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1477877] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1477877] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1477932] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1477932] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1477958] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1477958] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1478259] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1478259] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1478551] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1478551] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1478839] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1478839] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1478858] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1478858] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1479175] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1479175] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1479268] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1479268] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1479548] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1479548] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1479601] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1479601] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1479891] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1479891] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1479916] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1479916] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1480481] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1480481] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1481035] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1481035] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1481317] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1481317] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1481368] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1481368] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1481646] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1481646] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n517:1334655:0:1334655] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x149dfc400000)
[uc2n517:1334658:0:1334658] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14ab8e400000)
[uc2n517:1334656:0:1334656] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x152110400000)
[uc2n517:1334657:0:1334657] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14606c400000)
[uc2n517:1334653:0:1334653] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14fdd4400000)
[uc2n517:1334654:0:1334654] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14f1ae400000)
[uc2n517:1334652:0:1334652] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1492b4400000)
[uc2n517:1334651:0:1334651] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1531e0400000)
==== backtrace (tid:1334655) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x0000000000038b48 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
 9 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
10 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
11 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1334657) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x0000000000038b48 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
 9 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
10 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
11 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1334658) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x0000000000038b48 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
 9 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
10 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
11 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1334656) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x0000000000038b48 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
 9 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
10 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
11 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1334653) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x0000000000038b48 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
 9 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
10 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
11 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1334654) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x0000000000038b48 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
 9 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
10 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
11 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1334652) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x0000000000038b48 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
 9 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
10 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
11 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
[uc2n514:1113767:0:1113767] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14615c400000)
==== backtrace (tid:1334651) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x0000000000038b48 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
 9 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
10 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
11 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
[uc2n514:1113770:0:1113770] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c3a0400000)
[uc2n514:1113768:0:1113768] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x154284400000)
[uc2n514:1113769:0:1113769] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x152a64400000)
[uc2n514:1113765:0:1113765] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14dd90400000)
[uc2n514:1113766:0:1113766] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x153e4c400000)
[uc2n514:1113764:0:1113764] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14d74e400000)
[uc2n514:1113763:0:1113763] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14d3f8400000)
==== backtrace (tid:1113769) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x0000000000038b48 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
11 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
12 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
13 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x00000000004035a1 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1113767) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x0000000000038b48 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
11 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
12 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
13 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x00000000004035a1 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1113770) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x0000000000038b48 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
11 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
12 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
13 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x00000000004035a1 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1113768) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x0000000000038b48 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
11 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
12 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
13 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x00000000004035a1 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1113764) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x0000000000038b48 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
11 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
12 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
13 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x00000000004035a1 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1113765) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x0000000000038b48 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
11 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
12 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
13 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x00000000004035a1 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1113763) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x0000000000038b48 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
11 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
12 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
13 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x00000000004035a1 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1113766) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x0000000000038b48 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
11 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
12 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
13 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x00000000004035a1 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 12 with PID 1334655 on node uc2n517 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1481681] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1481681] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
The call to cuMemcpyAsync failed. This is a unrecoverable error and will
cause the program to abort.
  cuMemcpyAsync(0x150dc2c00000, 0x150fcac00000, 131072) returned value 1
Check the cuda.h file for what the return value means.
--------------------------------------------------------------------------
[uc2n517.localdomain:1335007] CUDA: Error in cuMemcpy: res=-1, dest=0x150dc2c00000, src=0x150fcac00000, size=131072
[uc2n517:1335007] *** Process received signal ***
[uc2n517:1335007] Signal: Aborted (6)
[uc2n517:1335007] Signal code:  (-6)
[uc2n517:1335007] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x15123a43cdd0]
[uc2n517:1335007] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x15123a09f70f]
[uc2n517:1335007] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x15123a089b25]
[uc2n517:1335007] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c58f)[0x15123900958f]
[uc2n517:1335007] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x77119)[0x151239004119]
[uc2n517:1335007] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_datatype_sndrcv+0x50a)[0x151245e42b2a]
[uc2n517:1335007] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x26e)[0x151245e9780e]
[uc2n517:1335007] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x151245ea3702]
[uc2n517:1335007] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x151245e4542b]
[uc2n517:1335007] [ 9] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_decomp.so(_ZN28MPIcuFFT_Slab_Z_Then_YX_Opt1IdE12All2All_SyncEPvb+0xf8)[0x1512505acb48]
[uc2n517:1335007] [10] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_decomp.so(_ZN28MPIcuFFT_Slab_Z_Then_YX_Opt1IdE7execR2CEPvPKv+0x138)[0x1512505ac358]
[uc2n517:1335007] [11] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_tests.so(_ZN27Tests_Slab_Random_Z_Then_YXIdE9testcase0Eii+0x49c)[0x1512507f10de]
[uc2n517:1335007] [12] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_tests.so(_ZN27Tests_Slab_Random_Z_Then_YXIdE3runEiii+0x2f)[0x1512507f0bc9]
[uc2n517:1335007] [13] slab[0x4035a1]
[uc2n517:1335007] [14] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x15123a08b6a3]
[uc2n517:1335007] [15] slab[0x4039fe]
[uc2n517:1335007] *** End of error message ***
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 15 with PID 1335007 on node uc2n517 exited on signal 6 (Aborted).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1481703] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1481703] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n517:1335282:0:1335282] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14fc80400000)
[uc2n517:1335285:0:1335285] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1481b4400000)
[uc2n517:1335288:0:1335288] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x151e94400000)
[uc2n517:1335284:0:1335284] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1469de400000)
[uc2n517:1335286:0:1335286] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c44c400000)
[uc2n517:1335287:0:1335287] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x151910400000)
[uc2n517:1335289:0:1335289] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x145934400000)
[uc2n517:1335283:0:1335283] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1510ae400000)
==== backtrace (tid:1335285) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000039333 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_MPIType()  ???:0
 8 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
 9 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
10 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1335282) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000039333 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_MPIType()  ???:0
 8 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
 9 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
10 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1335288) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000039333 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_MPIType()  ???:0
 8 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
 9 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
10 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1335286) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000039333 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_MPIType()  ???:0
 8 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
 9 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
10 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1335284) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000039333 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_MPIType()  ???:0
 8 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
 9 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
10 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1335287) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000039333 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_MPIType()  ???:0
 8 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
 9 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
10 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1335289) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000039333 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_MPIType()  ???:0
 8 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
 9 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
10 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1335283) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000039333 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_MPIType()  ???:0
 8 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
 9 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
10 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
[uc2n514:1114402:0:1114402] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x146858400000)
[uc2n514:1114399:0:1114399] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x149b1c400000)
[uc2n514:1114401:0:1114401] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x147ea0400000)
[uc2n514:1114403:0:1114403] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x149a7c400000)
[uc2n514:1114404:0:1114404] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14601e400000)
[uc2n514:1114400:0:1114400] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14b7fe400000)
[uc2n514:1114405:0:1114405] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x15498c400000)
[uc2n514:1114406:0:1114406] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c124400000)
==== backtrace (tid:1114402) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x0000000000039333 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_MPIType()  ???:0
10 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
11 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
12 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
13 0x00000000004035a1 main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1114399) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x0000000000039333 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_MPIType()  ???:0
10 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
11 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
12 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
13 0x00000000004035a1 main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1114401) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x0000000000039333 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_MPIType()  ???:0
10 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
11 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
12 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
13 0x00000000004035a1 main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1114403) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x0000000000039333 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_MPIType()  ???:0
10 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
11 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
12 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
13 0x00000000004035a1 main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1114404) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x0000000000039333 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_MPIType()  ???:0
10 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
11 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
12 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
13 0x00000000004035a1 main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1114400) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x0000000000039333 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_MPIType()  ???:0
10 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
11 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
12 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
13 0x00000000004035a1 main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1114405) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x0000000000039333 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_MPIType()  ???:0
10 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
11 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
12 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
13 0x00000000004035a1 main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1114406) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x0000000000039333 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_MPIType()  ???:0
10 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
11 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
12 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
13 0x00000000004035a1 main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 12 with PID 1335286 on node uc2n517 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1481735] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1481735] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
The call to cuMemcpyAsync failed. This is a unrecoverable error and will
cause the program to abort.
  cuMemcpyAsync(0x8637780, 0x148bf8800000, 65536) returned value 1
Check the cuda.h file for what the return value means.
--------------------------------------------------------------------------
[uc2n517.localdomain:1335642] CUDA: Error in cuMemcpy: res=-1, dest=0x8637780, src=0x148bf8800000, size=65536
[uc2n517:1335642] *** Process received signal ***
[uc2n517:1335642] Signal: Aborted (6)
[uc2n517:1335642] Signal code:  (-6)
[uc2n517:1335642] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x148e6beb6dd0]
[uc2n517:1335642] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x148e6bb1970f]
[uc2n517:1335642] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x148e6bb03b25]
[uc2n517:1335642] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x148e6aa83375]
[uc2n517:1335642] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x148e6aa7a1e8]
[uc2n517:1335642] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_datatype_sndrcv+0x1e3)[0x148e778bc803]
[uc2n517:1335642] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_coll_basic_alltoallw_intra+0xa4)[0x148e77950984]
[uc2n517:1335642] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallw+0x1eb)[0x148e778bfccb]
[uc2n517:1335642] [ 8] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_decomp.so(_ZN28MPIcuFFT_Slab_Z_Then_YX_Opt1IdE15All2All_MPITypeEPvb+0x153)[0x148e82027333]
[uc2n517:1335642] [ 9] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_decomp.so(_ZN28MPIcuFFT_Slab_Z_Then_YX_Opt1IdE7execR2CEPvPKv+0x138)[0x148e82026358]
[uc2n517:1335642] [10] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_tests.so(_ZN27Tests_Slab_Random_Z_Then_YXIdE9testcase0Eii+0x49c)[0x148e8226b0de]
[uc2n517:1335642] [11] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_tests.so(_ZN27Tests_Slab_Random_Z_Then_YXIdE3runEiii+0x2f)[0x148e8226abc9]
[uc2n517:1335642] [12] slab[0x4035a1]
[uc2n517:1335642] [13] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x148e6bb056a3]
[uc2n517:1335642] [14] slab[0x4039fe]
[uc2n517:1335642] *** End of error message ***
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 15 with PID 1335642 on node uc2n517 exited on signal 6 (Aborted).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1481755] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1481755] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1481782] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1481782] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1481835] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1481835] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1481854] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1481854] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1481871] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1481871] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1481904] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1481904] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1481921] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1481921] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1481938] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1481938] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1481969] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1481969] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1481985] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1481985] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1482004] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1482004] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1482032] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1482032] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1482049] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1482049] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1482068] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1482068] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1482099] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1482099] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1482118] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1482118] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1482137] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1482137] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1482164] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1482164] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1482183] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1482183] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1482200] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1482200] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1482219] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1482219] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1482252] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1482252] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1482270] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1482270] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1482532] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1482532] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1482551] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1482551] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1482586] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1482586] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1482605] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1482605] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1482632] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1482632] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1482652] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1482652] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1482673] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1482673] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1482925] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1482925] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1482960] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1482960] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1482979] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1482979] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1483031] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1483031] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1483023] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1483023] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1483306] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1483306] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1483338] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1483338] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1483371] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1483371] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1483395] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1483395] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1483413] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1483413] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1483689] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1483689] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1483723] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1483723] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1483754] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1483754] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1483778] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1483778] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1483815] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1483815] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1483921] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1483921] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[28407,1],14]
  Exit code:    1
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1483996] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1483996] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1484035] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1484035] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1484376] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1484376] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1484413] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1484413] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[27710,1],14]
  Exit code:    1
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1484722] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1484722] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1484766] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1484766] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1485300] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1485300] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1485396] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1485396] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1485949] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1485949] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1485997] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1485997] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n517:1349379:0:1349379] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14bdcc400000)
==== backtrace (tid:1349379) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x0000000000038b48 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
 9 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
10 0x000000000002b2a8 Tests_Slab_Random_Z_Then_YX<double>::testcase4()  ???:0
11 0x0000000000028c39 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
[uc2n517:1349380:0:1349380] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x150014400000)
==== backtrace (tid:1349380) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x0000000000038b48 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
 9 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
10 0x000000000002b2a8 Tests_Slab_Random_Z_Then_YX<double>::testcase4()  ???:0
11 0x0000000000028c39 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
[uc2n514:1128560:0:1128560] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1545ae400000)
==== backtrace (tid:1128560) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x0000000000038b48 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
11 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
12 0x000000000002b2a8 Tests_Slab_Random_Z_Then_YX<double>::testcase4()  ???:0
13 0x0000000000028c39 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x00000000004035a1 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
[uc2n514:1128559:0:1128559] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1544e8400000)
==== backtrace (tid:1128559) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x0000000000038b48 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
11 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
12 0x000000000002b2a8 Tests_Slab_Random_Z_Then_YX<double>::testcase4()  ???:0
13 0x0000000000028c39 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x00000000004035a1 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
[uc2n517:1349374:0:1349374] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x153136400000)
==== backtrace (tid:1349374) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x0000000000038b48 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
 9 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
10 0x000000000002b2a8 Tests_Slab_Random_Z_Then_YX<double>::testcase4()  ???:0
11 0x0000000000028c39 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
[uc2n517:1349373:0:1349373] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x148d4e400000)
==== backtrace (tid:1349373) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x0000000000038b48 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
 9 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
10 0x000000000002b2a8 Tests_Slab_Random_Z_Then_YX<double>::testcase4()  ???:0
11 0x0000000000028c39 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[uc2n514:1128553:0:1128553] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1528b8400000)
==== backtrace (tid:1128553) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x0000000000038b48 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
11 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
12 0x000000000002b2a8 Tests_Slab_Random_Z_Then_YX<double>::testcase4()  ???:0
13 0x0000000000028c39 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x00000000004035a1 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
mpiexec noticed that process rank 14 with PID 1349379 on node uc2n517 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1486310] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1486310] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1486396] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1486396] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[26496,1],14]
  Exit code:    1
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1486661] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1486661] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n517:1350106:0:1350106] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14bb5c400000)
==== backtrace (tid:1350106) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000039333 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_MPIType()  ???:0
 8 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
 9 0x000000000002b2a8 Tests_Slab_Random_Z_Then_YX<double>::testcase4()  ???:0
10 0x0000000000028c39 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
[uc2n514:1129287:0:1129287] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x144ce4400000)
==== backtrace (tid:1129287) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x0000000000039333 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_MPIType()  ???:0
10 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
11 0x000000000002b2a8 Tests_Slab_Random_Z_Then_YX<double>::testcase4()  ???:0
12 0x0000000000028c39 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
13 0x00000000004035a1 main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
[uc2n517:1350107:0:1350107] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x147624400000)
==== backtrace (tid:1350107) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000039333 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_MPIType()  ???:0
 8 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
 9 0x000000000002b2a8 Tests_Slab_Random_Z_Then_YX<double>::testcase4()  ???:0
10 0x0000000000028c39 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
[uc2n517:1350101:0:1350101] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14b7be400000)
==== backtrace (tid:1350101) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000039333 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_MPIType()  ???:0
 8 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
 9 0x000000000002b2a8 Tests_Slab_Random_Z_Then_YX<double>::testcase4()  ???:0
10 0x0000000000028c39 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
[uc2n517:1350100:0:1350100] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14f914400000)
==== backtrace (tid:1350100) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000039333 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_MPIType()  ???:0
 8 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
 9 0x000000000002b2a8 Tests_Slab_Random_Z_Then_YX<double>::testcase4()  ???:0
10 0x0000000000028c39 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
[uc2n514:1129286:0:1129286] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1497b4400000)
==== backtrace (tid:1129286) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x0000000000039333 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_MPIType()  ???:0
10 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
11 0x000000000002b2a8 Tests_Slab_Random_Z_Then_YX<double>::testcase4()  ???:0
12 0x0000000000028c39 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
13 0x00000000004035a1 main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 14 with PID 1350106 on node uc2n517 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1486773] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1486773] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n517:1350496:0:1350496] Caught signal 11 (Segmentation fault: invalid permissions for mapped object at address 0x1538ac400000)
==== backtrace (tid:1350496) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000039333 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_MPIType()  ???:0
 8 0x0000000000038358 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
 9 0x000000000002b2a8 Tests_Slab_Random_Z_Then_YX<double>::testcase4()  ???:0
10 0x0000000000028c39 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 15 with PID 1350496 on node uc2n517 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128
2021-09-30 07:30:19.493131
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128
2021-09-30 07:30:45.384372
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128
2021-09-30 07:30:54.596879
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128
2021-09-30 07:31:03.151356
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128
2021-09-30 07:31:12.469284
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128
2021-09-30 07:31:20.930172
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128
2021-09-30 07:31:30.658219
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128
2021-09-30 07:31:39.340366
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128
2021-09-30 07:31:48.478909
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128
2021-09-30 07:31:57.387574
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256
2021-09-30 07:32:06.804967
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256
2021-09-30 07:32:15.304777
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256
2021-09-30 07:32:24.576109
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256
2021-09-30 07:32:33.143282
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256
2021-09-30 07:32:42.413014
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256
2021-09-30 07:32:50.962748
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256
2021-09-30 07:33:00.672087
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256
2021-09-30 07:33:09.324790
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256
2021-09-30 07:33:18.719745
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256
2021-09-30 07:33:27.451474
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256
2021-09-30 07:33:36.905109
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256
2021-09-30 07:33:45.496731
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256
2021-09-30 07:33:54.765347
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256
2021-09-30 07:34:03.435698
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256
2021-09-30 07:34:12.730283
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256
2021-09-30 07:34:21.263203
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256
2021-09-30 07:34:30.493141
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256
2021-09-30 07:34:39.027756
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256
2021-09-30 07:34:47.831331
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256
2021-09-30 07:34:55.927791
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256
2021-09-30 07:35:05.011927
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256
2021-09-30 07:35:13.580322
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256
2021-09-30 07:35:22.480191
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256
2021-09-30 07:35:30.747795
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256
2021-09-30 07:35:39.631759
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256
2021-09-30 07:35:47.908631
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256
2021-09-30 07:35:56.801137
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256
2021-09-30 07:36:04.987514
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256
2021-09-30 07:36:14.007817
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256
2021-09-30 07:36:22.256918
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512
2021-09-30 07:36:31.292802
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512
2021-09-30 07:36:39.816703
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512
2021-09-30 07:36:48.678450
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512
2021-09-30 07:36:56.993678
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512
2021-09-30 07:37:05.954670
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512
2021-09-30 07:37:14.423373
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512
2021-09-30 07:37:23.324665
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512
2021-09-30 07:37:31.681407
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512
2021-09-30 07:37:40.769597
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512
2021-09-30 07:37:49.449684
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512
2021-09-30 07:37:58.592536
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512
2021-09-30 07:38:07.340943
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512
2021-09-30 07:38:16.648548
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512
2021-09-30 07:38:25.798144
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512
2021-09-30 07:38:35.340345
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512
2021-09-30 07:38:44.692404
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512
2021-09-30 07:38:54.445666
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512
2021-09-30 07:39:04.556364
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512
2021-09-30 07:39:14.295176
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512
2021-09-30 07:39:23.875528
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512
2021-09-30 07:39:33.607095
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512
2021-09-30 07:39:43.735334
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512
2021-09-30 07:39:53.644629
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512
2021-09-30 07:40:03.522926
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512
2021-09-30 07:40:13.862729
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512
2021-09-30 07:40:24.591906
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512
2021-09-30 07:40:34.759086
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512
2021-09-30 07:40:44.826070
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512
2021-09-30 07:40:55.121330
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512
2021-09-30 07:41:05.595267
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-30 07:41:15.624449
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-30 07:41:27.315004
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-30 07:41:38.499570
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-30 07:41:49.919725
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-30 07:42:01.001078
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-30 07:42:13.328955
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-30 07:42:24.278480
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-30 07:42:36.110696
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-30 07:42:47.246371
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-30 07:42:59.720876
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-30 07:43:11.174918
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-30 07:43:26.335912
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-30 07:43:39.418212
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-30 07:43:54.101452
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-30 07:44:06.959751
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-30 07:44:24.062628
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-30 07:44:36.882219
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-30 07:44:51.867904
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-30 07:45:04.857984
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-30 07:45:21.474470
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-30 07:45:34.799456
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-30 07:45:57.205725
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-30 07:46:13.522594
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-30 07:46:34.551207
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-30 07:46:51.907980
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-30 07:47:17.141577
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-30 07:47:33.831919
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-30 07:47:55.783530
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-30 07:48:12.409912
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-30 07:48:36.357927
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-30 07:48:53.903226
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-30 07:49:29.807511
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-30 07:49:54.857884
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-30 07:50:30.089821
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-30 07:50:55.030332
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-30 07:51:37.979840
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-30 07:52:03.029651
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-30 07:52:38.953375
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-30 07:53:04.047847
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-30 07:53:43.601712
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-30 07:54:10.178246
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-30 07:55:15.326699
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-30 07:55:55.923652
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-30 07:56:56.611079
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-30 07:57:37.464657
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-30 07:58:57.842509
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-30 07:59:39.775327
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-30 08:00:49.284831
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-30 08:01:30.430812
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-30 08:02:42.265498
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-30 08:03:26.622212
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-30 08:05:29.336834
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-30 08:06:41.290319
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-30 08:08:35.289277
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-30 08:09:47.119176
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-30 08:12:19.808776
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-30 08:13:31.950296
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-30 08:13:47.734042
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-30 08:14:02.534945
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-30 08:14:21.326553
b''

Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 08:14:36.354112
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 08:14:46.224350
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 08:14:55.441745
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 08:15:04.198353
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 08:15:13.350814
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 08:15:22.359963
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 08:15:32.086912
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 08:15:41.117380
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 08:15:50.539963
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 08:15:59.531002
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 08:16:08.920099
b'Result (avg): 5.19268e-09\nResult (max): 5.08699e-08\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 08:16:18.723511
b'Result (avg): 5.19268e-09\nResult (max): 5.08699e-08\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 08:16:28.122206
b'Result (avg): 5.19268e-09\nResult (max): 5.08699e-08\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 08:16:37.077620
b'Result (avg): 5.19268e-09\nResult (max): 5.08699e-08\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 08:16:46.550152
b'Result (avg): 5.19268e-09\nResult (max): 5.08699e-08\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 08:16:56.197455
b'Result (avg): 5.19268e-09\nResult (max): 5.08699e-08\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 08:17:05.571705
b'Result (avg): 5.19268e-09\nResult (max): 5.08699e-08\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 08:17:14.413587
b'Result (avg): 5.19268e-09\nResult (max): 5.08699e-08\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 08:17:23.822363
b'Result (avg): 5.19268e-09\nResult (max): 5.08699e-08\n'

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 08:17:32.933329
b'Result (avg): 5.19268e-09\nResult (max): 5.08699e-08\n'

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 08:17:42.286196
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 08:17:52.576502
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 08:18:03.088798
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 08:18:13.538483
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 08:18:24.524280
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 08:18:35.320080
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 08:18:45.815998
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 08:18:55.964049
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 08:19:06.261211
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 08:19:16.625956
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 08:19:27.165085
b'Result (avg): 7.69765e-07\nResult (max): 9.22816e-06\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 08:19:48.414652
b'Result (avg): 7.69765e-07\nResult (max): 9.22816e-06\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 08:20:09.887530
b'Result (avg): 7.69765e-07\nResult (max): 9.22816e-06\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 08:20:31.008756
b'Result (avg): 7.69765e-07\nResult (max): 9.22816e-06\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 08:20:51.615466
b'Result (avg): 7.69765e-07\nResult (max): 9.22816e-06\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 08:21:13.021174
b'Result (avg): 7.69765e-07\nResult (max): 9.22816e-06\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 08:21:33.508990
b'Result (avg): 7.69765e-07\nResult (max): 9.22816e-06\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 08:21:54.625453
b'Result (avg): 7.69765e-07\nResult (max): 9.22816e-06\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 08:22:15.344465
b'Result (avg): 7.69765e-07\nResult (max): 9.22816e-06\n'

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 08:22:36.874027
b'Result (avg): 7.69765e-07\nResult (max): 9.22816e-06\n'

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 08:22:57.590690
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 08:24:46.096314
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 08:26:03.497605
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 08:28:06.400017
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 08:29:23.739605
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 08:31:34.562834
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 08:33:17.072012
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 08:34:41.107703
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 08:36:15.391158
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 08:37:53.361644
b''

--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1487142] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1487142] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n511:1852165:0:1852165] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14d90c000000)
[uc2n511:1852172:0:1852172] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14d654000000)
[uc2n511:1852171:0:1852171] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x15105e000000)
[uc2n511:1852166:0:1852166] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x15412c000000)
[uc2n511:1852168:0:1852168] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x149dac000000)
[uc2n511:1852169:0:1852169] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14d804000000)
[uc2n511:1852170:0:1852170] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1475a4000000)
[uc2n511:1852167:0:1852167] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14904e000000)
==== backtrace (tid:1852168) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000002cd18 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
 9 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
10 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
11 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1852166) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
==== backtrace (tid:1852171) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000002cd18 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
 9 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
10 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
11 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1852172) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000002cd18 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
 9 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000002cd18 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
 9 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
10 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
11 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1852169) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000002cd18 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
 9 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
10 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
11 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1852167) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000002cd18 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
 9 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
10 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
11 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
==== backtrace (tid:1852165) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000002cd18 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
 9 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
10 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
11 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
10 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
11 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1852170) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000002cd18 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
 9 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
10 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
11 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 15 with PID 1852172 on node uc2n511 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1487428] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1487428] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n511:1852526:0:1852526] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x146768000010)
[uc2n511:1852530:0:1852530] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x153fee000010)
[uc2n511:1852527:0:1852527] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14f940000010)
[uc2n511:1852528:0:1852528] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c686000010)
[uc2n511:1852523:0:1852523] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x149e68000010)
[uc2n511:1852529:0:1852529] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x152c42000010)
[uc2n511:1852525:0:1852525] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x154d8e000010)
[uc2n511:1852524:0:1852524] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x152bb0000010)
==== backtrace (tid:1852530) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002cd18 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
18 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
19 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
20 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
21 0x00000000004035a1 main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1852529) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002cd18 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
18 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
19 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
20 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
21 0x00000000004035a1 main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1852526) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002cd18 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
18 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
19 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
20 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
==== backtrace (tid:1852523) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002cd18 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
18 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
19 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
20 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
21 0x00000000004035a1 main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1852524) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002cd18 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
18 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
19 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
20 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
21 0x00000000004035a1 main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004039fe _start()  ???:0
=================================
21 0x00000000004035a1 main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1852528) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002cd18 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
18 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
19 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
20 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
21 0x00000000004035a1 main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1852525) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002cd18 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
18 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
19 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
20 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
21 0x00000000004035a1 main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1852527) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002cd18 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
18 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
19 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
20 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
21 0x00000000004035a1 main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 13 with PID 1852528 on node uc2n511 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1487706] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1487706] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n511:1852867:0:1852867] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14730e000000)
[uc2n511:1852870:0:1852870] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14d05c000000)
[uc2n511:1852869:0:1852869] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x151b78000000)
[uc2n511:1852868:0:1852868] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14fc62000000)
[uc2n511:1852866:0:1852866] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c948000000)
[uc2n511:1852865:0:1852865] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c7ec000000)
[uc2n511:1852864:0:1852864] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1493f0000000)
[uc2n511:1852863:0:1852863] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1472f8000000)
==== backtrace (tid:1852867) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d3d9 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
 9 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
10 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1852870) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d3d9 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
 9 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
10 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1852869) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d3d9 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
 9 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
10 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1852868) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d3d9 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
 9 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
10 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1852866) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d3d9 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
 9 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
10 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1852865) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d3d9 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
 9 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
10 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1852864) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d3d9 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
 9 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
10 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1852863) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d3d9 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
 9 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
10 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 12 with PID 1852867 on node uc2n511 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1487983] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1487983] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n511:1853213:0:1853213] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x154aae000000)
[uc2n511:1853220:0:1853220] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x148fa2000000)
[uc2n511:1853216:0:1853216] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1456ee000000)
[uc2n511:1853219:0:1853219] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c86a000000)
[uc2n511:1853214:0:1853214] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x146b18000000)
[uc2n511:1853215:0:1853215] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x152468000000)
[uc2n511:1853218:0:1853218] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e740000000)
[uc2n511:1853217:0:1853217] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1528ce000000)
==== backtrace (tid:1853219) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d3d9 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
 9 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
10 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1853220) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d3d9 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
 9 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
10 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1853218) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d3d9 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
 9 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
10 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
==== backtrace (tid:1853213) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d3d9 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
 9 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
10 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1853214) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d3d9 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
 9 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
10 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1853216) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d3d9 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
 9 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
10 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1853215) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d3d9 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
 9 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
10 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1853217) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d3d9 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
 9 0x00000000000290de Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
10 0x0000000000028bc9 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 11 with PID 1853216 on node uc2n511 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1488268] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1488268] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1488536] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1488536] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1488805] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1488805] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1489109] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1489109] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1489393] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1489393] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1489661] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1489661] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1489932] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1489932] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1490211] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1490211] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1490476] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1490476] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1490744] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1490744] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1491025] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1491025] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1491290] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1491290] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1491558] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1491558] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1491866] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1491866] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1492150] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1492150] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1492420] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1492420] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1492699] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1492699] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1492967] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1492967] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1493237] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1493237] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1493515] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1493515] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1493786] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1493786] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1494054] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1494054] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1494337] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1494337] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1494631] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1494631] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1494914] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1494914] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1495195] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1495195] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1495470] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1495470] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1495745] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1495745] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1496015] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1496015] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1496285] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1496285] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1496568] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1496568] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1496839] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1496839] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1497123] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1497123] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1497430] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1497430] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1497733] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1497733] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1498005] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1498005] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1498293] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1498293] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1498577] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1498577] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1498864] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1498864] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1499143] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1499143] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1499432] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1499432] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1499780] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1499780] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[10466,1],14]
  Exit code:    1
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1500111] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1500111] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1500506] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1500506] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[12092,1],14]
  Exit code:    1
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1500881] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1500881] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1501248] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1501248] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1501636] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1501636] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n511:1867108:0:1867108] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x149114000000)
==== backtrace (tid:1867108) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000002cd18 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
 9 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
10 0x000000000002b2a8 Tests_Slab_Random_Z_Then_YX<double>::testcase4()  ???:0
11 0x0000000000028c39 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
[uc2n511:1867109:0:1867109] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e7c8000000)
==== backtrace (tid:1867109) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000002cd18 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
 9 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
10 0x000000000002b2a8 Tests_Slab_Random_Z_Then_YX<double>::testcase4()  ???:0
11 0x0000000000028c39 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
[uc2n511:1867102:0:1867102] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14a57c000000)
[uc2n511:1867103:0:1867103] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14d420000000)
==== backtrace (tid:1867103) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000002cd18 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
 9 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
10 0x000000000002b2a8 Tests_Slab_Random_Z_Then_YX<double>::testcase4()  ???:0
11 0x0000000000028c39 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1867102) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000002cd18 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
 9 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
10 0x000000000002b2a8 Tests_Slab_Random_Z_Then_YX<double>::testcase4()  ???:0
11 0x0000000000028c39 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 14 with PID 1867108 on node uc2n511 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1501970] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1501970] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[8564,1],14]
  Exit code:    1
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1502314] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1502314] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n511:1867837:0:1867837] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x147f1c000000)
==== backtrace (tid:1867837) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d3d9 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
 9 0x000000000002b2a8 Tests_Slab_Random_Z_Then_YX<double>::testcase4()  ???:0
10 0x0000000000028c39 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
[uc2n511:1867838:0:1867838] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1547a2000000)
==== backtrace (tid:1867838) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d3d9 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
 9 0x000000000002b2a8 Tests_Slab_Random_Z_Then_YX<double>::testcase4()  ???:0
10 0x0000000000028c39 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
[uc2n511:1867831:0:1867831] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x152080000000)
[uc2n511:1867832:0:1867832] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x15450c000000)
==== backtrace (tid:1867832) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d3d9 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
 9 0x000000000002b2a8 Tests_Slab_Random_Z_Then_YX<double>::testcase4()  ???:0
10 0x0000000000028c39 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1867831) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d3d9 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
 9 0x000000000002b2a8 Tests_Slab_Random_Z_Then_YX<double>::testcase4()  ???:0
10 0x0000000000028c39 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 14 with PID 1867837 on node uc2n511 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1502657] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1502657] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n511:1868234:0:1868234] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x146506000000)
==== backtrace (tid:1868234) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d3d9 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
 9 0x000000000002b2a8 Tests_Slab_Random_Z_Then_YX<double>::testcase4()  ???:0
10 0x0000000000028c39 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
[uc2n511:1868235:0:1868235] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x150022000000)
==== backtrace (tid:1868235) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d3d9 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
 9 0x000000000002b2a8 Tests_Slab_Random_Z_Then_YX<double>::testcase4()  ???:0
10 0x0000000000028c39 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
[uc2n511:1868229:0:1868229] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14578a000000)
==== backtrace (tid:1868229) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d3d9 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
 9 0x000000000002b2a8 Tests_Slab_Random_Z_Then_YX<double>::testcase4()  ???:0
10 0x0000000000028c39 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[uc2n511:1868228:0:1868228] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x148f32000000)
==== backtrace (tid:1868228) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d3d9 MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002b792 MPIcuFFT_Slab_Z_Then_YX<double>::execR2C()  ???:0
 9 0x000000000002b2a8 Tests_Slab_Random_Z_Then_YX<double>::testcase4()  ???:0
10 0x0000000000028c39 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
mpiexec noticed that process rank 14 with PID 1868234 on node uc2n511 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128
2021-09-30 07:30:19.493286
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128
2021-09-30 07:30:34.307352
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128
2021-09-30 07:30:43.060308
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128
2021-09-30 07:30:51.260593
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128
2021-09-30 07:31:00.157859
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128
2021-09-30 07:31:08.629852
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128
2021-09-30 07:31:19.258097
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128
2021-09-30 07:31:27.277892
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128
2021-09-30 07:31:35.987948
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128
2021-09-30 07:31:44.313221
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 256
2021-09-30 07:31:55.389384
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 256
2021-09-30 07:32:03.357841
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 256
2021-09-30 07:32:12.488618
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 256
2021-09-30 07:32:20.602415
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 256
2021-09-30 07:32:29.664028
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 256
2021-09-30 07:32:37.732731
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 256
2021-09-30 07:32:48.585227
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 256
2021-09-30 07:32:57.096197
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 256
2021-09-30 07:33:05.845873
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 256
2021-09-30 07:33:13.989484
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 256 -nz 256
2021-09-30 07:33:25.180605
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 256 -nz 256
2021-09-30 07:33:33.425901
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 256 -nz 256
2021-09-30 07:33:42.319875
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 256 -nz 256
2021-09-30 07:33:50.459037
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 256 -nz 256
2021-09-30 07:33:59.318931
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 256 -nz 256
2021-09-30 07:34:07.666886
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 256 -nz 256
2021-09-30 07:34:20.347013
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 256 -nz 256
2021-09-30 07:34:28.369701
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 256 -nz 256
2021-09-30 07:34:37.062713
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 256 -nz 256
2021-09-30 07:34:45.653466
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256
2021-09-30 07:34:58.933787
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256
2021-09-30 07:35:07.088935
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256
2021-09-30 07:35:15.956893
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256
2021-09-30 07:35:24.266282
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256
2021-09-30 07:35:33.133978
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256
2021-09-30 07:35:41.309619
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256
2021-09-30 07:35:57.789499
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256
2021-09-30 07:36:05.971956
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256
2021-09-30 07:36:14.981954
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256
2021-09-30 07:36:23.269900
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 512
2021-09-30 07:36:40.905105
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 512
2021-09-30 07:36:49.334894
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 512
2021-09-30 07:36:58.450719
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 512
2021-09-30 07:37:06.800099
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 512
2021-09-30 07:37:15.789316
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 512
2021-09-30 07:37:24.300281
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 512
2021-09-30 07:37:40.803425
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 512
2021-09-30 07:37:48.893931
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 512
2021-09-30 07:37:57.494602
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 512
2021-09-30 07:38:05.641675
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 512 -nz 512
2021-09-30 07:38:22.941528
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 512 -nz 512
2021-09-30 07:38:31.857658
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 512 -nz 512
2021-09-30 07:38:41.102971
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 512 -nz 512
2021-09-30 07:38:49.879677
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 512 -nz 512
2021-09-30 07:38:59.151899
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 512 -nz 512
2021-09-30 07:39:08.202244
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 512 -nz 512
2021-09-30 07:39:32.999084
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 512 -nz 512
2021-09-30 07:39:41.782779
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 512 -nz 512
2021-09-30 07:39:52.750846
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 512 -nz 512
2021-09-30 07:40:01.835723
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512
2021-09-30 07:40:28.704996
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512
2021-09-30 07:40:38.290897
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512
2021-09-30 07:40:47.961423
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512
2021-09-30 07:40:57.749948
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512
2021-09-30 07:41:07.647213
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512
2021-09-30 07:41:17.769860
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512
2021-09-30 07:41:58.210480
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512
2021-09-30 07:42:07.862633
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512
2021-09-30 07:42:17.512391
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512
2021-09-30 07:42:28.033775
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 1024
2021-09-30 07:43:12.298721
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 1024
2021-09-30 07:43:23.512955
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 1024
2021-09-30 07:43:34.195564
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 1024
2021-09-30 07:43:45.286976
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 1024
2021-09-30 07:43:56.146938
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 1024
2021-09-30 07:44:08.415690
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 1024
2021-09-30 07:44:49.512983
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 1024
2021-09-30 07:45:01.022739
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 1024
2021-09-30 07:45:11.910596
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 1024
2021-09-30 07:45:24.931033
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 1024 -nz 1024
2021-09-30 07:46:09.900247
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 1024 -nz 1024
2021-09-30 07:46:24.692589
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 1024 -nz 1024
2021-09-30 07:46:37.914720
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 1024 -nz 1024
2021-09-30 07:46:52.952447
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 1024 -nz 1024
2021-09-30 07:47:06.286878
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 1024 -nz 1024
2021-09-30 07:47:23.043943
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 1024 -nz 1024
2021-09-30 07:48:36.568415
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 1024 -nz 1024
2021-09-30 07:48:52.032083
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 1024 -nz 1024
2021-09-30 07:49:05.131961
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 1024 -nz 1024
2021-09-30 07:49:23.983050
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024
2021-09-30 07:50:46.958175
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024
2021-09-30 07:51:08.607002
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024
2021-09-30 07:51:25.843343
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024
2021-09-30 07:51:47.109599
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024
2021-09-30 07:52:04.646025
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024
2021-09-30 07:52:29.754461
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024
2021-09-30 07:54:48.520993
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024
2021-09-30 07:55:10.293787
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024
2021-09-30 07:55:27.554316
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024
2021-09-30 07:55:54.754478
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048
2021-09-30 07:58:28.968889
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048
2021-09-30 07:59:03.912298
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048
2021-09-30 07:59:30.437054
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048
2021-09-30 08:00:05.010431
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048
2021-09-30 08:00:32.612668
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048
2021-09-30 08:01:15.360582
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048
2021-09-30 08:03:40.924143
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048
2021-09-30 08:04:17.358364
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048
2021-09-30 08:04:44.174906
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048
2021-09-30 08:05:29.983939
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048
2021-09-30 08:08:11.269674
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048
2021-09-30 08:09:14.168389
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048
2021-09-30 08:10:01.852006
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048
2021-09-30 08:11:04.653406
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048
2021-09-30 08:11:54.090192
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048
2021-09-30 08:13:12.214160
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048
2021-09-30 08:17:54.154458
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048
2021-09-30 08:19:02.022654
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048
2021-09-30 08:19:48.270592
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048
2021-09-30 08:21:13.765707
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048
2021-09-30 08:26:27.562960
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048
2021-09-30 08:28:28.968271
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048
2021-09-30 08:30:01.101927
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048
2021-09-30 08:31:59.539115
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048
2021-09-30 08:33:29.674706
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048
2021-09-30 08:35:55.583338
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048
2021-09-30 08:45:11.519117
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048
2021-09-30 08:45:28.642323
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048
2021-09-30 08:45:44.592833
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048
2021-09-30 08:46:01.666132
b''

Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 08:46:17.865114
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 08:46:28.831544
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 08:46:38.105450
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 08:46:47.095558
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 08:46:56.437113
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 08:47:05.462220
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 08:47:15.000263
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 08:47:23.980021
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 08:47:33.305959
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-30 08:47:42.339647
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 08:47:51.952244
b'Result (avg): 5.01733e-09\nResult (max): 5.42241e-08\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 08:48:01.018383
b'Result (avg): 5.01733e-09\nResult (max): 5.42241e-08\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 08:48:10.506973
b'Result (avg): 5.01733e-09\nResult (max): 5.42241e-08\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 08:48:19.433419
b'Result (avg): 5.01733e-09\nResult (max): 5.42241e-08\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 08:48:29.484208
b'Result (avg): 5.01733e-09\nResult (max): 5.42241e-08\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 08:48:38.752998
b'Result (avg): 5.01733e-09\nResult (max): 5.42241e-08\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 08:48:48.919699
b'Result (avg): 5.01733e-09\nResult (max): 5.42241e-08\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 08:48:58.278146
b'Result (avg): 5.01733e-09\nResult (max): 5.42241e-08\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 08:49:07.695628
b'Result (avg): 5.01733e-09\nResult (max): 5.42241e-08\n'

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-30 08:49:16.740871
b'Result (avg): 5.01733e-09\nResult (max): 5.42241e-08\n'

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 08:49:26.939005
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 08:49:37.572822
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 08:49:48.691627
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 08:49:59.644569
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 08:50:11.377426
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 08:50:22.315243
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 08:50:36.029380
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 08:50:46.554963
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 08:50:57.518973
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-30 08:51:08.456232
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 08:51:22.351458
b'Result (avg): 7.38396e-07\nResult (max): 8.69717e-06\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 08:51:43.925762
b'Result (avg): 7.38396e-07\nResult (max): 8.69717e-06\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 08:52:04.978598
b'Result (avg): 7.38396e-07\nResult (max): 8.69717e-06\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 08:52:26.325316
b'Result (avg): 7.38396e-07\nResult (max): 8.69717e-06\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 08:52:47.602340
b'Result (avg): 7.38396e-07\nResult (max): 8.69717e-06\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 08:53:10.156663
b'Result (avg): 7.38396e-07\nResult (max): 8.69717e-06\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 08:53:41.862451
b'Result (avg): 7.38396e-07\nResult (max): 8.69717e-06\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 08:54:03.957280
b'Result (avg): 7.38396e-07\nResult (max): 8.69717e-06\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 08:54:25.264479
b'Result (avg): 7.38396e-07\nResult (max): 8.69717e-06\n'

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-30 08:54:47.652598
b'Result (avg): 7.38396e-07\nResult (max): 8.69717e-06\n'

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 08:55:20.396335
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 08:57:10.088314
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 08:58:29.152689
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 09:00:33.571509
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 09:01:52.902157
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 09:04:00.212731
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 09:06:26.362320
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 09:07:52.603887
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 09:09:28.768461
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/forward -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-30 09:11:11.317185
b''

Slab 2D->1D default/opt1 (inverse)
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1503013] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1503013] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1503038] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1503038] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1503012] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1503012] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1503313] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1503313] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1503320] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1503320] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1503591] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1503591] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1503620] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1503620] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1504131] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1504131] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1504149] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1504149] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1504414] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1504414] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1504431] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1504431] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1504695] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1504695] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1504713] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1504713] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1504993] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1504993] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1505011] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1505011] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1505265] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1505265] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1505290] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1505290] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1505542] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1505542] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1505570] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1505570] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1505835] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1505835] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1505863] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1505863] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1506115] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1506115] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1506143] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1506143] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1506349] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1506349] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1506425] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1506425] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1506531] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1506531] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1506716] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1506716] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1506811] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1506811] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1507240] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1507240] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1507248] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1507248] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1507525] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1507525] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1507620] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1507620] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1507820] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1507820] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1507915] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1507915] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1508095] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1508095] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1508113] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1508113] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1508376] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1508376] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1508394] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1508394] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1508675] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1508675] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1508770] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1508770] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1509049] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1509049] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1508954] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1508954] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1509235] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1509235] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1509236] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1509236] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1509520] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1509520] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1509538] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1509538] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1509800] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1509800] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1509818] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1509818] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1510329] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1510329] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1510347] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1510347] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1510631] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1510631] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1510728] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1510728] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1510913] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1510913] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1511008] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1511008] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1511194] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1511194] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1511289] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1511289] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1511485] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1511485] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1511580] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1511580] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1511765] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1511765] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1512018] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1512018] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1512047] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1512047] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1512311] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1512311] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1512342] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1512342] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1512593] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1512593] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1512622] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1512622] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1512875] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1512875] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1512904] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1512904] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1513163] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1513163] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1513450] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1513450] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1513702] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1513702] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1513730] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1513730] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1513993] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1513993] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1514011] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1514011] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1514280] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1514280] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1514301] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1514301] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1514563] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1514563] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1514581] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1514581] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1514845] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1514845] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1514865] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1514865] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1515144] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1515144] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1515297] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1515297] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1515423] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1515423] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1515572] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1515572] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1515706] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1515706] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1515959] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1515959] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1516004] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1516004] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1516100] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1516100] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1516534] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1516534] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1516704] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1516704] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1516816] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1516816] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1516982] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1516982] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1517108] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1517108] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1517374] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1517374] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1517470] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1517470] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1517655] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1517655] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1517751] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1517751] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1517946] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1517946] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1518044] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1518044] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1518227] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1518227] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1518323] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1518323] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1518543] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1518543] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1518827] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1518827] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1518831] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1518831] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1519102] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1519102] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1519120] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1519120] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1519632] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1519632] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1519650] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1519650] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1519925] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1519925] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1519943] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1519943] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1520205] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1520205] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1520223] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1520223] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1520486] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1520486] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1520504] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1520504] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1520783] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1520783] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1521051] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1521051] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1521147] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1521147] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1521336] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1521336] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1521440] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1521440] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1521626] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1521626] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1521723] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1521723] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1521906] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1521906] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1521913] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1521913] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1522198] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1522198] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1522715] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1522715] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1522966] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1522966] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1522998] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1522998] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1523248] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1523248] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1523291] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1523291] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1523541] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1523541] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1523570] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1523570] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1523822] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1523822] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1523852] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1523852] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1524019] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1524019] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1524149] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1524149] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1524305] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1524305] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1524429] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1524429] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1524705] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1524705] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1524969] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1524969] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1524989] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1524989] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1525242] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1525242] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1525273] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1525273] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1525432] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1525432] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1525813] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1525813] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1525908] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1525908] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1526095] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1526095] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1526379] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1526379] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1526634] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1526634] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1526663] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1526663] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1526915] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1526915] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1526946] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1526946] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1527206] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1527206] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1527237] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1527237] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1527490] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1527490] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1527520] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1527520] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1527618] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1527618] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1527812] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1527812] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1528066] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1528066] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1528094] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1528094] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1528378] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1528378] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1528900] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1528900] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1528995] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1528995] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1529196] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1529196] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1529291] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1529291] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1529475] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1529475] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1529494] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1529494] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1529758] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1529758] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1529786] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1529786] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1530056] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1530056] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1530327] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1530327] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1530606] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1530606] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1530626] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1530626] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1530891] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1530891] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1530909] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1530909] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1531186] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1531186] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1531207] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1531207] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1531307] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1531307] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1531502] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1531502] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1531520] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1531520] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1531917] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1531917] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1532069] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1532069] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1532339] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1532339] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1532625] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1532625] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1532902] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1532902] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1533167] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1533167] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1533190] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1533190] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1533308] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1533308] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1533487] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1533487] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1533505] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1533505] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1533771] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1533771] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1533802] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1533802] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1534074] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1534074] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1534364] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1534364] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1534647] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1534647] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1534666] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1534666] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1535051] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1535051] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1535220] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1535220] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1535318] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1535318] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1535512] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1535512] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1535530] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1535530] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1535816] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1535816] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1535842] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1535842] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1536005] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1536005] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1536141] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1536141] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1536432] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1536432] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1536712] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1536712] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1536732] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1536732] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1537009] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1537009] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1537032] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1537032] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1537059] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1537059] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1537330] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1537330] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1537349] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1537349] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1537679] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1537679] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1537943] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1537943] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1537988] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1537988] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1538276] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1538276] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1538450] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1538450] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1538573] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1538573] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1538840] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1538840] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1538887] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1538887] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1538883] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1538883] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1539193] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1539193] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1539232] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1539232] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1539529] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1539529] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1539847] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1539847] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1540113] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1540113] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1540149] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1540149] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1540417] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1540417] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1540448] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1540448] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1540493] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1540493] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1540769] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1540769] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1540813] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1540813] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1541179] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1541179] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1541440] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1541440] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1541501] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1541501] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1541515] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1541515] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1541911] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1541911] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1542126] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1542126] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1542155] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1542155] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1542443] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1542443] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1542489] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1542489] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1542775] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1542775] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1542878] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1542878] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1543198] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1543198] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n511:1907755:0:1907755] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x154c9c280000)
[uc2n511:1907759:0:1907759] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c8ac380000)
[uc2n511:1907754:0:1907754] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x145c54240000)
[uc2n511:1907756:0:1907756] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x145afc2c0000)
[uc2n511:1907760:0:1907760] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14fc263c0000)
[uc2n511:1907753:0:1907753] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e1a0200000)
[uc2n511:1907757:0:1907757] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x148bdc300000)
[uc2n511:1907758:0:1907758] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x148994340000)
==== backtrace (tid:1907755) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001088e MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
 9 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
10 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
11 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1907754) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001088e MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
 9 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
10 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
11 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1907759) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001088e MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
 9 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
10 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
11 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1907753) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001088e MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
 9 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
10 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
11 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1907756) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001088e MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
 9 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
10 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
11 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1907760) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001088e MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
 9 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
10 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
11 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1907757) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001088e MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
 9 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
10 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
11 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1907758) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001088e MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
 9 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
10 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
11 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 14 with PID 1907759 on node uc2n511 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1543462] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1543462] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n511:1908100:0:1908100] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1519062c0010)
[uc2n511:1908098:0:1908098] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e84a240010)
[uc2n511:1908097:0:1908097] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14b692200010)
[uc2n511:1908101:0:1908101] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x15350e300010)
[uc2n511:1908102:0:1908102] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x148c56340010)
[uc2n511:1908103:0:1908103] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x152b38380010)
[uc2n511:1908104:0:1908104] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c65e3c0010)
[uc2n511:1908099:0:1908099] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x145926280010)
==== backtrace (tid:1908100) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000001088e MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
17 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
18 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
19 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
20 0x000000000040332f main()  ???:0
21 0x00000000000236a3 __libc_start_main()  ???:0
22 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1908097) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000001088e MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
17 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
18 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
19 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
20 0x000000000040332f main()  ???:0
21 0x00000000000236a3 __libc_start_main()  ???:0
22 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1908098) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000001088e MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
17 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
18 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
19 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
20 0x000000000040332f main()  ???:0
21 0x00000000000236a3 __libc_start_main()  ???:0
22 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1908099) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000001088e MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
17 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
18 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
19 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
20 0x000000000040332f main()  ???:0
21 0x00000000000236a3 __libc_start_main()  ???:0
22 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1908101) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000001088e MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
17 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
18 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
19 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
20 0x000000000040332f main()  ???:0
21 0x00000000000236a3 __libc_start_main()  ???:0
22 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1908102) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000001088e MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
17 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
18 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
19 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
20 0x000000000040332f main()  ???:0
21 0x00000000000236a3 __libc_start_main()  ???:0
22 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1908103) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000001088e MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
17 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
18 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
19 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
20 0x000000000040332f main()  ???:0
21 0x00000000000236a3 __libc_start_main()  ???:0
22 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1908104) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000001088e MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
17 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
18 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
19 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
20 0x000000000040332f main()  ???:0
21 0x00000000000236a3 __libc_start_main()  ???:0
22 0x00000000004039fe _start()  ???:0
=================================
[uc2n510:1543482:0:1543482] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14a290200000)
[uc2n510:1543479:0:1543479] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1478c6200000)
[uc2n510:1543485:0:1543485] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1451d6200000)
[uc2n510:1543484:0:1543484] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14544e200000)
[uc2n510:1543481:0:1543481] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14ada2200000)
[uc2n510:1543483:0:1543483] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1486c2200000)
[uc2n510:1543480:0:1543480] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14de12200000)
[uc2n510:1543486:0:1543486] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14b55e200000)
==== backtrace (tid:1543486) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000001088e MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
11 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
12 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
13 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
14 0x000000000040332f main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1543485) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000001088e MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
11 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
12 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
13 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
14 0x000000000040332f main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1543483) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000001088e MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
11 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
12 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
13 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
14 0x000000000040332f main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1543484) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000001088e MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
11 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
12 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
13 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
14 0x000000000040332f main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1543482) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000001088e MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
11 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
12 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
13 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
14 0x000000000040332f main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1543481) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000001088e MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
11 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
12 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
13 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
14 0x000000000040332f main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1543480) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000001088e MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
11 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
12 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
13 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
14 0x000000000040332f main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1543479) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000001088e MPIcuFFT_Slab<double>::All2All_Sync()  ???:0
11 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
12 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
13 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
14 0x000000000040332f main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 12 with PID 1908101 on node uc2n511 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1543813] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1543813] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1544146] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1544146] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n511:1908818:0:1908818] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14ad02200000)
[uc2n511:1908823:0:1908823] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14aeae340000)
[uc2n511:1908825:0:1908825] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x147dea3c0000)
[uc2n511:1908822:0:1908822] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1481d0300000)
[uc2n511:1908819:0:1908819] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14716e240000)
[uc2n511:1908821:0:1908821] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14af662c0000)
[uc2n511:1908820:0:1908820] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14d67a280000)
[uc2n511:1908824:0:1908824] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14905e380000)
==== backtrace (tid:1908821) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010f81 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
 9 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
10 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1908818) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010f81 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
 9 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
10 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1908819) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010f81 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
 9 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
10 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1908824) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010f81 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
 9 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
10 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1908825) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010f81 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
 9 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
10 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1908823) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010f81 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
 9 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
10 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1908822) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010f81 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
 9 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
10 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1908820) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000010f81 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
 8 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
 9 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
10 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
[uc2n510.localdomain:1544193] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1544193] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510:1544213:0:1544213] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14bd52200000)
[uc2n510:1544212:0:1544212] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14a918200000)
[uc2n510:1544206:0:1544206] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x152442200000)
[uc2n510:1544207:0:1544207] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14f54e200000)
[uc2n510:1544211:0:1544211] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x151360200000)
[uc2n510:1544210:0:1544210] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c9aa200000)
[uc2n510:1544208:0:1544208] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x146c90200000)
[uc2n510:1544209:0:1544209] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x153f06200000)
==== backtrace (tid:1544212) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x0000000000010f81 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
10 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
11 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
12 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
13 0x000000000040332f main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1544213) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x0000000000010f81 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
10 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
11 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
12 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
13 0x000000000040332f main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1544207) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x0000000000010f81 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
10 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
11 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
12 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
13 0x000000000040332f main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1544210) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x0000000000010f81 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
10 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
11 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
12 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
13 0x000000000040332f main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1544211) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x0000000000010f81 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
10 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
11 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
12 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
13 0x000000000040332f main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1544206) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x0000000000010f81 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
10 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
11 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
12 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
13 0x000000000040332f main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1544208) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x0000000000010f81 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
10 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
11 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
12 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
13 0x000000000040332f main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1544209) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x0000000000010f81 MPIcuFFT_Slab<double>::All2All_MPIType()  ???:0
10 0x0000000000010205 MPIcuFFT_Slab<double>::execC2R()  ???:0
11 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
12 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
13 0x000000000040332f main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 15 with PID 1908825 on node uc2n511 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 09:12:49.730316
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 09:13:08.069046
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 09:13:18.025431
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 09:13:27.471164
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 09:13:37.471587
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 09:13:46.771669
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 09:13:56.934490
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 09:14:06.488966
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 09:14:16.906813
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 09:14:26.483882
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 09:14:36.863219
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 09:14:46.598655
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 09:14:56.797495
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 09:15:06.486113
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 09:15:16.636543
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 09:15:26.094589
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 09:15:36.346626
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 09:15:45.781639
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 09:15:55.779331
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 09:16:05.416238
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 09:16:15.945012
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 09:16:25.347861
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 09:16:35.620062
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 09:16:45.113077
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 09:16:55.535938
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 09:17:05.087496
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 09:17:15.186183
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 09:17:24.589502
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 09:17:34.718802
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 09:17:44.146983
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 09:17:54.529908
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 09:18:04.011475
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 09:18:14.054055
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 09:18:23.685648
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 09:18:34.191603
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 09:18:43.730675
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 09:18:53.883599
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 09:19:03.379297
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 09:19:13.596168
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 09:19:23.245744
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 09:19:33.698433
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 09:19:43.537854
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 09:19:53.654236
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 09:20:04.082346
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 09:20:14.343774
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 09:20:24.108691
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 09:20:34.743149
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 09:20:44.599178
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 09:20:54.963127
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 09:21:04.758127
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 09:21:15.111142
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 09:21:25.329156
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 09:21:35.880586
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 09:21:46.147795
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 09:21:56.711563
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 09:22:06.958560
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 09:22:17.417776
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 09:22:27.583021
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 09:22:38.173952
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 09:22:48.459517
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 09:22:59.157102
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 09:23:10.298028
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 09:23:21.136335
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 09:23:32.224346
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 09:23:43.198510
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 09:23:54.326238
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 09:24:05.545955
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 09:24:16.573741
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 09:24:27.502708
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 09:24:38.781149
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 09:24:50.111116
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 09:25:02.516363
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 09:25:14.441453
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 09:25:26.851319
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 09:25:38.856071
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 09:25:51.815226
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 09:26:03.859495
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 09:26:16.383929
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 09:26:28.181830
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 09:26:40.946470
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:26:52.761750
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:27:08.065721
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:27:21.559083
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:27:36.536551
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:27:49.675639
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:28:06.068575
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:28:19.704349
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:28:34.751220
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:28:47.721444
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:29:04.469981
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:29:18.513444
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:29:40.366384
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:30:00.178948
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:30:21.136448
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:30:37.986791
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:31:02.117191
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:31:19.027902
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:31:40.999584
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:31:58.097508
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:32:22.223584
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 09:32:40.657050
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 09:33:15.906972
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 09:33:40.289336
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 09:34:13.890280
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 09:34:38.073274
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 09:35:17.134257
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 09:35:41.306656
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 09:36:16.218574
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 09:36:41.281983
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 09:37:19.973984
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 09:37:47.443731
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 09:38:51.810446
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 09:39:32.165363
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 09:40:29.756004
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 09:41:10.294717
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 09:42:19.773130
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 09:43:00.979969
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 09:44:02.296411
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 09:44:41.387694
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 09:45:49.415680
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 09:46:34.105994
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 09:48:28.855261
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 09:49:40.045301
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 09:51:30.444714
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 09:52:42.568151
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 09:54:50.352235
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 09:55:57.415024
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 09:56:14.454382
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 09:56:28.192572
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 09:58:34.674095
b''

--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1544554] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1544554] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1544596] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1544596] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1544721] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1544721] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1545034] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1545034] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1545147] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1545147] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1545210] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1545210] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1545304] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1545304] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1545388] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1545388] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1545509] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1545509] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1545771] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1545771] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n517:1396023:0:1396023] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x152f4e280000)
[uc2n517:1396026:0:1396026] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14d394340000)
[uc2n517:1396028:0:1396028] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1459903c0000)
[uc2n517:1396021:0:1396021] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x149394200000)
[uc2n517:1396022:0:1396022] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x150fd4240000)
[uc2n517:1396024:0:1396024] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14d89c2c0000)
[uc2n517:1396027:0:1396027] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14d866380000)
[uc2n517:1396025:0:1396025] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x153a3a300000)
[uc2n514:1175378:0:1175378] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x148b08200000)
[uc2n514:1175381:0:1175381] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1480fe200000)
[uc2n514:1175383:0:1175383] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1502b0200000)
[uc2n514:1175376:0:1175376] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14dc3c200000)
[uc2n514:1175377:0:1175377] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c620200000)
[uc2n514:1175379:0:1175379] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14818e200000)
[uc2n514:1175382:0:1175382] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c32e200000)
[uc2n514:1175380:0:1175380] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14faf8200000)
==== backtrace (tid:1396022) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001ee17 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
 9 0x000000000001e765 MPIcuFFT_Slab_Opt1<double>::execC2R()  ???:0
10 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
11 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1396027) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001ee17 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
 9 0x000000000001e765 MPIcuFFT_Slab_Opt1<double>::execC2R()  ???:0
10 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
11 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1396023) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001ee17 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
 9 0x000000000001e765 MPIcuFFT_Slab_Opt1<double>::execC2R()  ???:0
10 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
11 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1396024) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001ee17 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
 9 0x000000000001e765 MPIcuFFT_Slab_Opt1<double>::execC2R()  ???:0
10 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
11 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1396025) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001ee17 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
 9 0x000000000001e765 MPIcuFFT_Slab_Opt1<double>::execC2R()  ???:0
10 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
11 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1396021) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001ee17 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
 9 0x000000000001e765 MPIcuFFT_Slab_Opt1<double>::execC2R()  ???:0
10 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
11 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1396028) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001ee17 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
 9 0x000000000001e765 MPIcuFFT_Slab_Opt1<double>::execC2R()  ???:0
10 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
11 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1396026) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000001ee17 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
 9 0x000000000001e765 MPIcuFFT_Slab_Opt1<double>::execC2R()  ???:0
10 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
11 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
12 0x000000000040332f main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1175378) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000001ee17 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
11 0x000000000001e765 MPIcuFFT_Slab_Opt1<double>::execC2R()  ???:0
12 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
13 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
14 0x000000000040332f main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1175383) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000001ee17 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
11 0x000000000001e765 MPIcuFFT_Slab_Opt1<double>::execC2R()  ???:0
12 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
13 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
14 0x000000000040332f main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1175381) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000001ee17 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
11 0x000000000001e765 MPIcuFFT_Slab_Opt1<double>::execC2R()  ???:0
12 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
13 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
14 0x000000000040332f main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1175376) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000001ee17 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
11 0x000000000001e765 MPIcuFFT_Slab_Opt1<double>::execC2R()  ???:0
12 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
13 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
14 0x000000000040332f main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1175377) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000001ee17 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
11 0x000000000001e765 MPIcuFFT_Slab_Opt1<double>::execC2R()  ???:0
12 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
13 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
14 0x000000000040332f main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1175379) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000001ee17 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
11 0x000000000001e765 MPIcuFFT_Slab_Opt1<double>::execC2R()  ???:0
12 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
13 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
14 0x000000000040332f main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1175382) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000001ee17 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
11 0x000000000001e765 MPIcuFFT_Slab_Opt1<double>::execC2R()  ???:0
12 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
13 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
14 0x000000000040332f main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1175380) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000001ee17 MPIcuFFT_Slab_Opt1<double>::All2All_Sync()  ???:0
11 0x000000000001e765 MPIcuFFT_Slab_Opt1<double>::execC2R()  ???:0
12 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
13 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
14 0x000000000040332f main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 2 with PID 1175378 on node uc2n514 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1545800] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1545800] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
The call to cuMemcpyAsync failed. This is a unrecoverable error and will
cause the program to abort.
  cuMemcpyAsync(0x146cfec00000, 0x146af3000000, 131072) returned value 1
Check the cuda.h file for what the return value means.
--------------------------------------------------------------------------
[uc2n517.localdomain:1396389] CUDA: Error in cuMemcpy: res=-1, dest=0x146cfec00000, src=0x146af3000000, size=131072
[uc2n517:1396389] *** Process received signal ***
[uc2n517:1396389] Signal: Aborted (6)
[uc2n517:1396389] Signal code:  (-6)
[uc2n517:1396389] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x146f6ff61dd0]
[uc2n517:1396389] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x146f6fbc470f]
[uc2n517:1396389] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x146f6fbaeb25]
[uc2n517:1396389] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c58f)[0x146f6eb2e58f]
[uc2n517:1396389] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x77119)[0x146f6eb29119]
[uc2n517:1396389] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_datatype_sndrcv+0x50a)[0x146f7b967b2a]
[uc2n517:1396389] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x26e)[0x146f7b9bc80e]
[uc2n517:1396389] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x146f7b9c8702]
[uc2n517:1396389] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x146f7b96a42b]
[uc2n517:1396389] [ 9] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_decomp.so(_ZN18MPIcuFFT_Slab_Opt1IdE12All2All_SyncEPvb+0x3e7)[0x146f860b7e17]
[uc2n517:1396389] [10] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_decomp.so(_ZN18MPIcuFFT_Slab_Opt1IdE7execC2REPvPKv+0x115)[0x146f860b7765]
[uc2n517:1396389] [11] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_tests.so(_ZN25Tests_Slab_Random_DefaultIdE9testcase2Eii+0x51f)[0x146f86304939]
[uc2n517:1396389] [12] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_tests.so(_ZN25Tests_Slab_Random_DefaultIdE3runEiii+0x67)[0x146f86303cb5]
[uc2n517:1396389] [13] slab[0x40332f]
[uc2n517:1396389] [14] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x146f6fbb06a3]
[uc2n517:1396389] [15] slab[0x4039fe]
[uc2n517:1396389] *** End of error message ***
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 15 with PID 1396389 on node uc2n517 exited on signal 6 (Aborted).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1545822] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1545822] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n517:1396677:0:1396677] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14d2d4200000)
[uc2n517:1396678:0:1396678] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1498e6240000)
[uc2n517:1396682:0:1396682] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14d396340000)
[uc2n517:1396681:0:1396681] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x15394e300000)
[uc2n517:1396683:0:1396683] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14f400380000)
[uc2n517:1396679:0:1396679] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x147390280000)
[uc2n517:1396684:0:1396684] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1536d43c0000)
[uc2n517:1396680:0:1396680] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x154c7c2c0000)
==== backtrace (tid:1396677) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000001f4df MPIcuFFT_Slab_Opt1<double>::All2All_MPIType()  ???:0
 8 0x000000000001e765 MPIcuFFT_Slab_Opt1<double>::execC2R()  ???:0
 9 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
10 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1396678) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000001f4df MPIcuFFT_Slab_Opt1<double>::All2All_MPIType()  ???:0
 8 0x000000000001e765 MPIcuFFT_Slab_Opt1<double>::execC2R()  ???:0
 9 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
10 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1396682) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000001f4df MPIcuFFT_Slab_Opt1<double>::All2All_MPIType()  ???:0
 8 0x000000000001e765 MPIcuFFT_Slab_Opt1<double>::execC2R()  ???:0
 9 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
10 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1396681) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000001f4df MPIcuFFT_Slab_Opt1<double>::All2All_MPIType()  ???:0
 8 0x000000000001e765 MPIcuFFT_Slab_Opt1<double>::execC2R()  ???:0
 9 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
10 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1396683) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000001f4df MPIcuFFT_Slab_Opt1<double>::All2All_MPIType()  ???:0
 8 0x000000000001e765 MPIcuFFT_Slab_Opt1<double>::execC2R()  ???:0
 9 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
10 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1396679) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000001f4df MPIcuFFT_Slab_Opt1<double>::All2All_MPIType()  ???:0
 8 0x000000000001e765 MPIcuFFT_Slab_Opt1<double>::execC2R()  ???:0
 9 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
10 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1396680) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000001f4df MPIcuFFT_Slab_Opt1<double>::All2All_MPIType()  ???:0
 8 0x000000000001e765 MPIcuFFT_Slab_Opt1<double>::execC2R()  ???:0
 9 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
10 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1396684) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000001f4df MPIcuFFT_Slab_Opt1<double>::All2All_MPIType()  ???:0
 8 0x000000000001e765 MPIcuFFT_Slab_Opt1<double>::execC2R()  ???:0
 9 0x0000000000017939 Tests_Slab_Random_Default<double>::testcase2()  ???:0
10 0x0000000000016cb5 Tests_Slab_Random_Default<double>::run()  ???:0
11 0x000000000040332f main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 13 with PID 1396682 on node uc2n517 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1545860] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1545860] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
The call to cuMemcpyAsync failed. This is a unrecoverable error and will
cause the program to abort.
  cuMemcpyAsync(0x1476b6800000, 0x9358340, 65536) returned value 1
Check the cuda.h file for what the return value means.
--------------------------------------------------------------------------
[uc2n517.localdomain:1397046] CUDA: Error in cuMemcpy: res=-1, dest=0x1476b6800000, src=0x9358340, size=65536
[uc2n517:1397046] *** Process received signal ***
[uc2n517:1397046] Signal: Aborted (6)
[uc2n517:1397046] Signal code:  (-6)
[uc2n517:1397046] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x1479280fadd0]
[uc2n517:1397046] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x147927d5d70f]
[uc2n517:1397046] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x147927d47b25]
[uc2n517:1397046] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x147926cc7375]
[uc2n517:1397046] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_unpack+0xb9)[0x147926cbe399]
[uc2n517:1397046] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_datatype_sndrcv+0x1f7)[0x147933b00817]
[uc2n517:1397046] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_coll_basic_alltoallw_intra+0xa4)[0x147933b94984]
[uc2n517:1397046] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallw+0x1eb)[0x147933b03ccb]
[uc2n517:1397046] [ 8] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_decomp.so(_ZN18MPIcuFFT_Slab_Opt1IdE15All2All_MPITypeEPvb+0x35f)[0x14793e2514df]
[uc2n517:1397046] [ 9] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_decomp.so(_ZN18MPIcuFFT_Slab_Opt1IdE7execC2REPvPKv+0x115)[0x14793e250765]
[uc2n517:1397046] [10] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_tests.so(_ZN25Tests_Slab_Random_DefaultIdE9testcase2Eii+0x51f)[0x14793e49d939]
[uc2n517:1397046] [11] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_tests.so(_ZN25Tests_Slab_Random_DefaultIdE3runEiii+0x67)[0x14793e49ccb5]
[uc2n517:1397046] [12] slab[0x40332f]
[uc2n517:1397046] [13] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x147927d496a3]
[uc2n517:1397046] [14] slab[0x4039fe]
[uc2n517:1397046] *** End of error message ***
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 15 with PID 1397046 on node uc2n517 exited on signal 6 (Aborted).
--------------------------------------------------------------------------
Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 09:12:49.730433
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 09:12:58.565411
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 09:13:07.989217
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 09:13:16.606743
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 09:13:26.063853
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 09:13:34.560555
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 09:13:44.874965
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 09:13:53.503196
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 09:14:02.967773
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 09:14:11.601030
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 09:14:22.135156
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 09:14:30.755040
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 09:14:39.982513
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 09:14:48.581828
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 09:14:57.822421
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 09:15:06.387755
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 09:15:17.691915
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 09:15:26.578312
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 09:15:36.080722
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 09:15:45.151305
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 09:15:57.286562
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 09:16:06.045570
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 09:16:15.944625
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 09:16:25.087798
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 09:16:34.524605
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 09:16:43.654888
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 09:16:57.279915
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 09:17:06.186159
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 09:17:15.976315
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 09:17:25.042938
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 09:17:39.527631
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 09:17:48.666587
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 09:17:58.624766
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 09:18:08.071264
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 09:18:18.201807
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 09:18:27.763295
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 09:18:41.929976
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 09:18:51.434830
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 09:19:01.697283
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 09:19:11.337584
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 09:19:25.941404
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 09:19:36.113606
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 09:19:47.078142
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 09:19:56.506244
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 09:20:07.477821
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 09:20:17.510432
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 09:20:35.536078
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 09:20:45.341132
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 09:20:55.750194
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 09:21:06.214513
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 09:21:25.286364
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 09:21:34.985138
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 09:21:45.299099
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 09:21:54.926791
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 09:22:04.969490
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 09:22:14.900858
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 09:22:40.151988
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 09:22:50.213585
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 09:23:00.188313
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 09:23:10.218579
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 09:23:37.647396
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 09:23:48.188137
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 09:23:58.694797
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 09:24:08.930028
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 09:24:19.419939
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 09:24:30.298045
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 09:24:56.118180
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 09:25:06.633000
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 09:25:17.314085
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 09:25:28.316548
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 09:25:56.165667
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 09:26:08.327277
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 09:26:19.866426
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 09:26:31.664032
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 09:26:43.244703
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 09:26:56.170188
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 09:27:38.018503
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 09:27:50.216470
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 09:28:01.720668
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 09:28:15.029900
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:29:00.537124
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:29:15.869349
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:29:28.672495
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:29:43.539217
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:29:56.810104
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:30:13.653328
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:31:27.585263
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:31:43.223125
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:31:56.234903
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:32:14.282332
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:33:35.888366
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:33:57.902705
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:34:14.553240
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:34:36.245405
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:34:54.476110
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:35:19.521408
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:36:36.247074
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:36:58.982637
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:37:16.417760
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 09:37:43.265112
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 09:39:09.016272
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 09:39:43.556530
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 09:40:09.426171
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 09:40:43.802428
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 09:41:10.263268
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 09:41:50.476171
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 09:44:14.273214
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 09:44:49.647811
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 09:45:14.209197
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 09:45:58.040804
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 09:48:38.704938
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 09:49:39.039174
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 09:50:23.089231
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 09:51:22.028506
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 09:52:03.722246
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 09:53:14.735713
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 09:57:51.503435
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 09:58:54.240967
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 09:59:33.621265
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 10:00:53.426441
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 10:06:05.449726
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 10:07:56.716308
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 10:09:02.963254
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 10:10:50.839051
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 10:12:04.138967
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 10:14:14.440840
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 10:19:12.268482
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 10:19:28.599374
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 10:19:44.586491
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 10:20:04.300628
b''

Slab 1D->2D default/opt1 (inverse)
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1545899] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1545899] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1545898] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1545898] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1546175] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1546175] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1546183] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1546183] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1546469] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1546469] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1546482] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1546482] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1547001] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1547001] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1547095] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1547095] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1547281] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1547281] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1547376] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1547376] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1547566] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1547566] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1547685] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1547685] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1547852] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1547852] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1547870] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1547870] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1548146] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1548146] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1548126] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1548126] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1548438] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1548438] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1548430] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1548430] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1548712] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1548712] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1548720] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1548720] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1548989] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1548989] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1549007] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1549007] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1549279] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1549279] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1549299] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1549299] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1549560] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1549560] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1549578] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1549578] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1550088] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1550088] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1550130] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1550130] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1550105] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1550105] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1550401] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1550401] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1550419] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1550419] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1550687] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1550687] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1550782] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1550782] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1550975] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1550975] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1550993] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1550993] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1551259] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1551259] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1551356] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1551356] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1551543] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1551543] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1551551] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1551551] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1551839] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1551839] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1551852] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1551852] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1552116] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1552116] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1552135] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1552135] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1552398] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1552398] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1552416] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1552416] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1552696] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1552696] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1552714] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1552714] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1553228] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1553228] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1553325] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1553325] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1553511] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1553511] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1553633] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1553633] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1553801] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1553801] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1553898] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1553898] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1554088] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1554088] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1554339] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1554339] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1554365] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1554365] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1554638] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1554638] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1554656] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1554656] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1554918] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1554918] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1554936] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1554936] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1555200] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1555200] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1555236] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1555236] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1555349] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1555349] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1555520] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1555520] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1555771] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1555771] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1555798] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1555798] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1556052] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1556052] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1556327] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1556327] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1556591] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1556591] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1556619] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1556619] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1556873] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1556873] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1556899] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1556899] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1557165] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1557165] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1557182] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1557182] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1557214] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1557214] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1557375] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1557375] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1557494] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1557494] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1557747] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1557747] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1557777] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1557777] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1558027] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1558027] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1558070] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1558070] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1558323] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1558323] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1558347] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1558347] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1558384] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1558384] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1558366] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1558366] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1558664] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1558664] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1558759] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1558759] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1558945] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1558945] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1559040] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1559040] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1559471] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1559471] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1559481] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1559481] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1559781] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1559781] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1559763] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1559763] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1560046] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1560046] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1560141] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1560141] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1560323] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1560323] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1560376] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1560376] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1560356] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1560356] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1560640] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1560640] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1560644] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1560644] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1560921] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1560921] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1561028] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1561028] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1561211] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1561211] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1561307] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1561307] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1561487] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1561487] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1561523] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1561523] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1561774] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1561774] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1561803] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1561803] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1562086] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1562086] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1561813] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1561813] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1562614] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1562614] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1562627] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1562627] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1562897] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1562897] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1562905] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1562905] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1563177] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1563177] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1563185] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1563185] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1563465] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1563465] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1563485] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1563485] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1563504] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1563504] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1563523] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1563523] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1563794] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1563794] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1563812] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1563812] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1564076] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1564076] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1564094] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1564094] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1564362] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1564362] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1564457] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1564457] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1564654] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1564654] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1564673] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1564673] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1564693] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1564693] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1564723] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1564723] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1564985] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1564985] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1565004] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1565004] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1565266] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1565266] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1565286] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1565286] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1565812] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1565812] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1565816] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1565816] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1566093] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1566093] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1566206] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1566206] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1566372] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1566372] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1566469] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1566469] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1566663] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1566663] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1566682] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1566682] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1566702] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1566702] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1566735] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1566735] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1566766] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1566766] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1566758] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1566758] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1567047] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1567047] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1567218] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1567218] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1567329] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1567329] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1567579] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1567579] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1567610] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1567610] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1567887] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1567887] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1567906] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1567906] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1567925] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1567925] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1567957] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1567957] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1567979] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1567979] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1568244] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1568244] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1568274] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1568274] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1568535] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1568535] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1568553] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1568553] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1569064] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1569064] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1569098] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1569098] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1569369] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1569369] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1569377] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1569377] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1569653] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1569653] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1569821] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1569821] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1569946] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1569946] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1569978] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1569978] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1569999] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1569999] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1570040] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1570040] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1570292] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1570292] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1570319] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1570319] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1570583] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1570583] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1570611] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1570611] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1570881] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1570881] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1571143] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1571143] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n517
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1571174] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1571174] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1571198] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1571198] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1571233] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1571233] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1571252] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1571252] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1571531] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1571531] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1571549] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1571549] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1571818] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1571818] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1571932] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1571932] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1572359] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1572359] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1572625] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1572625] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1572889] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1572889] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1572925] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1572925] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1573192] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1573192] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1573232] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1573232] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1573268] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1573268] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1573313] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1573313] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1573337] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1573337] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1573611] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1573611] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1573876] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1573876] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1573896] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1573896] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1574176] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1574176] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1574440] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1574440] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1574482] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1574482] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1574531] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1574531] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1574572] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1574572] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1574596] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1574596] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1574881] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1574881] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1575151] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1575151] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1575411] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1575411] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1575693] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1575693] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1575977] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1575977] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1576230] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1576230] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1576264] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1576264] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1576564] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1576564] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1576609] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1576609] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1576669] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1576669] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1576712] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1576712] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1576775] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1576775] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1577035] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1577035] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1577076] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1577076] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1577347] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1577347] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1577357] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1577357] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1577651] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1577651] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1577951] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1577951] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1577993] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1577993] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1578089] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1578089] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1578151] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1578151] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1578429] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1578429] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1578452] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1578452] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1578740] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1578740] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1579285] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1579285] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1579569] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1579569] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1579600] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1579600] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1579898] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1579898] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1580174] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1580174] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1580313] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1580313] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1580382] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1580382] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n517:1439635:0:1439635] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1463b8000000)
[uc2n517:1439632:0:1439632] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14abec000000)
[uc2n517:1439638:0:1439638] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e2b4000000)
[uc2n517:1439639:0:1439639] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x148306000000)
[uc2n517:1439634:0:1439634] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x145890000000)
[uc2n517:1439633:0:1439633] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14612c000000)
[uc2n517:1439637:0:1439637] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x152c4c000000)
[uc2n517:1439636:0:1439636] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1527b0000000)
[uc2n514:1219119:0:1219119] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14dda8000000)
[uc2n514:1219120:0:1219120] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14cf5e000000)
[uc2n514:1219122:0:1219122] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x149ecc000000)
[uc2n514:1219125:0:1219125] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x146a3c000000)
[uc2n514:1219126:0:1219126] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14cd4c000000)
[uc2n514:1219121:0:1219121] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1519a4000000)
[uc2n514:1219124:0:1219124] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14d618000000)
[uc2n514:1219123:0:1219123] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x147210000000)
==== backtrace (tid:1219119) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x0000000000038e4a MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
11 0x0000000000038732 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execC2R()  ???:0
12 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
13 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x00000000004035a1 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1219120) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x0000000000038e4a MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
11 0x0000000000038732 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execC2R()  ???:0
12 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
13 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x00000000004035a1 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1219122) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x0000000000038e4a MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
11 0x0000000000038732 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execC2R()  ???:0
12 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
13 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x00000000004035a1 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1219125) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x0000000000038e4a MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
11 0x0000000000038732 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execC2R()  ???:0
12 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
13 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x00000000004035a1 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1219126) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x0000000000038e4a MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
11 0x0000000000038732 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execC2R()  ???:0
12 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
13 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x00000000004035a1 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1219121) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x0000000000038e4a MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
11 0x0000000000038732 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execC2R()  ???:0
12 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
13 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x00000000004035a1 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1219124) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x0000000000038e4a MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
11 0x0000000000038732 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execC2R()  ???:0
12 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
13 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x00000000004035a1 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1219123) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x0000000000038e4a MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
11 0x0000000000038732 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execC2R()  ???:0
12 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
13 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x00000000004035a1 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1439638) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x0000000000038e4a MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
 9 0x0000000000038732 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execC2R()  ???:0
10 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
11 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1439636) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x0000000000038e4a MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
 9 0x0000000000038732 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execC2R()  ???:0
10 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
11 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
==== backtrace (tid:1439633) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
==== backtrace (tid:1439632) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x0000000000038e4a MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
 9 0x0000000000038732 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execC2R()  ???:0
10 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
11 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x0000000000038e4a MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
 9 0x0000000000038732 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execC2R()  ???:0
10 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
11 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1439635) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x0000000000038e4a MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
 9 0x0000000000038732 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execC2R()  ???:0
10 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
11 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1439634) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x0000000000038e4a MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
 9 0x0000000000038732 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execC2R()  ???:0
10 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
11 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1439639) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x0000000000038e4a MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
 9 0x0000000000038732 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execC2R()  ???:0
10 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
11 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1439637) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x0000000000038e4a MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
 9 0x0000000000038732 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execC2R()  ???:0
10 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
11 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 0 with PID 1219119 on node uc2n514 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1580413] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1580413] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
The call to cuMemcpyAsync failed. This is a unrecoverable error and will
cause the program to abort.
  cuMemcpyAsync(0x146a2ec00000, 0x146822c00000, 131072) returned value 1
Check the cuda.h file for what the return value means.
--------------------------------------------------------------------------
[uc2n517.localdomain:1439982] CUDA: Error in cuMemcpy: res=-1, dest=0x146a2ec00000, src=0x146822c00000, size=131072
[uc2n517:1439982] *** Process received signal ***
[uc2n517:1439982] Signal: Aborted (6)
[uc2n517:1439982] Signal code:  (-6)
[uc2n517:1439982] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x146ca1940dd0]
[uc2n517:1439982] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x146ca15a370f]
[uc2n517:1439982] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x146ca158db25]
[uc2n517:1439982] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c58f)[0x146ca050d58f]
[uc2n517:1439982] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x77119)[0x146ca0508119]
[uc2n517:1439982] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_datatype_sndrcv+0x50a)[0x146cad346b2a]
[uc2n517:1439982] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x26e)[0x146cad39b80e]
[uc2n517:1439982] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x146cad3a7702]
[uc2n517:1439982] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x146cad34942b]
[uc2n517:1439982] [ 9] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_decomp.so(_ZN28MPIcuFFT_Slab_Z_Then_YX_Opt1IdE12All2All_SyncEPvb+0x3fa)[0x146cb7ab0e4a]
[uc2n517:1439982] [10] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_decomp.so(_ZN28MPIcuFFT_Slab_Z_Then_YX_Opt1IdE7execC2REPvPKv+0xe2)[0x146cb7ab0732]
[uc2n517:1439982] [11] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_tests.so(_ZN27Tests_Slab_Random_Z_Then_YXIdE9testcase2Eii+0x499)[0x146cb7cf5775]
[uc2n517:1439982] [12] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_tests.so(_ZN27Tests_Slab_Random_Z_Then_YXIdE3runEiii+0x67)[0x146cb7cf4c01]
[uc2n517:1439982] [13] slab[0x4035a1]
[uc2n517:1439982] [14] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x146ca158f6a3]
[uc2n517:1439982] [15] slab[0x4039fe]
[uc2n517:1439982] *** End of error message ***
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 15 with PID 1439982 on node uc2n517 exited on signal 6 (Aborted).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1580456] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1580456] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510.localdomain:1580445] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1580445] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1580758] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1580758] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1581045] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1581045] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1581355] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1581355] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1581618] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1581618] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
The call to cuMemcpyAsync failed. This is a unrecoverable error and will
cause the program to abort.
  cuMemcpyAsync(0x14f2d0800000, 0x829cf40, 65536) returned value 1
Check the cuda.h file for what the return value means.
--------------------------------------------------------------------------
[uc2n517.localdomain:1440643] CUDA: Error in cuMemcpy: res=-1, dest=0x14f2d0800000, src=0x829cf40, size=65536
[uc2n517:1440643] *** Process received signal ***
[uc2n517:1440643] Signal: Aborted (6)
[uc2n517:1440643] Signal code:  (-6)
[uc2n517:1440643] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x14f543613dd0]
[uc2n517:1440643] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x14f54327670f]
[uc2n517:1440643] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x14f543260b25]
[uc2n517:1440643] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x14f5421e0375]
[uc2n517:1440643] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_unpack+0xb9)[0x14f5421d7399]
[uc2n517:1440643] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_datatype_sndrcv+0x1f7)[0x14f54f019817]
[uc2n517:1440643] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_coll_basic_alltoallw_intra+0xa4)[0x14f54f0ad984]
[uc2n517:1440643] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallw+0x1eb)[0x14f54f01cccb]
[uc2n517:1440643] [ 8] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_decomp.so(_ZN28MPIcuFFT_Slab_Z_Then_YX_Opt1IdE15All2All_MPITypeEPvb+0x36f)[0x14f55978454f]
[uc2n517:1440643] [ 9] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_decomp.so(_ZN28MPIcuFFT_Slab_Z_Then_YX_Opt1IdE7execC2REPvPKv+0xe2)[0x14f559783732]
[uc2n517:1440643] [10] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_tests.so(_ZN27Tests_Slab_Random_Z_Then_YXIdE9testcase2Eii+0x499)[0x14f5599c8775]
[uc2n517:1440643] [11] /home/st/st_us-051200/st_st160727/DistributedFFT/build_gpu8/libslab_tests.so(_ZN27Tests_Slab_Random_Z_Then_YXIdE3runEiii+0x67)[0x14f5599c7c01]
[uc2n517:1440643] [12] slab[0x4035a1]
[uc2n517:1440643] [13] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x14f5432626a3]
[uc2n517:1440643] [14] slab[0x4039fe]
[uc2n517:1440643] *** End of error message ***
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 15 with PID 1440643 on node uc2n517 exited on signal 6 (Aborted).
--------------------------------------------------------------------------
Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 10:20:30.064092
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 10:20:39.833459
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 10:20:55.814807
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 10:21:04.677290
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 10:21:14.495062
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 10:21:23.635217
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 10:21:33.736167
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 10:21:42.764968
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 10:21:56.578159
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 10:22:06.095940
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 10:22:16.090473
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 10:22:25.070885
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 10:22:34.680604
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 10:22:45.006583
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 10:22:54.858099
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 10:23:08.975682
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 10:23:18.733772
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 10:23:28.887982
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 10:23:39.925303
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 10:23:48.876020
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 10:23:59.050772
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 10:24:08.321577
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 10:24:18.632441
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 10:24:27.885454
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 10:24:38.299093
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 10:24:47.766679
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 10:24:57.641651
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 10:25:16.514078
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 10:25:27.532001
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 10:25:36.544952
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 10:25:46.136671
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 10:25:55.437809
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 10:26:05.399025
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 10:26:14.324076
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 10:26:23.699330
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 10:26:32.679432
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 10:26:41.998132
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 10:26:50.800813
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 10:27:00.200032
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 10:27:09.039301
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 10:27:18.654441
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 10:27:27.442474
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 10:27:36.887355
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 10:27:45.750646
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 10:27:55.217591
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 10:28:04.174864
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 10:28:13.563027
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 10:28:31.944236
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 10:28:41.377797
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 10:28:50.349386
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 10:29:00.627033
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 10:29:11.591458
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 10:29:21.985849
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 10:29:31.161783
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 10:29:41.054488
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 10:29:55.393323
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 10:30:05.080263
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 10:30:23.113105
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 10:30:32.800522
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 10:30:42.201142
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 10:30:52.514378
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 10:31:05.976021
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 10:31:15.922787
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 10:31:25.869390
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 10:31:35.774703
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 10:31:45.985308
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 10:31:56.047797
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 10:32:06.110779
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 10:32:20.116812
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 10:32:30.425682
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 10:32:40.530886
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 10:32:51.939502
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 10:33:03.148676
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 10:33:14.164747
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 10:33:24.523943
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 10:33:37.420286
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 10:33:47.768359
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 10:34:03.586448
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 10:34:14.714755
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 10:34:26.835141
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:34:38.035286
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:34:53.378178
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:35:05.336622
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:35:19.207499
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:35:38.676742
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:35:53.300854
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:36:06.930675
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:36:21.341667
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:36:33.476839
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:36:54.084419
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:37:06.505297
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:37:27.196839
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:37:42.676807
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:38:02.805000
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:38:20.477847
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:38:42.569368
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:38:57.913472
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:39:18.484142
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:39:34.473186
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:39:59.251199
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 10:40:15.734912
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 10:40:49.609911
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 10:41:12.689250
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 10:41:46.346311
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 10:42:10.680692
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 10:42:45.815855
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 10:43:16.998437
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 10:43:51.104491
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 10:44:14.649285
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 10:44:54.524773
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 10:45:24.505358
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 10:46:22.046804
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 10:46:58.788086
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 10:47:55.404076
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 10:48:32.296100
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 10:49:32.409746
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 10:50:09.040458
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 10:51:09.528889
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 10:51:46.091542
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 10:52:53.479352
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 10:53:32.842438
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 10:55:22.611192
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 10:56:26.343188
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 10:58:18.487082
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 10:59:23.496902
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 11:01:13.224759
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 11:02:21.258037
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 11:02:37.174353
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 11:02:55.227056
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 11:05:01.871202
b''

--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1581835] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1581835] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1582150] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1582150] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1582447] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1582447] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1583006] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1583006] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1583315] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1583315] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1583651] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1583651] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1584284] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1584284] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1584600] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1584600] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1584896] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1584896] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1585229] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1585229] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1585886] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1585886] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1586251] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1586251] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1586584] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1586584] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1587179] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1587179] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1587516] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1587516] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1587914] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1587914] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n511
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1588909] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1588909] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n511:1951999:0:1951999] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14a08c400000)
[uc2n511:1951994:0:1951994] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14ce10400000)
[uc2n511:1951997:0:1951997] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x150c34400000)
[uc2n511:1951998:0:1951998] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14b580400000)
[uc2n511:1951996:0:1951996] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14798c400000)
[uc2n511:1952001:0:1952001] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x148456400000)
[uc2n511:1952000:0:1952000] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14cd54400000)
[uc2n511:1951995:0:1951995] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x145e0c400000)
==== backtrace (tid:1951999) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000002cf0e MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
 9 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
10 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
11 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1951994) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000002cf0e MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
 9 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
10 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
11 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1951997) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000002cf0e MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
 9 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
10 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
11 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1951996) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000002cf0e MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
 9 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
10 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
11 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1951998) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000002cf0e MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
 9 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
10 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
11 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1952000) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000002cf0e MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
 9 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
10 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
11 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1952001) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000002cf0e MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
 9 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
10 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
11 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1951995) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x000000000002cf0e MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
 9 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
10 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
11 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x00000000004035a1 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 13 with PID 1951999 on node uc2n511 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510:1589200:0:1589200] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x151f9e000000)
==== backtrace (tid:1589200) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002cf0e MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
11 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
12 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
13 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x00000000004035a1 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
[uc2n510.localdomain:1589179] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1589179] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n510:1589207:0:1589207] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1454ce000000)
[uc2n510:1589205:0:1589205] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14ede2000000)
[uc2n510:1589206:0:1589206] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x153f4e000000)
[uc2n510:1589202:0:1589202] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1502b6000000)
[uc2n510:1589203:0:1589203] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e42e000000)
[uc2n510:1589204:0:1589204] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x144f6e000000)
[uc2n510:1589201:0:1589201] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x151a9e000000)
==== backtrace (tid:1589205) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002cf0e MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
11 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
12 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
13 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x00000000004035a1 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1589207) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002cf0e MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
11 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
12 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
13 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x00000000004035a1 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1589206) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002cf0e MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
11 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
12 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
13 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x00000000004035a1 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1589202) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002cf0e MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
11 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
12 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
13 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x00000000004035a1 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1589201) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002cf0e MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
11 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
12 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
13 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x00000000004035a1 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1589203) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002cf0e MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
11 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
12 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
13 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x00000000004035a1 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1589204) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002cf0e MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
11 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
12 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
13 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x00000000004035a1 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039fe _start()  ???:0
=================================
[uc2n511:1952370:0:1952370] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x154466000010)
[uc2n511:1952371:0:1952371] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1501de000010)
[uc2n511:1952372:0:1952372] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14d192000010)
[uc2n511:1952367:0:1952367] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14eef0000010)
[uc2n511:1952366:0:1952366] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14a92a000010)
[uc2n511:1952369:0:1952369] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14f026000010)
[uc2n511:1952368:0:1952368] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x150c9e000010)
[uc2n511:1952365:0:1952365] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x150be8000010)
==== backtrace (tid:1952370) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002cf0e MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
17 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
18 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
19 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
20 0x00000000004035a1 main()  ???:0
21 0x00000000000236a3 __libc_start_main()  ???:0
22 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1952371) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002cf0e MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
17 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
18 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
19 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
20 0x00000000004035a1 main()  ???:0
21 0x00000000000236a3 __libc_start_main()  ???:0
22 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1952372) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002cf0e MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
17 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
18 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
19 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
20 0x00000000004035a1 main()  ???:0
21 0x00000000000236a3 __libc_start_main()  ???:0
22 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1952367) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002cf0e MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
17 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
18 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
19 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
20 0x00000000004035a1 main()  ???:0
21 0x00000000000236a3 __libc_start_main()  ???:0
22 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1952365) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002cf0e MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
17 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
18 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
19 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
20 0x00000000004035a1 main()  ???:0
21 0x00000000000236a3 __libc_start_main()  ???:0
22 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1952366) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002cf0e MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
17 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
18 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
19 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
20 0x00000000004035a1 main()  ???:0
21 0x00000000000236a3 __libc_start_main()  ???:0
22 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1952369) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002cf0e MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
17 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
18 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
19 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
20 0x00000000004035a1 main()  ???:0
21 0x00000000000236a3 __libc_start_main()  ???:0
22 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1952368) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002cf0e MPIcuFFT_Slab_Z_Then_YX<double>::All2All_Sync()  ???:0
17 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
18 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
19 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
20 0x00000000004035a1 main()  ???:0
21 0x00000000000236a3 __libc_start_main()  ???:0
22 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 0 with PID 0 on node uc2n510 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1589518] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1589518] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n510
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n510.localdomain:1589927] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n510.localdomain:1589927] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n511:1953105:0:1953105] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x153412000000)
[uc2n511:1953109:0:1953109] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c3c8000000)
[uc2n511:1953112:0:1953112] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14d99e000000)
[uc2n511:1953110:0:1953110] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14b702000000)
[uc2n511:1953111:0:1953111] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x148688000000)
[uc2n511:1953108:0:1953108] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x15013e000000)
[uc2n511:1953106:0:1953106] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1519a2000000)
[uc2n511:1953107:0:1953107] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x150f08000000)
==== backtrace (tid:1953105) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d5ef MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
 9 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
10 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1953106) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d5ef MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
 9 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
10 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1953107) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d5ef MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
 9 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
10 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1953108) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d5ef MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
 9 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
10 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
==== backtrace (tid:1953111) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d5ef MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
 9 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
10 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
==== backtrace (tid:1953112) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d5ef MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
 9 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
10 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1953110) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d5ef MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
 9 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
10 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
=================================
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
==== backtrace (tid:1953109) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002d5ef MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
 8 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
 9 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
10 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x00000000004035a1 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[uc2n510:1589943:0:1589943] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x148c3c000000)
==== backtrace (tid:1589943) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002d5ef MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
10 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
11 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
12 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
13 0x00000000004035a1 main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
[uc2n510:1589944:0:1589944] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14cd56000000)
==== backtrace (tid:1589944) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002d5ef MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
10 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
11 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
12 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
13 0x00000000004035a1 main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
[uc2n510:1589945:0:1589945] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x152f96000000)
==== backtrace (tid:1589945) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002d5ef MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
10 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
11 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
12 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
13 0x00000000004035a1 main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
[uc2n510:1589946:0:1589946] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x146c96000000)
==== backtrace (tid:1589946) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002d5ef MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
10 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
11 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
12 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
13 0x00000000004035a1 main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
[uc2n510:1589947:0:1589947] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x148152000000)
==== backtrace (tid:1589947) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002d5ef MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
10 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
11 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
12 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
13 0x00000000004035a1 main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
[uc2n510:1589948:0:1589948] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x148320000000)
==== backtrace (tid:1589948) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002d5ef MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
10 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
11 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
12 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
13 0x00000000004035a1 main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
[uc2n510:1589949:0:1589949] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x154a6a000000)
==== backtrace (tid:1589949) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002d5ef MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
10 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
11 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
12 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
13 0x00000000004035a1 main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
[uc2n510:1589950:0:1589950] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1542e0000000)
==== backtrace (tid:1589950) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002d5ef MPIcuFFT_Slab_Z_Then_YX<double>::All2All_MPIType()  ???:0
10 0x000000000002bb71 MPIcuFFT_Slab_Z_Then_YX<double>::execC2R()  ???:0
11 0x0000000000029775 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
12 0x0000000000028c01 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
13 0x00000000004035a1 main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039fe _start()  ???:0
=================================
--------------------------------------------------------------------------
mpiexec noticed that process rank 8 with PID 1953105 on node uc2n511 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 10:20:30.064145
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 10:20:39.070980
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 10:20:55.345200
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 10:21:04.249263
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 10:21:13.441803
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 10:21:21.898952
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 10:21:34.494725
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 10:21:46.744591
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 10:21:56.186347
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-30 10:22:05.564650
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 10:22:19.094531
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 10:22:27.630519
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 10:22:37.033066
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 10:22:45.537610
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 10:23:09.502213
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 10:23:18.079327
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 10:23:30.621716
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 10:23:39.203592
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 10:23:48.602089
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-30 10:23:57.827814
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 10:24:11.527822
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 10:24:19.719452
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 10:24:28.622440
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 10:24:37.518665
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 10:24:46.333075
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 10:24:54.462364
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 10:25:12.818797
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 10:25:21.041388
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 10:25:29.802151
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-30 10:25:38.033951
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 10:25:54.163226
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 10:26:02.401699
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 10:26:11.203435
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 10:26:19.463753
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 10:26:28.306979
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 10:26:36.604020
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 10:26:58.251028
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 10:27:06.514817
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 10:27:15.250763
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-30 10:27:23.489796
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 10:27:46.221778
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 10:27:54.608936
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 10:28:03.566656
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 10:28:11.852080
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 10:28:32.087617
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 10:28:40.784827
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 10:29:03.046028
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 10:29:11.502068
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 10:29:21.317757
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-30 10:29:29.900885
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 10:29:52.736175
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 10:30:01.565772
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 10:30:14.258744
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 10:30:22.921633
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 10:30:32.107499
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 10:30:41.990446
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 10:31:18.201913
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 10:31:27.020124
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 10:31:36.366952
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-30 10:31:45.499160
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 10:32:22.397354
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 10:32:32.110765
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 10:32:42.257039
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 10:32:51.890286
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 10:33:01.851993
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 10:33:12.394801
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 10:34:14.343962
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 10:34:24.750861
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 10:34:34.390551
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-30 10:34:44.813457
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 10:35:48.991135
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 10:36:00.447437
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 10:36:11.346426
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 10:36:22.472458
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 10:36:33.287921
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 10:36:51.366960
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 10:37:54.652324
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 10:38:11.118757
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 10:38:21.922621
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-30 10:38:34.610124
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:39:40.051561
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:40:00.558889
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:40:13.520971
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:40:28.945678
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:40:41.584727
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:40:59.150463
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:42:53.241026
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:43:09.765268
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:43:22.150198
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:43:39.253319
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:45:38.187876
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:45:59.419074
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:46:15.883540
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:46:37.148442
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:46:54.857440
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:47:21.159261
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:51:03.239770
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:51:24.563793
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:51:43.172482
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-30 10:52:12.953318
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 10:56:02.065448
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 10:56:38.974425
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 10:57:04.915537
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 10:57:51.737045
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 10:58:26.731505
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 10:59:11.017748
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 11:02:57.471998
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 11:03:34.422884
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 11:04:00.426330
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-30 11:04:54.941314
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 11:08:53.901432
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 11:09:59.695418
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 11:10:46.865862
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 11:11:50.009382
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 11:12:40.172443
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 11:14:02.021351
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 11:21:25.210906
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 11:22:38.039336
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 11:23:21.607273
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-30 11:24:42.308704
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 11:32:31.758248
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 11:34:35.982147
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 11:35:55.746344
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 11:37:54.450879
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 11:39:19.500530
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 11:41:57.949649
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 11:56:46.597886
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 11:57:05.785686
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 11:57:24.700554
b''

-> Executing test 9
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 16 -b ../benchmarks/bwunicluster/gpu8/large/inverse -s Z_Then_YX -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-30 12:00:03.167313
b''


============================= JOB FEEDBACK =============================

NodeName=uc2n[510-511,514,517]
Job ID: 19960394
Cluster: uc2
User/Group: st_st160727/st_us-051200
State: COMPLETED (exit code 0)
Nodes: 4
Cores per node: 80
CPU Utilized: 12-09:30:48
CPU Efficiency: 6.32% of 196-01:30:40 core-walltime
Job Wall-clock time: 14:42:17
Memory Utilized: 198.64 GB
Memory Efficiency: 0.00% of 0.00 MB
