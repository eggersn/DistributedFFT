Modules loaded
uc2n508
uc2n508
uc2n508
uc2n508
uc2n508
uc2n508
uc2n508
uc2n508
uc2n508 uc2n508 uc2n508 uc2n508 uc2n508 uc2n508 uc2n508 uc2n508
start building
-- The CUDA compiler identification is NVIDIA 11.0.194
-- The CXX compiler identification is GNU 8.3.1
-- Detecting CUDA compiler ABI info
-- Detecting CUDA compiler ABI info - done
-- Check for working CUDA compiler: /opt/bwhpc/common/devel/cuda/11.0/bin/nvcc - skipped
-- Detecting CUDA compile features
-- Detecting CUDA compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /usr/bin/g++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Found MPI_CXX: /pfs/data5/software_uc2/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so (found version "3.1") 
-- Found MPI: TRUE (found version "3.1")  
-- Found CUDAToolkit: /opt/bwhpc/common/devel/cuda/11.0/include (found version "11.0.194") 
-- Looking for C++ include pthread.h
-- Looking for C++ include pthread.h - found
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed
-- Looking for pthread_create in pthreads
-- Looking for pthread_create in pthreads - not found
-- Looking for pthread_create in pthread
-- Looking for pthread_create in pthread - found
-- Found Threads: TRUE  
-- Configuring done
-- Generating done
-- Build files have been written to: /home/st/st_us-051200/st_st160727/DistributedFFT/build
Scanning dependencies of target test_base
[  3%] Building CUDA object CMakeFiles/test_base.dir/tests/src/base.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[  6%] Linking CUDA shared library libtest_base.so
[  6%] Built target test_base
Scanning dependencies of target mpicufft
[  9%] Building CXX object CMakeFiles/mpicufft.dir/src/mpicufft.cpp.o
[ 12%] Linking CXX shared library libmpicufft.so
[ 12%] Built target mpicufft
Scanning dependencies of target timer
[ 15%] Building CXX object CMakeFiles/timer.dir/src/timer.cpp.o
[ 18%] Linking CXX shared library libtimer.so
[ 18%] Built target timer
Scanning dependencies of target pencil_decomp
[ 21%] Building CXX object CMakeFiles/pencil_decomp.dir/src/pencil/mpicufft_pencil.cpp.o
[ 24%] Building CXX object CMakeFiles/pencil_decomp.dir/src/pencil/mpicufft_pencil_opt1.cpp.o
[ 27%] Linking CXX shared library libpencil_decomp.so
[ 27%] Built target pencil_decomp
Scanning dependencies of target pencil_tests
[ 30%] Building CUDA object CMakeFiles/pencil_tests.dir/tests/src/pencil/base.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 33%] Building CUDA object CMakeFiles/pencil_tests.dir/tests/src/pencil/random_dist_1D.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 36%] Building CUDA object CMakeFiles/pencil_tests.dir/tests/src/pencil/random_dist_2D.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 39%] Building CUDA object CMakeFiles/pencil_tests.dir/tests/src/pencil/random_dist_3D.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 42%] Linking CUDA shared library libpencil_tests.so
[ 42%] Built target pencil_tests
Scanning dependencies of target pencil
[ 45%] Building CXX object CMakeFiles/pencil.dir/tests/src/pencil/main.cpp.o
[ 48%] Linking CXX executable pencil
[ 48%] Built target pencil
Scanning dependencies of target slab_decomp
[ 51%] Building CXX object CMakeFiles/slab_decomp.dir/src/slab/default/mpicufft_slab.cpp.o
[ 54%] Building CXX object CMakeFiles/slab_decomp.dir/src/slab/default/mpicufft_slab_opt1.cpp.o
[ 57%] Building CXX object CMakeFiles/slab_decomp.dir/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp.o
[ 60%] Building CXX object CMakeFiles/slab_decomp.dir/src/slab/z_then_yx/mpicufft_slab_z_then_yx_opt1.cpp.o
[ 63%] Building CXX object CMakeFiles/slab_decomp.dir/src/slab/y_then_zx/mpicufft_slab_y_then_zx.cpp.o
[ 66%] Linking CXX shared library libslab_decomp.so
[ 66%] Built target slab_decomp
Scanning dependencies of target slab_tests
[ 69%] Building CUDA object CMakeFiles/slab_tests.dir/tests/src/slab/base.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 72%] Building CUDA object CMakeFiles/slab_tests.dir/tests/src/slab/random_dist_default.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 75%] Building CUDA object CMakeFiles/slab_tests.dir/tests/src/slab/random_dist_y_then_zx.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 78%] Building CUDA object CMakeFiles/slab_tests.dir/tests/src/slab/random_dist_z_then_yx.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 81%] Linking CUDA shared library libslab_tests.so
[ 81%] Built target slab_tests
Scanning dependencies of target slab
[ 84%] Building CXX object CMakeFiles/slab.dir/tests/src/slab/main.cpp.o
[ 87%] Linking CXX executable slab
[ 87%] Built target slab
Scanning dependencies of target reference_tests
[ 90%] Building CUDA object CMakeFiles/reference_tests.dir/tests/src/reference/reference.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 93%] Linking CUDA shared library libreference_tests.so
[ 93%] Built target reference_tests
Scanning dependencies of target reference
[ 96%] Building CXX object CMakeFiles/reference.dir/tests/src/reference/main.cpp.o
[100%] Linking CXX executable reference
[100%] Built target reference
finished building
start python script
Slab 1D->2D opt1
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1338341] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1338341] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1338598] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1338598] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1338858] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1338858] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1339366] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1339366] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1339635] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1339635] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1339894] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1339894] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1340154] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1340154] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1340409] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1340409] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1340669] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1340669] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1340941] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1340941] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1341196] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1341196] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1341456] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1341456] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1341756] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1341756] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1342271] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1342271] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1342533] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1342533] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1342794] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1342794] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1343052] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1343052] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1343309] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1343309] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1343577] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1343577] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1343837] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1343837] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1344092] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1344092] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1344350] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1344350] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1344628] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1344628] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1345131] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1345131] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1345393] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1345393] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1345651] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1345651] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1345919] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1345919] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1346176] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1346176] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1346438] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1346438] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1346693] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1346693] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1346952] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1346952] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1347220] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1347220] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1347482] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1347482] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1347987] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1347987] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1348245] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1348245] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1348519] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1348519] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1348774] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1348774] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1349036] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1349036] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1349296] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1349296] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1349566] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1349566] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1349824] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1349824] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1350084] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1350084] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1350342] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1350342] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1350860] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1350860] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1351119] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1351119] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1351381] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1351381] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1351639] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1351639] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1351911] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1351911] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1352170] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1352170] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1352430] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1352430] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1352688] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1352688] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1352956] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1352956] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1353214] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1353214] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1353725] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1353725] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1353983] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1353983] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1354255] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1354255] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1354510] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1354510] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1354770] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1354770] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1355029] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1355029] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1355301] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1355301] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1355562] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1355562] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1355820] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1355820] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1356090] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1356090] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1356596] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1356596] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1356856] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1356856] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1357126] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1357126] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1357384] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1357384] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1357645] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1357645] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1357904] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1357904] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1358178] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1358178] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1358438] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1358438] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1358711] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1358711] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1358973] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1358973] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1359479] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1359479] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1359749] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1359749] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1360010] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1360010] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1360290] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1360290] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1360546] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1360546] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1360804] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1360804] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1361076] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1361076] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1361336] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1361336] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1361611] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1361611] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1361875] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1361875] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1362401] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1362401] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1362659] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1362659] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1362934] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1362934] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1363209] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1363209] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1363472] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1363472] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1363748] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1363748] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1364010] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1364010] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1364282] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1364282] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1364564] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1364564] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1364843] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1364843] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1365368] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1365368] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1365634] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1365634] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1365931] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1365931] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1366196] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1366196] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1366491] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1366491] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1366754] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1366754] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1367040] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1367040] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1367315] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1367315] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1367625] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1367625] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1367928] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1367928] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1368483] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1368483] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1368767] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1368767] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1369077] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1369077] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1369361] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1369361] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1369671] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1369671] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1369953] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1369953] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1370272] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1370272] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1370562] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1370562] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1370918] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1370918] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1371239] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1371239] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1371840] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1371840] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1372153] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1372153] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1372509] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1372509] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1372814] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1372814] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n508:1372824:0:1372824] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x15228e400000)
[uc2n508:1372825:0:1372825] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x151396400000)
[uc2n508:1372827:0:1372827] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x152cc4400000)
[uc2n508:1372826:0:1372826] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1510a8400000)
==== backtrace (tid:1372825) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x0000000000038a18 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
 9 0x0000000000038242 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
10 0x0000000000029076 Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
11 0x0000000000028b61 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x0000000000403591 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039ee _start()  ???:0
==== backtrace (tid:1372827) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x0000000000038a18 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
 9 0x0000000000038242 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
10 0x0000000000029076 Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
11 0x0000000000028b61 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x0000000000403591 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039ee _start()  ???:0
=================================
=================================
==== backtrace (tid:1372826) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x0000000000038a18 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
 9 0x0000000000038242 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
10 0x0000000000029076 Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
11 0x0000000000028b61 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x0000000000403591 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039ee _start()  ???:0
=================================
==== backtrace (tid:1372824) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x0000000000038a18 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
 9 0x0000000000038242 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
10 0x0000000000029076 Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
11 0x0000000000028b61 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x0000000000403591 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039ee _start()  ???:0
=================================
[uc2n508:1372820:0:1372820] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14ab50400000)
[uc2n508:1372823:0:1372823] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14dfc0400000)
[uc2n508:1372822:0:1372822] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x150026400000)
[uc2n508:1372821:0:1372821] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c5cc400000)
==== backtrace (tid:1372820) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x0000000000038a18 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
11 0x0000000000038242 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
12 0x0000000000029076 Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
13 0x0000000000028b61 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x0000000000403591 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039ee _start()  ???:0
=================================
==== backtrace (tid:1372821) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x0000000000038a18 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
11 0x0000000000038242 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
12 0x0000000000029076 Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
13 0x0000000000028b61 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x0000000000403591 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039ee _start()  ???:0
=================================
==== backtrace (tid:1372823) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x0000000000038a18 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
11 0x0000000000038242 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
12 0x0000000000029076 Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
13 0x0000000000028b61 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x0000000000403591 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039ee _start()  ???:0
=================================
==== backtrace (tid:1372822) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x0000000000038a18 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
11 0x0000000000038242 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
12 0x0000000000029076 Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
13 0x0000000000028b61 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x0000000000403591 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039ee _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 6 with PID 1372826 on node uc2n508 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
The call to cuMemcpyAsync failed. This is a unrecoverable error and will
cause the program to abort.
  cuMemcpyAsync(0x1498dac00000, 0x149ae2c00000, 131072) returned value 1
Check the cuda.h file for what the return value means.
--------------------------------------------------------------------------
[uc2n508.localdomain:1373166] CUDA: Error in cuMemcpy: res=-1, dest=0x1498dac00000, src=0x149ae2c00000, size=131072
[uc2n508:1373166] *** Process received signal ***
[uc2n508:1373166] Signal: Aborted (6)
[uc2n508:1373166] Signal code:  (-6)
[uc2n508:1373166] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x149d527efdd0]
[uc2n508:1373166] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x149d5245270f]
[uc2n508:1373166] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x149d5243cb25]
[uc2n508:1373166] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c58f)[0x149d513bc58f]
[uc2n508:1373166] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x77119)[0x149d513b7119]
[uc2n508:1373166] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_datatype_sndrcv+0x50a)[0x149d5e1f5b2a]
[uc2n508:1373166] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x26e)[0x149d5e24a80e]
[uc2n508:1373166] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x149d5e256702]
[uc2n508:1373166] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x149d5e1f842b]
[uc2n508:1373166] [ 9] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libslab_decomp.so(_ZN28MPIcuFFT_Slab_Z_Then_YX_Opt1IdE12All2All_SyncEPvb+0xf8)[0x149d6895fa18]
[uc2n508:1373166] [10] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libslab_decomp.so(_ZN28MPIcuFFT_Slab_Z_Then_YX_Opt1IdE7execR2CEPvPKv+0x122)[0x149d6895f242]
[uc2n508:1373166] [11] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libslab_tests.so(_ZN27Tests_Slab_Random_Z_Then_YXIdE9testcase0Eii+0x49c)[0x149d68ba4076]
[uc2n508:1373166] [12] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libslab_tests.so(_ZN27Tests_Slab_Random_Z_Then_YXIdE3runEiii+0x2f)[0x149d68ba3b61]
[uc2n508:1373166] [13] slab[0x403591]
[uc2n508:1373166] [14] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x149d5243e6a3]
[uc2n508:1373166] [15] slab[0x4039ee]
[uc2n508:1373166] *** End of error message ***
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 7 with PID 1373166 on node uc2n508 exited on signal 6 (Aborted).
--------------------------------------------------------------------------
[uc2n508.localdomain:1373145] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1373145] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1373420] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1373420] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n508:1373432:0:1373432] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14ea4c400000)
[uc2n508:1373431:0:1373431] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c884400000)
[uc2n508:1373433:0:1373433] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x145248400000)
[uc2n508:1373430:0:1373430] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x153c18400000)
==== backtrace (tid:1373431) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000039203 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_MPIType()  ???:0
 8 0x0000000000038242 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
 9 0x0000000000029076 Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
10 0x0000000000028b61 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x0000000000403591 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039ee _start()  ???:0
=================================
==== backtrace (tid:1373430) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000039203 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_MPIType()  ???:0
 8 0x0000000000038242 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
 9 0x0000000000029076 Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
10 0x0000000000028b61 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x0000000000403591 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039ee _start()  ???:0
=================================
==== backtrace (tid:1373433) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000039203 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_MPIType()  ???:0
 8 0x0000000000038242 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
 9 0x0000000000029076 Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
10 0x0000000000028b61 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x0000000000403591 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039ee _start()  ???:0
=================================
==== backtrace (tid:1373432) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x0000000000039203 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_MPIType()  ???:0
 8 0x0000000000038242 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
 9 0x0000000000029076 Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
10 0x0000000000028b61 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
11 0x0000000000403591 main()  ???:0
12 0x00000000000236a3 __libc_start_main()  ???:0
13 0x00000000004039ee _start()  ???:0
=================================
[uc2n508:1373429:0:1373429] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e43c400000)
[uc2n508:1373427:0:1373427] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x15109c400000)
[uc2n508:1373428:0:1373428] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x151570400000)
[uc2n508:1373426:0:1373426] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14b592400000)
==== backtrace (tid:1373428) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x0000000000039203 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_MPIType()  ???:0
10 0x0000000000038242 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
11 0x0000000000029076 Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
12 0x0000000000028b61 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
13 0x0000000000403591 main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039ee _start()  ???:0
=================================
==== backtrace (tid:1373429) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x0000000000039203 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_MPIType()  ???:0
10 0x0000000000038242 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
11 0x0000000000029076 Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
12 0x0000000000028b61 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
13 0x0000000000403591 main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039ee _start()  ???:0
=================================
==== backtrace (tid:1373426) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x0000000000039203 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_MPIType()  ???:0
10 0x0000000000038242 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
11 0x0000000000029076 Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
12 0x0000000000028b61 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
13 0x0000000000403591 main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039ee _start()  ???:0
=================================
==== backtrace (tid:1373427) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x0000000000039203 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_MPIType()  ???:0
10 0x0000000000038242 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execR2C()  ???:0
11 0x0000000000029076 Tests_Slab_Random_Z_Then_YX<double>::testcase0()  ???:0
12 0x0000000000028b61 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
13 0x0000000000403591 main()  ???:0
14 0x00000000000236a3 __libc_start_main()  ???:0
15 0x00000000004039ee _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 4 with PID 1373430 on node uc2n508 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
The call to cuMemcpyAsync failed. This is a unrecoverable error and will
cause the program to abort.
  cuMemcpyAsync(0x870ae40, 0x14d560800000, 65536) returned value 1
Check the cuda.h file for what the return value means.
--------------------------------------------------------------------------
[uc2n508.localdomain:1373745] CUDA: Error in cuMemcpy: res=-1, dest=0x870ae40, src=0x14d560800000, size=65536
[uc2n508:1373745] *** Process received signal ***
[uc2n508:1373745] Signal: Aborted (6)
[uc2n508:1373745] Signal code:  (-6)
[uc2n508:1373745] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x14d7d2d51dd0]
[uc2n508:1373745] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x14d7d29b470f]
[uc2n508:1373745] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x14d7d299eb25]
[uc2n508:1373745] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x14d7d191e375]
[uc2n508:1373745] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x14d7d19151e8]
[uc2n508:1373745] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_datatype_sndrcv+0x1e3)[0x14d7de757803]
[uc2n508:1373745] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_coll_basic_alltoallw_intra+0xa4)[0x14d7de7eb984]
[uc2n508:1373745] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallw+0x1eb)[0x14d7de75accb]
[uc2n508:1373745] [ 8] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libslab_decomp.so(_ZN28MPIcuFFT_Slab_Z_Then_YX_Opt1IdE15All2All_MPITypeEPvb+0x153)[0x14d7e8ec2203]
[uc2n508:1373745] [ 9] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libslab_decomp.so(_ZN28MPIcuFFT_Slab_Z_Then_YX_Opt1IdE7execR2CEPvPKv+0x122)[0x14d7e8ec1242]
[uc2n508:1373745] [10] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libslab_tests.so(_ZN27Tests_Slab_Random_Z_Then_YXIdE9testcase0Eii+0x49c)[0x14d7e9106076]
[uc2n508:1373745] [11] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libslab_tests.so(_ZN27Tests_Slab_Random_Z_Then_YXIdE3runEiii+0x2f)[0x14d7e9105b61]
[uc2n508:1373745] [12] slab[0x403591]
[uc2n508:1373745] [13] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x14d7d29a06a3]
[uc2n508:1373745] [14] slab[0x4039ee]
[uc2n508:1373745] *** End of error message ***
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 7 with PID 1373745 on node uc2n508 exited on signal 6 (Aborted).
--------------------------------------------------------------------------
[uc2n508.localdomain:1373732] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1373732] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[54546,1],7]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n508.localdomain:1374000] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1374000] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[55816,1],6]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n508.localdomain:1374250] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1374250] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[56073,1],3]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n508.localdomain:1374507] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1374507] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[55311,1],6]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n508.localdomain:1374765] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1374765] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[55568,1],5]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n508.localdomain:1375026] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1375026] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[56849,1],7]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n508.localdomain:1375283] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1375283] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[57109,1],7]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n508.localdomain:1375543] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1375543] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[56350,1],7]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n508.localdomain:1375804] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1375804] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[56605,1],5]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n508.localdomain:1376063] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1376063] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[8817,1],3]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n508.localdomain:1376338] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1376338] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1376595] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1376595] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1376861] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1376861] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1377117] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1377117] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1377398] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1377398] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1377684] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1377684] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1377937] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1377937] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1378195] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1378195] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1378451] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1378451] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1378708] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1378708] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1378978] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1378978] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1379235] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1379235] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1379497] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1379497] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1379753] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1379753] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1380033] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1380033] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1380326] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1380326] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1380582] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1380582] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1380841] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1380841] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1381099] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1381099] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1381367] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1381367] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1381625] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1381625] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1381883] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1381883] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1382143] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1382143] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1382411] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1382411] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1382693] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1382693] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1382968] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1382968] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1383226] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1383226] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1383499] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1383499] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1383759] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1383759] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1384018] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1384018] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1384290] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1384290] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1384548] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1384548] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1384826] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1384826] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1385106] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1385106] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1385409] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1385409] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1385707] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1385707] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1385989] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1385989] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1386269] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1386269] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1386548] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1386548] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1386831] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1386831] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1387109] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1387109] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1387387] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1387387] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 5 with PID 1387398 on
node uc2n508 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1387650] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1387650] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 4 with PID 1387660 on
node uc2n508 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1387932] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1387932] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 5 with PID 1387943 on
node uc2n508 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1388212] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1388212] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 4 with PID 1388222 on
node uc2n508 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1388488] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1388488] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 6 with PID 1388500 on
node uc2n508 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1388771] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1388771] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 7 with PID 1388784 on
node uc2n508 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1389037] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1389037] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 6 with PID 1389049 on
node uc2n508 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1389317] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1389317] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 4 with PID 1389327 on
node uc2n508 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1389596] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1389596] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 3 with PID 1389605 on
node uc2n508 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1389878] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1389878] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 4 with PID 1389888 on
node uc2n508 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
Starting computation for size 128
-> Executing test 0
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128
2021-09-20 21:59:40.290495
b''

-> Executing test 1
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128
2021-09-20 21:59:46.928922
b''

-> Executing test 2
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128
2021-09-20 21:59:53.919749
b''

-> Executing test 3
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128
2021-09-20 22:00:00.496861
b''

-> Executing test 4
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128
2021-09-20 22:00:07.733120
b''

-> Executing test 5
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128
2021-09-20 22:00:14.265843
b''

-> Executing test 6
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128
2021-09-20 22:00:21.562603
b''

-> Executing test 7
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128
2021-09-20 22:00:27.996838
b''

-> Executing test 8
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128
2021-09-20 22:00:35.167240
b''

-> Executing test 9
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128
2021-09-20 22:00:41.682449
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256
2021-09-20 22:00:48.803222
b''

-> Executing test 1
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256
2021-09-20 22:00:55.507939
b''

-> Executing test 2
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256
2021-09-20 22:01:02.710600
b''

-> Executing test 3
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256
2021-09-20 22:01:09.249063
b''

-> Executing test 4
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256
2021-09-20 22:01:16.446634
b''

-> Executing test 5
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256
2021-09-20 22:01:22.991499
b''

-> Executing test 6
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256
2021-09-20 22:01:30.256451
b''

-> Executing test 7
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256
2021-09-20 22:01:36.638215
b''

-> Executing test 8
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256
2021-09-20 22:01:43.766282
b''

-> Executing test 9
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256
2021-09-20 22:01:50.214444
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256
2021-09-20 22:01:57.436791
b''

-> Executing test 1
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256
2021-09-20 22:02:03.918196
b''

-> Executing test 2
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256
2021-09-20 22:02:11.282120
b''

-> Executing test 3
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256
2021-09-20 22:02:17.900709
b''

-> Executing test 4
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256
2021-09-20 22:02:25.019046
b''

-> Executing test 5
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256
2021-09-20 22:02:31.684318
b''

-> Executing test 6
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256
2021-09-20 22:02:38.637579
b''

-> Executing test 7
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256
2021-09-20 22:02:45.235568
b''

-> Executing test 8
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256
2021-09-20 22:02:52.421161
b''

-> Executing test 9
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256
2021-09-20 22:02:58.983721
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256
2021-09-20 22:03:06.259781
b''

-> Executing test 1
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256
2021-09-20 22:03:12.931934
b''

-> Executing test 2
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256
2021-09-20 22:03:20.281697
b''

-> Executing test 3
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256
2021-09-20 22:03:27.105229
b''

-> Executing test 4
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256
2021-09-20 22:03:34.439002
b''

-> Executing test 5
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256
2021-09-20 22:03:41.254398
b''

-> Executing test 6
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256
2021-09-20 22:03:48.563249
b''

-> Executing test 7
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256
2021-09-20 22:03:55.375472
b''

-> Executing test 8
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256
2021-09-20 22:04:02.687446
b''

-> Executing test 9
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256
2021-09-20 22:04:09.562953
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512
2021-09-20 22:04:16.979469
b''

-> Executing test 1
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512
2021-09-20 22:04:24.301827
b''

-> Executing test 2
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512
2021-09-20 22:04:31.735261
b''

-> Executing test 3
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512
2021-09-20 22:04:38.808664
b''

-> Executing test 4
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512
2021-09-20 22:04:46.416494
b''

-> Executing test 5
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512
2021-09-20 22:04:53.815119
b''

-> Executing test 6
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512
2021-09-20 22:05:01.609769
b''

-> Executing test 7
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512
2021-09-20 22:05:08.826811
b''

-> Executing test 8
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512
2021-09-20 22:05:16.446004
b''

-> Executing test 9
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512
2021-09-20 22:05:23.886988
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512
2021-09-20 22:05:31.456204
b''

-> Executing test 1
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512
2021-09-20 22:05:39.694772
b''

-> Executing test 2
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512
2021-09-20 22:05:47.600767
b''

-> Executing test 3
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512
2021-09-20 22:05:55.308171
b''

-> Executing test 4
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512
2021-09-20 22:06:03.320954
b''

-> Executing test 5
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512
2021-09-20 22:06:11.471396
b''

-> Executing test 6
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512
2021-09-20 22:06:19.585902
b''

-> Executing test 7
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512
2021-09-20 22:06:27.872137
b''

-> Executing test 8
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512
2021-09-20 22:06:35.641376
b''

-> Executing test 9
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512
2021-09-20 22:06:43.714770
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512
2021-09-20 22:06:51.826491
b''

-> Executing test 1
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512
2021-09-20 22:07:01.651796
b''

-> Executing test 2
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512
2021-09-20 22:07:10.582365
b''

-> Executing test 3
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512
2021-09-20 22:07:19.961024
b''

-> Executing test 4
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512
2021-09-20 22:07:28.700456
b''

-> Executing test 5
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512
2021-09-20 22:07:38.901978
b''

-> Executing test 6
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512
2021-09-20 22:07:47.693206
b''

-> Executing test 7
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512
2021-09-20 22:07:57.892247
b''

-> Executing test 8
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512
2021-09-20 22:08:06.792571
b''

-> Executing test 9
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512
2021-09-20 22:08:16.873876
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-20 22:08:26.183811
b''

-> Executing test 1
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-20 22:08:40.261381
b''

-> Executing test 2
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-20 22:08:50.969539
b''

-> Executing test 3
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-20 22:09:03.746280
b''

-> Executing test 4
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-20 22:09:14.359983
b''

-> Executing test 5
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-20 22:09:29.211950
b''

-> Executing test 6
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-20 22:09:39.971681
b''

-> Executing test 7
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-20 22:09:53.686190
b''

-> Executing test 8
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-20 22:10:03.727718
b''

-> Executing test 9
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-20 22:10:17.126182
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-20 22:10:27.925111
b''

-> Executing test 1
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-20 22:10:48.941989
b''

-> Executing test 2
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-20 22:11:02.330300
b''

-> Executing test 3
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-20 22:11:21.278961
b''

-> Executing test 4
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-20 22:11:34.785468
b''

-> Executing test 5
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-20 22:11:55.871933
b''

-> Executing test 6
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-20 22:12:09.394241
b''

-> Executing test 7
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-20 22:12:30.050499
b''

-> Executing test 8
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-20 22:12:43.268773
b''

-> Executing test 9
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-20 22:13:04.016305
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-20 22:13:18.576266
b''

-> Executing test 1
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-20 22:13:55.205949
b''

-> Executing test 2
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-20 22:14:15.038856
b''

-> Executing test 3
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-20 22:14:45.989081
b''

-> Executing test 4
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-20 22:15:05.968313
b''

-> Executing test 5
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-20 22:15:43.207135
b''

-> Executing test 6
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-20 22:16:02.887074
b''

-> Executing test 7
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-20 22:16:38.364164
b''

-> Executing test 8
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-20 22:16:58.390461
b''

-> Executing test 9
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-20 22:17:34.345222
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-20 22:17:57.639483
b''

-> Executing test 1
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-20 22:19:05.571809
b''

-> Executing test 2
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-20 22:19:39.668693
b''

-> Executing test 3
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-20 22:20:38.230210
b''

-> Executing test 4
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-20 22:21:12.786123
b''

-> Executing test 5
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-20 22:22:18.141130
b''

-> Executing test 6
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-20 22:22:52.328057
b''

-> Executing test 7
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-20 22:23:57.994641
b''

-> Executing test 8
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-20 22:24:32.614821
b''

-> Executing test 9
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-20 22:25:39.808362
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-20 22:26:19.925786
b''

-> Executing test 1
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-20 22:28:24.383977
b''

-> Executing test 2
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-20 22:29:25.989969
b''

-> Executing test 3
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-20 22:31:14.718118
b''

-> Executing test 4
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-20 22:32:17.848936
b''

-> Executing test 5
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-20 22:34:25.458750
b''

-> Executing test 6
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-20 22:35:26.672967
b''

-> Executing test 7
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-20 22:35:38.219927
b''

-> Executing test 8
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-20 22:35:47.405458
b''

-> Executing test 9
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-20 22:35:58.643522
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-20 22:36:08.054509
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\n'

-> Executing test 1
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-20 22:36:11.696159
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\n'

-> Executing test 2
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-20 22:36:15.299166
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\n'

-> Executing test 3
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-20 22:36:18.735676
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\n'

-> Executing test 4
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-20 22:36:22.362110
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\n'

-> Executing test 5
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-20 22:36:25.990041
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\n'

-> Executing test 6
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-20 22:36:29.603434
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\n'

-> Executing test 7
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-20 22:36:33.284941
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\n'

-> Executing test 8
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-20 22:36:36.855770
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\n'

-> Executing test 9
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-20 22:36:40.565314
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\n'

Starting computation for size 128
-> Executing test 0
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-20 22:36:44.326440
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 1
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-20 22:36:52.062210
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 2
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-20 22:36:58.342441
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 3
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-20 22:37:04.278590
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 4
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-20 22:37:10.723390
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 5
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-20 22:37:16.549876
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 6
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-20 22:37:22.997601
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 7
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-20 22:37:28.968126
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 8
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-20 22:37:35.304917
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 9
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-20 22:37:41.221611
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

Starting computation for size 256
-> Executing test 0
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-20 22:37:47.495519
b'Result (avg): 5.19268e-09\nResult (max): 5.08699e-08\n'

-> Executing test 1
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-20 22:37:53.740722
b'Result (avg): 5.19268e-09\nResult (max): 5.08699e-08\n'

-> Executing test 2
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-20 22:38:00.155031
b'Result (avg): 5.19268e-09\nResult (max): 5.08699e-08\n'

-> Executing test 3
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-20 22:38:06.468946
b'Result (avg): 5.19268e-09\nResult (max): 5.08699e-08\n'

-> Executing test 4
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-20 22:38:12.905150
b'Result (avg): 5.19268e-09\nResult (max): 5.08699e-08\n'

-> Executing test 5
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-20 22:38:19.344550
b'Result (avg): 5.19268e-09\nResult (max): 5.08699e-08\n'

-> Executing test 6
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-20 22:38:25.832170
b'Result (avg): 5.19268e-09\nResult (max): 5.08699e-08\n'

-> Executing test 7
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-20 22:38:32.302360
b'Result (avg): 5.19268e-09\nResult (max): 5.08699e-08\n'

-> Executing test 8
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-20 22:38:38.814424
b'Result (avg): 5.19268e-09\nResult (max): 5.08699e-08\n'

-> Executing test 9
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-20 22:38:45.096625
b'Result (avg): 5.19268e-09\nResult (max): 5.08699e-08\n'

Starting computation for size 512
-> Executing test 0
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-20 22:38:51.482421
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 1
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-20 22:39:00.369956
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 2
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-20 22:39:09.218782
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 3
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-20 22:39:18.084507
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 4
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-20 22:39:27.084486
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 5
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-20 22:39:35.853282
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 6
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-20 22:39:44.615487
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 7
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-20 22:39:53.541552
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 8
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-20 22:40:02.501902
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 9
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-20 22:40:11.515878
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

Starting computation for size 1024
-> Executing test 0
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-20 22:40:20.311749
b'Result (avg): 7.69765e-07\nResult (max): 9.22816e-06\n'

-> Executing test 1
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-20 22:40:50.894044
b'Result (avg): 7.69765e-07\nResult (max): 9.22816e-06\n'

-> Executing test 2
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-20 22:41:19.575183
b'Result (avg): 7.69765e-07\nResult (max): 9.22816e-06\n'

-> Executing test 3
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-20 22:41:49.704580
b'Result (avg): 7.69765e-07\nResult (max): 9.22816e-06\n'

-> Executing test 4
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-20 22:42:18.602068
b'Result (avg): 7.69765e-07\nResult (max): 9.22816e-06\n'

-> Executing test 5
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-20 22:42:48.975716
b'Result (avg): 7.69765e-07\nResult (max): 9.22816e-06\n'

-> Executing test 6
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-20 22:43:17.619186
b'Result (avg): 7.69765e-07\nResult (max): 9.22816e-06\n'

-> Executing test 7
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-20 22:43:48.460869
b'Result (avg): 7.69765e-07\nResult (max): 9.22816e-06\n'

-> Executing test 8
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-20 22:44:17.085135
b'Result (avg): 7.69765e-07\nResult (max): 9.22816e-06\n'

-> Executing test 9
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-20 22:44:47.590213
b'Result (avg): 7.69765e-07\nResult (max): 9.22816e-06\n'

Starting computation for size 2048
-> Executing test 0
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-20 22:45:16.756111
b'Error at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\n'

-> Executing test 1
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-20 22:45:32.951959
b'Error at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\n'

-> Executing test 2
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-20 22:45:57.572520
b'Error at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\n'

-> Executing test 3
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-20 22:46:22.471085
b'Error at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\n'

-> Executing test 4
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-20 22:46:47.477218
b'Error at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\n'

-> Executing test 5
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-20 22:47:12.255974
b'Error at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\n'

-> Executing test 6
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-20 22:47:37.288609
b'Error at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\n'

-> Executing test 7
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-20 22:48:02.187944
b'Error at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\n'

-> Executing test 8
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-20 22:48:26.834691
b'Error at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\n'

-> Executing test 9
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 1 --iterations 0 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-20 22:48:51.845710
b'Error at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\nError at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/slab/random_dist_z_then_yx.cu:663\n'

--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1390156] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1390156] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1390421] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1390421] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1390676] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1390676] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1391196] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1391196] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1391700] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1391700] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1391962] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1391962] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1392221] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1392221] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1392476] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1392476] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1392752] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1392752] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1393005] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1393005] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1393267] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1393267] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1393525] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1393525] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1393782] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1393782] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1394300] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1394300] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1394803] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1394803] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1395065] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1395065] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1395323] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1395323] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1395578] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1395578] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1395848] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1395848] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1396105] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1396105] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1396364] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1396364] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1396622] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1396622] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1396879] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1396879] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1397401] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1397401] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1397904] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1397904] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1398166] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1398166] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1398424] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1398424] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1398679] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1398679] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1398953] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1398953] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1399210] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1399210] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1399470] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1399470] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1399728] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1399728] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1399985] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1399985] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1400501] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1400501] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1401007] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1401007] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1401266] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1401266] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1401526] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1401526] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1401783] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1401783] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1402056] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1402056] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1402313] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1402313] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1402572] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1402572] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1402830] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1402830] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1403097] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1403097] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1403603] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1403603] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1404109] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1404109] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1404368] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1404368] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1404626] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1404626] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1404900] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1404900] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1405158] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1405158] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1405420] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1405420] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1405678] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1405678] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1405936] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1405936] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1406210] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1406210] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1406718] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1406718] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1407225] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1407225] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1407486] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1407486] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1407758] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1407758] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1408013] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1408013] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1408275] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1408275] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1408533] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1408533] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1408800] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1408800] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1409060] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1409060] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1409320] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1409320] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1409826] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1409826] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1410347] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1410347] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1410607] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1410607] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1410868] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1410868] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1411128] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1411128] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1411398] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1411398] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1411655] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1411655] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1411915] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1411915] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1412175] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1412175] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1412444] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1412444] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1412954] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1412954] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1413462] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1413462] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1413736] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1413736] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1413998] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1413998] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1414270] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1414270] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1414531] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1414531] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1414793] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1414793] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1415063] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1415063] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1415324] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1415324] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1415594] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1415594] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1416113] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1416113] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1416620] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1416620] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1416896] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1416896] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1417252] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1417252] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1417531] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1417531] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1417792] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1417792] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1418071] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1418071] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1418385] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1418385] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1418666] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1418666] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1418928] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1418928] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1419464] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1419464] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1419987] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1419987] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1420266] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1420266] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1420531] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1420531] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1420816] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1420816] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1421091] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1421091] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1421372] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1421372] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1421651] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1421651] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1421955] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1421955] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1422239] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1422239] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1422773] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1422773] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1423301] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1423301] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1423607] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1423607] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1423888] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1423888] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1424197] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1424197] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1424478] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1424478] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1424786] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1424786] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1425072] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1425072] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1425425] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1425425] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1425725] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1425725] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1426310] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1426310] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1426866] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1426866] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1427205] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1427205] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1427510] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1427510] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n508:1427522:0:1427522] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14f1e8000000)
[uc2n508:1427523:0:1427523] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x15358e000000)
[uc2n508:1427520:0:1427520] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14b810000000)
[uc2n508:1427521:0:1427521] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14bb7c000000)
==== backtrace (tid:1427523) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x0000000000038d1a MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
 9 0x0000000000038655 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execC2R()  ???:0
10 0x0000000000029707 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
11 0x0000000000028b99 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x0000000000403591 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039ee _start()  ???:0
=================================
==== backtrace (tid:1427520) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x0000000000038d1a MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
 9 0x0000000000038655 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execC2R()  ???:0
10 0x0000000000029707 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
11 0x0000000000028b99 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x0000000000403591 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039ee _start()  ???:0
=================================
==== backtrace (tid:1427522) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x0000000000038d1a MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
 9 0x0000000000038655 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execC2R()  ???:0
10 0x0000000000029707 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
11 0x0000000000028b99 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x0000000000403591 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039ee _start()  ???:0
=================================
==== backtrace (tid:1427521) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000076438 non_overlap_copy_content_same_ddt()  opal_datatype_copy.c:0
 4 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
 5 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 6 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 7 0x000000000009042b PMPI_Alltoallv()  ???:0
 8 0x0000000000038d1a MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
 9 0x0000000000038655 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execC2R()  ???:0
10 0x0000000000029707 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
11 0x0000000000028b99 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
12 0x0000000000403591 main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004039ee _start()  ???:0
=================================
[uc2n508:1427518:0:1427518] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e59e000000)
[uc2n508:1427516:0:1427516] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x15309b000000)
[uc2n508:1427519:0:1427519] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14ea0c000000)
[uc2n508:1427517:0:1427517] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14f01c000000)
==== backtrace (tid:1427518) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x0000000000038d1a MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
11 0x0000000000038655 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execC2R()  ???:0
12 0x0000000000029707 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
13 0x0000000000028b99 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x0000000000403591 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039ee _start()  ???:0
=================================
==== backtrace (tid:1427516) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x0000000000038d1a MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
11 0x0000000000038655 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execC2R()  ???:0
12 0x0000000000029707 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
13 0x0000000000028b99 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x0000000000403591 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039ee _start()  ???:0
=================================
==== backtrace (tid:1427519) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x0000000000038d1a MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
11 0x0000000000038655 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execC2R()  ???:0
12 0x0000000000029707 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
13 0x0000000000028b99 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x0000000000403591 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039ee _start()  ???:0
=================================
==== backtrace (tid:1427517) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x0000000000038d1a MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::All2All_Sync()  ???:0
11 0x0000000000038655 MPIcuFFT_Slab_Z_Then_YX_Opt1<double>::execC2R()  ???:0
12 0x0000000000029707 Tests_Slab_Random_Z_Then_YX<double>::testcase2()  ???:0
13 0x0000000000028b99 Tests_Slab_Random_Z_Then_YX<double>::run()  ???:0
14 0x0000000000403591 main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004039ee _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 4 with PID 1427520 on node uc2n508 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
The call to cuMemcpyAsync failed. This is a unrecoverable error and will
cause the program to abort.
  cuMemcpyAsync(0x14c294c00000, 0x14c088c00000, 131072) returned value 1
Check the cuda.h file for what the return value means.
--------------------------------------------------------------------------
[uc2n508.localdomain:1427853] CUDA: Error in cuMemcpy: res=-1, dest=0x14c294c00000, src=0x14c088c00000, size=131072
[uc2n508:1427853] *** Process received signal ***
[uc2n508:1427853] Signal: Aborted (6)
[uc2n508:1427853] Signal code:  (-6)
[uc2n508:1427853] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x14c506cfedd0]
[uc2n508:1427853] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x14c50696170f]
[uc2n508:1427853] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x14c50694bb25]
[uc2n508:1427853] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c58f)[0x14c5058cb58f]
[uc2n508:1427853] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x77119)[0x14c5058c6119]
[uc2n508:1427853] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_datatype_sndrcv+0x50a)[0x14c512704b2a]
[uc2n508:1427853] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x26e)[0x14c51275980e]
[uc2n508:1427853] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x14c512765702]
[uc2n508:1427853] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x14c51270742b]
[uc2n508:1427853] [ 9] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libslab_decomp.so(_ZN28MPIcuFFT_Slab_Z_Then_YX_Opt1IdE12All2All_SyncEPvb+0x3fa)[0x14c51ce6ed1a]
[uc2n508:1427853] [10] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libslab_decomp.so(_ZN28MPIcuFFT_Slab_Z_Then_YX_Opt1IdE7execC2REPvPKv+0x115)[0x14c51ce6e655]
[uc2n508:1427853] [11] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libslab_tests.so(_ZN27Tests_Slab_Random_Z_Then_YXIdE9testcase2Eii+0x499)[0x14c51d0b3707]
[uc2n508:1427853] [12] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libslab_tests.so(_ZN27Tests_Slab_Random_Z_Then_YXIdE3runEiii+0x67)[0x14c51d0b2b99]
[uc2n508:1427853] [13] slab[0x403591]
[uc2n508:1427853] [14] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x14c50694d6a3]
[uc2n508:1427853] [15] slab[0x4039ee]
[uc2n508:1427853] *** End of error message ***
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 7 with PID 1427853 on node uc2n508 exited on signal 6 (Aborted).
--------------------------------------------------------------------------
[uc2n508.localdomain:1427840] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1427840] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n508.localdomain:1428109] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1428109] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
The call to cuMemcpyAsync failed. This is a unrecoverable error and will
cause the program to abort.
  cuMemcpyAsync(0x15076a800000, 0x916aeb0, 65536) returned value 1
Check the cuda.h file for what the return value means.
--------------------------------------------------------------------------
[uc2n508.localdomain:1428466] CUDA: Error in cuMemcpy: res=-1, dest=0x15076a800000, src=0x916aeb0, size=65536
[uc2n508:1428466] *** Process received signal ***
[uc2n508:1428466] Signal: Aborted (6)
[uc2n508:1428466] Signal code:  (-6)
[uc2n508:1428466] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x1509dc67ddd0]
[uc2n508:1428466] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x1509dc2e070f]
[uc2n508:1428466] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x1509dc2cab25]
[uc2n508:1428466] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x1509db24a375]
[uc2n508:1428466] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_unpack+0xb9)[0x1509db241399]
[uc2n508:1428466] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_datatype_sndrcv+0x1f7)[0x1509e8083817]
[uc2n508:1428466] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_coll_basic_alltoallw_intra+0xa4)[0x1509e8117984]
[uc2n508:1428466] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallw+0x1eb)[0x1509e8086ccb]
[uc2n508:1428466] [ 8] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libslab_decomp.so(_ZN28MPIcuFFT_Slab_Z_Then_YX_Opt1IdE15All2All_MPITypeEPvb+0x36f)[0x1509f27ee41f]
[uc2n508:1428466] [ 9] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libslab_decomp.so(_ZN28MPIcuFFT_Slab_Z_Then_YX_Opt1IdE7execC2REPvPKv+0x115)[0x1509f27ed655]
[uc2n508:1428466] [10] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libslab_tests.so(_ZN27Tests_Slab_Random_Z_Then_YXIdE9testcase2Eii+0x499)[0x1509f2a32707]
[uc2n508:1428466] [11] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libslab_tests.so(_ZN27Tests_Slab_Random_Z_Then_YXIdE3runEiii+0x67)[0x1509f2a31b99]
[uc2n508:1428466] [12] slab[0x403591]
[uc2n508:1428466] [13] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x1509dc2cc6a3]
[uc2n508:1428466] [14] slab[0x4039ee]
[uc2n508:1428466] *** End of error message ***
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 7 with PID 1428466 on node uc2n508 exited on signal 6 (Aborted).
--------------------------------------------------------------------------
[uc2n508.localdomain:1428453] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1428453] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[61132,1],5]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n508.localdomain:1428719] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1428719] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[61434,1],5]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n508.localdomain:1428953] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1428953] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[60670,1],5]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n508.localdomain:1429213] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1429213] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[60866,1],6]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n508.localdomain:1429473] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1429473] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[62145,1],2]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n508.localdomain:1429730] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1429730] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[62407,1],6]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n508.localdomain:1429988] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1429988] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[61658,1],0]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n508.localdomain:1430265] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1430265] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[61913,1],6]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n508.localdomain:1430522] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1430522] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[63199,1],7]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n508.localdomain:1430780] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1430780] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n508
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[62499,1],4]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n508.localdomain:1431040] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n508.localdomain:1431040] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
Starting computation for size 128
-> Executing test 0
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-20 22:49:16.694602
b''

-> Executing test 1
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-20 22:49:30.754316
b''

-> Executing test 2
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-20 22:49:36.986039
b''

-> Executing test 3
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-20 22:49:42.469299
b''

-> Executing test 4
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-20 22:49:48.784210
b''

-> Executing test 5
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-20 22:49:54.399938
b''

-> Executing test 6
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-20 22:50:00.761990
b''

-> Executing test 7
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-20 22:50:06.372775
b''

-> Executing test 8
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-20 22:50:12.628898
b''

-> Executing test 9
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-20 22:50:18.244778
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-20 22:50:24.507561
b''

-> Executing test 1
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-20 22:50:30.095148
b''

-> Executing test 2
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-20 22:50:36.319254
b''

-> Executing test 3
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-20 22:50:42.140290
b''

-> Executing test 4
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-20 22:50:48.488948
b''

-> Executing test 5
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-20 22:50:54.155969
b''

-> Executing test 6
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-20 22:51:00.523006
b''

-> Executing test 7
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-20 22:51:06.183397
b''

-> Executing test 8
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-20 22:51:12.398853
b''

-> Executing test 9
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-20 22:51:18.142058
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-20 22:51:24.583857
b''

-> Executing test 1
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-20 22:51:30.419357
b''

-> Executing test 2
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-20 22:51:36.906767
b''

-> Executing test 3
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-20 22:51:42.722002
b''

-> Executing test 4
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-20 22:51:49.147455
b''

-> Executing test 5
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-20 22:51:54.876375
b''

-> Executing test 6
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-20 22:52:01.283118
b''

-> Executing test 7
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-20 22:52:07.119158
b''

-> Executing test 8
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-20 22:52:13.510333
b''

-> Executing test 9
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-20 22:52:19.182295
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-20 22:52:25.578211
b''

-> Executing test 1
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-20 22:52:31.478200
b''

-> Executing test 2
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-20 22:52:38.003975
b''

-> Executing test 3
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-20 22:52:43.808149
b''

-> Executing test 4
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-20 22:52:50.177065
b''

-> Executing test 5
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-20 22:52:56.104472
b''

-> Executing test 6
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-20 22:53:02.418136
b''

-> Executing test 7
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-20 22:53:08.320063
b''

-> Executing test 8
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-20 22:53:14.773383
b''

-> Executing test 9
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-20 22:53:20.680223
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-20 22:53:27.276814
b''

-> Executing test 1
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-20 22:53:33.383572
b''

-> Executing test 2
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-20 22:53:39.907897
b''

-> Executing test 3
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-20 22:53:46.054999
b''

-> Executing test 4
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-20 22:53:52.520918
b''

-> Executing test 5
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-20 22:53:58.773795
b''

-> Executing test 6
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-20 22:54:05.357408
b''

-> Executing test 7
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-20 22:54:11.469036
b''

-> Executing test 8
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-20 22:54:18.142764
b''

-> Executing test 9
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-20 22:54:24.528378
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-20 22:54:31.208016
b''

-> Executing test 1
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-20 22:54:38.168444
b''

-> Executing test 2
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-20 22:54:45.192694
b''

-> Executing test 3
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-20 22:54:52.028069
b''

-> Executing test 4
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-20 22:54:59.086900
b''

-> Executing test 5
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-20 22:55:05.978220
b''

-> Executing test 6
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-20 22:55:12.858556
b''

-> Executing test 7
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-20 22:55:19.901317
b''

-> Executing test 8
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-20 22:55:26.243265
b''

-> Executing test 9
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-20 22:55:33.074217
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-20 22:55:39.755136
b''

-> Executing test 1
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-20 22:55:48.000500
b''

-> Executing test 2
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-20 22:55:55.364365
b''

-> Executing test 3
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-20 22:56:02.922964
b''

-> Executing test 4
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-20 22:56:10.124310
b''

-> Executing test 5
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-20 22:56:18.487096
b''

-> Executing test 6
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-20 22:56:25.659005
b''

-> Executing test 7
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-20 22:56:34.167085
b''

-> Executing test 8
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-20 22:56:41.451970
b''

-> Executing test 9
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-20 22:56:50.174457
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-20 22:56:57.838123
b''

-> Executing test 1
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-20 22:57:09.260895
b''

-> Executing test 2
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-20 22:57:18.065677
b''

-> Executing test 3
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-20 22:57:28.646761
b''

-> Executing test 4
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-20 22:57:37.466656
b''

-> Executing test 5
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-20 22:57:49.155116
b''

-> Executing test 6
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-20 22:57:57.924245
b''

-> Executing test 7
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-20 22:58:09.955799
b''

-> Executing test 8
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-20 22:58:18.726622
b''

-> Executing test 9
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-20 22:58:30.962735
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-20 22:58:40.440117
b''

-> Executing test 1
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-20 22:58:58.271422
b''

-> Executing test 2
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-20 22:59:10.044451
b''

-> Executing test 3
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-20 22:59:25.871065
b''

-> Executing test 4
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-20 22:59:37.580093
b''

-> Executing test 5
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-20 22:59:55.822087
b''

-> Executing test 6
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-20 23:00:07.567120
b''

-> Executing test 7
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-20 23:00:26.709491
b''

-> Executing test 8
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-20 23:00:38.670623
b''

-> Executing test 9
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-20 23:00:57.882462
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-20 23:01:10.980079
b''

-> Executing test 1
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-20 23:01:41.899987
b''

-> Executing test 2
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-20 23:01:59.769828
b''

-> Executing test 3
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-20 23:02:26.604523
b''

-> Executing test 4
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-20 23:02:44.227927
b''

-> Executing test 5
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-20 23:03:15.224192
b''

-> Executing test 6
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-20 23:03:32.662687
b''

-> Executing test 7
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-20 23:04:05.646458
b''

-> Executing test 8
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-20 23:04:23.247954
b''

-> Executing test 9
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-20 23:04:56.449296
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-20 23:05:16.943248
b''

-> Executing test 1
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-20 23:06:13.477084
b''

-> Executing test 2
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-20 23:06:43.179708
b''

-> Executing test 3
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-20 23:07:31.530402
b''

-> Executing test 4
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-20 23:08:00.949720
b''

-> Executing test 5
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-20 23:08:58.123975
b''

-> Executing test 6
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-20 23:09:27.624339
b''

-> Executing test 7
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-20 23:10:28.558134
b''

-> Executing test 8
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-20 23:10:57.971954
b''

-> Executing test 9
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-20 23:12:00.413287
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-20 23:12:35.765905
b''

-> Executing test 1
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-20 23:14:22.609508
b''

-> Executing test 2
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-20 23:15:17.242592
b''

-> Executing test 3
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-20 23:16:49.011305
b''

-> Executing test 4
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-20 23:17:43.804893
b''

-> Executing test 5
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-20 23:19:34.464994
b''

-> Executing test 6
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-20 23:20:28.721845
b''

-> Executing test 7
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-20 23:20:39.893158
b''

-> Executing test 8
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-20 23:20:49.111179
b''

-> Executing test 9
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-20 23:22:46.002311
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-20 23:22:50.996824
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\n'

-> Executing test 1
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-20 23:22:54.626097
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\n'

-> Executing test 2
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-20 23:22:58.174338
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\n'

-> Executing test 3
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd Streams --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-20 23:23:01.644453
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\n'

-> Executing test 4
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-20 23:23:05.168060
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\n'

-> Executing test 5
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm Peer2Peer -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-20 23:23:08.683363
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\n'

-> Executing test 6
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-20 23:23:12.216321
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\n'

-> Executing test 7
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd Sync --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-20 23:23:15.833564
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\n'

-> Executing test 8
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-20 23:23:19.559325
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\n'

-> Executing test 9
mpiexec -n 8 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 slab -comm All2All -snd MPI_Type --cuda_aware --warmup-rounds 10 --iterations 20 --double_prec -p 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -s Z_Then_YX --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-20 23:23:23.253274
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp:204\n'

all done

============================= JOB FEEDBACK =============================

NodeName=uc2n508
Job ID: 19856693
Cluster: uc2
User/Group: st_st160727/st_us-051200
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 80
CPU Utilized: 07:34:17
CPU Efficiency: 6.67% of 4-17:30:40 core-walltime
Job Wall-clock time: 01:25:08
Memory Utilized: 100.08 GB
Memory Efficiency: 0.00% of 0.00 MB
