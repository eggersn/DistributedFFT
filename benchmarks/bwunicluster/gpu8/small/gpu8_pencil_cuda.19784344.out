Modules loaded
uc2n514
uc2n514
uc2n514
uc2n514
uc2n514
uc2n514
uc2n514
uc2n514
uc2n516
uc2n516
uc2n516
uc2n516
uc2n516
uc2n516
uc2n516
uc2n516
uc2n514 uc2n514 uc2n514 uc2n514 uc2n514 uc2n514 uc2n514 uc2n514 uc2n516 uc2n516 uc2n516 uc2n516 uc2n516 uc2n516 uc2n516 uc2n516
uc2n514 uc2n514 uc2n514 uc2n514 uc2n514 uc2n514 uc2n514 uc2n514
uc2n516 uc2n516 uc2n516 uc2n516 uc2n516 uc2n516 uc2n516 uc2n516
start building
-- The CUDA compiler identification is NVIDIA 11.0.194
-- The CXX compiler identification is GNU 8.3.1
-- Detecting CUDA compiler ABI info
-- Detecting CUDA compiler ABI info - done
-- Check for working CUDA compiler: /opt/bwhpc/common/devel/cuda/11.0/bin/nvcc - skipped
-- Detecting CUDA compile features
-- Detecting CUDA compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /usr/bin/g++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Found MPI_CXX: /pfs/data5/software_uc2/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so (found version "3.1") 
-- Found MPI: TRUE (found version "3.1")  
-- Found CUDAToolkit: /opt/bwhpc/common/devel/cuda/11.0/include (found version "11.0.194") 
-- Looking for C++ include pthread.h
-- Looking for C++ include pthread.h - found
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed
-- Looking for pthread_create in pthreads
-- Looking for pthread_create in pthreads - not found
-- Looking for pthread_create in pthread
-- Looking for pthread_create in pthread - found
-- Found Threads: TRUE  
-- Configuring done
-- Generating done
-- Build files have been written to: /home/st/st_us-051200/st_st160727/DistributedFFT/build
Scanning dependencies of target test_base
[  3%] Building CUDA object CMakeFiles/test_base.dir/tests/src/base.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[  6%] Linking CUDA shared library libtest_base.so
[  6%] Built target test_base
Scanning dependencies of target mpicufft
[  9%] Building CXX object CMakeFiles/mpicufft.dir/src/mpicufft.cpp.o
[ 12%] Linking CXX shared library libmpicufft.so
[ 12%] Built target mpicufft
Scanning dependencies of target timer
[ 15%] Building CXX object CMakeFiles/timer.dir/src/timer.cpp.o
[ 18%] Linking CXX shared library libtimer.so
[ 18%] Built target timer
Scanning dependencies of target pencil_decomp
[ 21%] Building CXX object CMakeFiles/pencil_decomp.dir/src/pencil/mpicufft_pencil.cpp.o
[ 24%] Building CXX object CMakeFiles/pencil_decomp.dir/src/pencil/mpicufft_pencil_opt1.cpp.o
[ 27%] Linking CXX shared library libpencil_decomp.so
[ 27%] Built target pencil_decomp
Scanning dependencies of target pencil_tests
[ 30%] Building CUDA object CMakeFiles/pencil_tests.dir/tests/src/pencil/base.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 33%] Building CUDA object CMakeFiles/pencil_tests.dir/tests/src/pencil/random_dist_1D.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 36%] Building CUDA object CMakeFiles/pencil_tests.dir/tests/src/pencil/random_dist_2D.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 39%] Building CUDA object CMakeFiles/pencil_tests.dir/tests/src/pencil/random_dist_3D.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 42%] Linking CUDA shared library libpencil_tests.so
[ 42%] Built target pencil_tests
Scanning dependencies of target pencil
[ 45%] Building CXX object CMakeFiles/pencil.dir/tests/src/pencil/main.cpp.o
[ 48%] Linking CXX executable pencil
[ 48%] Built target pencil
Scanning dependencies of target slab_decomp
[ 51%] Building CXX object CMakeFiles/slab_decomp.dir/src/slab/default/mpicufft_slab.cpp.o
[ 54%] Building CXX object CMakeFiles/slab_decomp.dir/src/slab/default/mpicufft_slab_opt1.cpp.o
[ 57%] Building CXX object CMakeFiles/slab_decomp.dir/src/slab/z_then_yx/mpicufft_slab_z_then_yx.cpp.o
[ 60%] Building CXX object CMakeFiles/slab_decomp.dir/src/slab/z_then_yx/mpicufft_slab_z_then_yx_opt1.cpp.o
[ 63%] Building CXX object CMakeFiles/slab_decomp.dir/src/slab/y_then_zx/mpicufft_slab_y_then_zx.cpp.o
[ 66%] Linking CXX shared library libslab_decomp.so
[ 66%] Built target slab_decomp
Scanning dependencies of target slab_tests
[ 69%] Building CUDA object CMakeFiles/slab_tests.dir/tests/src/slab/base.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 72%] Building CUDA object CMakeFiles/slab_tests.dir/tests/src/slab/random_dist_default.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 75%] Building CUDA object CMakeFiles/slab_tests.dir/tests/src/slab/random_dist_y_then_zx.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 78%] Building CUDA object CMakeFiles/slab_tests.dir/tests/src/slab/random_dist_z_then_yx.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 81%] Linking CUDA shared library libslab_tests.so
[ 81%] Built target slab_tests
Scanning dependencies of target slab
[ 84%] Building CXX object CMakeFiles/slab.dir/tests/src/slab/main.cpp.o
[ 87%] Linking CXX executable slab
[ 87%] Built target slab
Scanning dependencies of target reference_tests
[ 90%] Building CUDA object CMakeFiles/reference_tests.dir/tests/src/reference/reference.cu.o
nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).
[ 93%] Linking CUDA shared library libreference_tests.so
[ 93%] Built target reference_tests
Scanning dependencies of target reference
[ 96%] Building CXX object CMakeFiles/reference.dir/tests/src/reference/main.cpp.o
[100%] Linking CXX executable reference
[100%] Built target reference
finished building
start python script
Starting on HOST16
*****************************************************************************
Partition 4x4
-----------------------------------------------------------------------------
Pencil Default
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1762947] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1762947] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1763226] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1763226] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1763737] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1763737] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1764003] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1764003] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1764282] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1764282] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1764552] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1764552] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1765063] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1765063] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1765332] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1765332] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1765608] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1765608] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1765875] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1765875] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1766143] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1766143] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1766669] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1766669] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1766941] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1766941] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1767205] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1767205] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1767484] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1767484] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1767999] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1767999] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1768264] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1768264] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1768547] [[28437,0],0] ORTE_ERROR_LOG: Data unpack would read past end of buffer in file util/show_help.c at line 513
[uc2n514.localdomain:1768547] 14 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1768547] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1768816] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1768816] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1769081] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1769081] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1769598] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1769598] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1769881] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1769881] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1770143] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1770143] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1770413] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1770413] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1770934] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1770934] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1771203] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1771203] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1771471] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1771471] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1771746] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1771746] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1772013] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1772013] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1772529] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1772529] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1772813] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1772813] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1773078] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1773078] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1773355] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1773355] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1773869] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1773869] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1774134] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1774134] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1774411] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1774411] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1774679] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1774679] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1774944] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1774944] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1775461] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1775461] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1775739] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1775739] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1776003] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1776003] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1776325] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1776325] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1776840] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1776840] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1777104] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1777104] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1777382] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1777382] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1777649] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1777649] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1777914] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1777914] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1778427] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1778427] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1778714] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1778714] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1778981] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1778981] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1779261] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1779261] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1779775] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1779775] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1780051] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1780051] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1780318] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1780318] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1780585] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1780585] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1780852] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1780852] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1781379] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1781379] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1781663] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1781663] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1781923] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1781923] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1782203] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1782203] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1782717] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1782717] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1782984] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1782984] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1783266] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1783266] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1783533] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1783533] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1783800] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1783800] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1784323] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1784323] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1784610] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1784610] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1784878] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1784878] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1785166] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1785166] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1785679] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1785679] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1785959] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1785959] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1786228] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1786228] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1786496] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1786496] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1786769] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1786769] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1787287] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1787287] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1787591] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1787591] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1787858] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1787858] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1788167] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1788167] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1788683] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1788683] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1788960] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1788960] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1789232] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1789232] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1789501] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1789501] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1789780] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1789780] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1790315] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1790315] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1790633] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1790633] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1790917] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1790917] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1791249] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1791249] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1791767] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1791767] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1792049] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1792049] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1792316] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1792316] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1792596] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1792596] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1792888] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1792888] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1793415] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1793415] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1793760] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1793760] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1794044] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1794044] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1794385] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1794385] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1794921] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1794921] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1795203] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1795203] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1795490] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1795490] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1795779] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1795779] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1796070] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1796070] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1796625] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1796625] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1797043] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1797043] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1797346] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1797346] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1797760] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1797760] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1798307] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1798307] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1798596] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1798596] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1798902] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1798902] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1799195] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1799195] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1799528] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1799528] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1800108] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1800108] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1800684] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1800684] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1801016] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1801016] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1801579] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1801579] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1802156] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1802156] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1802471] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1802471] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
The call to cuMemcpyAsync failed. This is a unrecoverable error and will
cause the program to abort.
  cuMemcpyAsync(0x14b195fe0be0, 0x14b5c6f11664, 131040) returned value 1
Check the cuda.h file for what the return value means.
--------------------------------------------------------------------------
[uc2n514.localdomain:1802488] CUDA: Error in cuMemcpy: res=-1, dest=0x14b195fe0be0, src=0x14b5c6f11664, size=131040
[uc2n514:1802488] *** Process received signal ***
[uc2n514:1802488] Signal: Aborted (6)
[uc2n514:1802488] Signal code:  (-6)
[uc2n514.localdomain:1802484] CUDA: Error in cuMemcpy: res=-1, dest=0x14eba1fe0be0, src=0x14efe1a51664, size=131040
[uc2n514:1802484] *** Process received signal ***
[uc2n514:1802484] Signal: Aborted (6)
[uc2n514:1802484] Signal code:  (-6)
[uc2n514:1802488] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x14b60c710dd0]
[uc2n514:1802488] [ 1] [uc2n514:1802484] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x14f016ec1dd0]
[uc2n514:1802484] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x14f016b2470f]
[uc2n514:1802484] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x14f016b0eb25]
[uc2n514:1802484] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x14f015a8e375]
[uc2n514:1802484] [ 4] /usr/lib64/libc.so.6(gsignal+0x10f)[0x14b60c37370f]
[uc2n514:1802488] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x14b60c35db25]
[uc2n514:1802488] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x14b60b2dd375]
[uc2n514:1802488] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_unpack+0xb9)[0x14f015a85399]
[uc2n514:1802484] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_recv_request_progress_frag+0x124)[0x14f022a3db04]
[uc2n514:1802484] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_unpack+0xb9)[0x14b60b2d4399]
[uc2n514:1802488] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xd8e21)[0x14f015aeae21]
[uc2n514:1802484] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_recv_request_progress_frag+0x124)[0x14b61828cb04]
[uc2n514:1802488] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda75c)[0x14f015aec75c]
[uc2n514:1802484] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xd8e21)[0x14b60b339e21]
[uc2n514:1802488] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x14f015aed1a6]
[uc2n514:1802484] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x14f015a74a1b]
[uc2n514:1802484] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x14f015a7aef5]
[uc2n514:1802484] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x14f0228b78ea]
[uc2n514:1802484] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda75c)[0x14b60b33b75c]
[uc2n514:1802488] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x14b60b33c1a6]
[uc2n514:1802488] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x14b60b2c3a1b]
[uc2n514:1802488] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x14b60b2c9ef5]
[uc2n514:1802488] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x1db)[0x14f02291c77b]
[uc2n514:1802484] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x14f022928702]
[uc2n514:1802484] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x14f0228ca42b]
[uc2n514:1802484] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE28All2All_Sync_SecondTransposeEPvb+0x261)[0x14f02d00db21]
[uc2n514:1802484] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execR2CEPvPKvi+0x486)[0x14f02d00a0c6]
/opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x14b6181068ea]
[uc2n514:1802488] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x1db)[0x14b61816b77b]
[uc2n514:1802488] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x14b618177702]
[uc2n514:1802488] [14] [uc2n514:1802484] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase0Eii+0x686)[0x14f02d26bd66]
[uc2n514:1802484] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x2f)[0x14f02d26b667]
[uc2n514:1802484] [19] pencil[0x40326b]
[uc2n514:1802484] [20] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x14f016b106a3]
[uc2n514:1802484] [21] pencil[0x4035fe]
/opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x14b61811942b]
[uc2n514:1802488] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE28All2All_Sync_SecondTransposeEPvb+0x261)[0x14b62285cb21]
[uc2n514:1802488] [16] [uc2n514:1802484] *** End of error message ***
/home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execR2CEPvPKvi+0x486)[0x14b6228590c6]
[uc2n514:1802488] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase0Eii+0x686)[0x14b622abad66]
[uc2n514:1802488] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x2f)[0x14b622aba667]
[uc2n514:1802488] [19] pencil[0x40326b]
[uc2n514:1802488] [20] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x14b60c35f6a3]
[uc2n514:1802488] [21] pencil[0x4035fe]
[uc2n514:1802488] *** End of error message ***
[uc2n516.localdomain:3736751] CUDA: Error in cuMemcpy: res=-1, dest=0x14b061fe0be0, src=0x14b4b43f9178, size=131040
[uc2n516:3736751] *** Process received signal ***
[uc2n516:3736751] Signal: Aborted (6)
[uc2n516:3736751] Signal code:  (-6)
[uc2n516:3736751] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x14b4d8967dd0]
[uc2n516:3736751] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x14b4d85ca70f]
[uc2n516:3736751] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x14b4d85b4b25]
[uc2n516:3736751] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x14b4d7534375]
[uc2n516:3736751] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_unpack+0xb9)[0x14b4d752b399]
[uc2n516:3736751] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_recv_request_progress_frag+0x124)[0x14b4e44e3b04]
[uc2n516:3736751] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_smcuda_component_progress+0x42e)[0x14b4d75853ee]
[uc2n516:3736751] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x14b4d751aa1b]
[uc2n516:3736751] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x14b4d7520ef5]
[uc2n516:3736751] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x14b4e435d8ea]
[uc2n516:3736751] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x1db)[0x14b4e43c277b]
[uc2n516:3736751] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x14b4e43ce702]
[uc2n516:3736751] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x14b4e437042b]
[uc2n516:3736751] [13] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE28All2All_Sync_SecondTransposeEPvb+0x261)[0x14b4eeab3b21]
[uc2n516:3736751] [14] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execR2CEPvPKvi+0x486)[0x14b4eeab00c6]
[uc2n516:3736751] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase0Eii+0x686)[0x14b4eed11d66]
[uc2n516:3736751] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x2f)[0x14b4eed11667]
[uc2n516:3736751] [17] pencil[0x40326b]
[uc2n516:3736751] [18] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x14b4d85b66a3]
[uc2n516:3736751] [19] pencil[0x4035fe]
[uc2n516:3736751] *** End of error message ***
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 4 with PID 0 on node uc2n514 exited on signal 6 (Aborted).
--------------------------------------------------------------------------
[uc2n514.localdomain:1802471] 2 more processes have sent help message help-mpi-common-cuda.txt / cuMemcpyAsync failed
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1802759] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1802759] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
The call to cuMemcpyAsync failed. This is a unrecoverable error and will
cause the program to abort.
  cuMemcpyAsync(0x1488e7fe0be0, 0x148d3299a0e4, 131040) returned value 1
Check the cuda.h file for what the return value means.
--------------------------------------------------------------------------
[uc2n514.localdomain:1802778] CUDA: Error in cuMemcpy: res=-1, dest=0x1488e7fe0be0, src=0x148d3299a0e4, size=131040
[uc2n514:1802778] *** Process received signal ***
[uc2n514:1802778] Signal: Aborted (6)
[uc2n514:1802778] Signal code:  (-6)
[uc2n514:1802778] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x148d5ec9fdd0]
[uc2n514:1802778] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x148d5e90270f]
[uc2n514:1802778] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x148d5e8ecb25]
[uc2n514:1802778] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x148d5d86c375]
[uc2n514:1802778] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_unpack+0xb9)[0x148d5d863399]
[uc2n514:1802778] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_recv_request_progress_frag+0x124)[0x148d6a81bb04]
[uc2n514:1802778] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xd8e21)[0x148d5d8c8e21]
[uc2n514:1802778] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda75c)[0x148d5d8ca75c]
[uc2n514:1802778] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x148d5d8cb1a6]
[uc2n514:1802778] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x148d5d852a1b]
[uc2n514:1802778] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x148d5d858ef5]
[uc2n514:1802778] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x148d6a6958ea]
[uc2n514:1802778] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_coll_basic_alltoallw_intra+0x252)[0x148d6a739b32]
[uc2n514:1802778] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallw+0x1eb)[0x148d6a6a8ccb]
[uc2n514:1802778] [14] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE31All2All_MPIType_SecondTransposeEPvb+0x15d)[0x148d74dec20d]
[uc2n514:1802778] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execR2CEPvPKvi+0x486)[0x148d74de80c6]
[uc2n514:1802778] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase0Eii+0x686)[0x148d75049d66]
[uc2n514:1802778] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x2f)[0x148d75049667]
[uc2n514:1802778] [18] pencil[0x40326b]
[uc2n514:1802778] [19] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x148d5e8ee6a3]
[uc2n514:1802778] [20] pencil[0x4035fe]
[uc2n514:1802778] *** End of error message ***
[uc2n514.localdomain:1802774] CUDA: Error in cuMemcpy: res=-1, dest=0x145addfe0be0, src=0x145f235a77e4, size=131040
[uc2n514:1802774] *** Process received signal ***
[uc2n514:1802774] Signal: Aborted (6)
[uc2n514:1802774] Signal code:  (-6)
[uc2n514:1802774] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x145f54503dd0]
[uc2n514:1802774] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x145f5416670f]
[uc2n514:1802774] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x145f54150b25]
[uc2n514:1802774] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x145f530d0375]
[uc2n514:1802774] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_unpack+0xb9)[0x145f530c7399]
[uc2n514:1802774] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_recv_request_progress_frag+0x124)[0x145f6007fb04]
[uc2n514:1802774] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xd8e21)[0x145f5312ce21]
[uc2n514:1802774] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda75c)[0x145f5312e75c]
[uc2n514:1802774] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x145f5312f1a6]
[uc2n514:1802774] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x145f530b6a1b]
[uc2n514:1802774] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x145f530bcef5]
[uc2n514:1802774] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x145f5fef98ea]
[uc2n514:1802774] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_coll_basic_alltoallw_intra+0x252)[0x145f5ff9db32]
[uc2n514:1802774] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallw+0x1eb)[0x145f5ff0cccb]
[uc2n514:1802774] [14] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE31All2All_MPIType_SecondTransposeEPvb+0x15d)[0x145f6a65020d]
[uc2n514:1802774] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execR2CEPvPKvi+0x486)[0x145f6a64c0c6]
[uc2n514:1802774] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase0Eii+0x686)[0x145f6a8add66]
[uc2n514:1802774] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x2f)[0x145f6a8ad667]
[uc2n514:1802774] [18] pencil[0x40326b]
[uc2n514:1802774] [19] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x145f541526a3]
[uc2n514:1802774] [20] pencil[0x4035fe]
[uc2n514:1802774] *** End of error message ***
[uc2n516.localdomain:3737050] CUDA: Error in cuMemcpy: res=-1, dest=0x149551fe0be0, src=0x1499a4707138, size=131040
[uc2n516:3737050] *** Process received signal ***
[uc2n516:3737050] Signal: Aborted (6)
[uc2n516:3737050] Signal code:  (-6)
[uc2n516:3737050] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x1499ca266dd0]
[uc2n516:3737050] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x1499c9ec970f]
[uc2n516:3737050] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x1499c9eb3b25]
[uc2n516:3737050] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x1499c8e33375]
[uc2n516:3737050] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_unpack+0xb9)[0x1499c8e2a399]
[uc2n516:3737050] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_recv_request_progress_frag+0x124)[0x1499d5de2b04]
[uc2n516:3737050] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_smcuda_component_progress+0x42e)[0x1499c8e843ee]
[uc2n516:3737050] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x1499c8e19a1b]
[uc2n516:3737050] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x1499c8e1fef5]
[uc2n516:3737050] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x1499d5c5c8ea]
[uc2n516:3737050] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_coll_basic_alltoallw_intra+0x252)[0x1499d5d00b32]
[uc2n516:3737050] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallw+0x1eb)[0x1499d5c6fccb]
[uc2n516:3737050] [12] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE31All2All_MPIType_SecondTransposeEPvb+0x15d)[0x1499e03b320d]
[uc2n516:3737050] [13] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execR2CEPvPKvi+0x486)[0x1499e03af0c6]
[uc2n516:3737050] [14] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase0Eii+0x686)[0x1499e0610d66]
[uc2n516:3737050] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x2f)[0x1499e0610667]
[uc2n516:3737050] [16] pencil[0x40326b]
[uc2n516:3737050] [17] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x1499c9eb56a3]
[uc2n516:3737050] [18] pencil[0x4035fe]
[uc2n516:3737050] *** End of error message ***
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 4 with PID 0 on node uc2n514 exited on signal 6 (Aborted).
--------------------------------------------------------------------------
[uc2n514.localdomain:1802759] 2 more processes have sent help message help-mpi-common-cuda.txt / cuMemcpyAsync failed
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1803056] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1803056] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1803323] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1803323] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1803623] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1803623] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1803890] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1803890] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1804155] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1804155] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1804423] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1804423] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1804722] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1804722] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1804988] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1804988] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1805252] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1805252] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1805529] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1805529] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1805795] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1805795] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1806086] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1806086] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1806363] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1806363] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1806632] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1806632] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1806897] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1806897] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1807178] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1807178] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1807458] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1807458] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1807723] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1807723] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1807992] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1807992] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1808269] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1808269] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1808560] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1808560] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1808825] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1808825] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1809104] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1809104] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1809368] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1809368] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1809668] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1809668] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1809933] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1809933] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1810198] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1810198] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1810474] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1810474] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1810743] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1810743] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1811054] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1811054] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1811341] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1811341] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1811622] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1811622] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1811897] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1811897] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1812193] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1812193] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1812483] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1812483] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1812769] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1812769] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1813043] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1813043] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 5 with PID 0 on
node uc2n514 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1813321] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1813321] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 14 with PID 3747749 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1813605] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1813605] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1814010] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1814010] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 15 with PID 3748450 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1814291] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1814291] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1814660] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1814660] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 11 with PID 3749096 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1814930] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1814930] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 13 with PID 3749392 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1815210] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1815210] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 6 with PID 0 on
node uc2n514 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1815494] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1815494] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 2 with PID 0 on
node uc2n514 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128
2021-09-16 16:54:25.732209
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128
2021-09-16 16:54:39.959456
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128
2021-09-16 16:54:48.775182
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128
2021-09-16 16:54:58.513610
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128
2021-09-16 16:55:07.448223
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128
2021-09-16 16:55:17.503873
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128
2021-09-16 16:55:26.272582
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128
2021-09-16 16:55:35.068637
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128
2021-09-16 16:55:43.647377
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 256
2021-09-16 16:55:53.353631
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 256
2021-09-16 16:56:02.350940
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 256
2021-09-16 16:56:11.281304
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 256
2021-09-16 16:56:21.214841
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 256
2021-09-16 16:56:30.076272
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 256
2021-09-16 16:56:40.043347
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 256
2021-09-16 16:56:49.967692
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 256
2021-09-16 16:56:58.987954
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 256
2021-09-16 16:57:07.880923
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 256 -nz 256
2021-09-16 16:57:16.905384
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 256 -nz 256
2021-09-16 16:57:25.580855
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 256 -nz 256
2021-09-16 16:57:35.631474
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 256 -nz 256
2021-09-16 16:57:46.637691
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 256 -nz 256
2021-09-16 16:57:55.570362
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 256 -nz 256
2021-09-16 16:58:06.597072
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 256 -nz 256
2021-09-16 16:58:15.583409
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 256 -nz 256
2021-09-16 16:58:24.428348
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 256 -nz 256
2021-09-16 16:58:33.295547
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256
2021-09-16 16:58:42.478345
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256
2021-09-16 16:58:51.891270
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256
2021-09-16 16:59:06.835053
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256
2021-09-16 16:59:21.004916
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256
2021-09-16 16:59:29.981843
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256
2021-09-16 16:59:42.815398
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256
2021-09-16 16:59:51.707548
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256
2021-09-16 17:00:00.795624
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256
2021-09-16 17:00:09.538796
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 512
2021-09-16 17:00:18.536866
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 512
2021-09-16 17:00:27.879829
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 512
2021-09-16 17:00:37.098159
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 512
2021-09-16 17:00:50.413060
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 512
2021-09-16 17:00:59.308370
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 512
2021-09-16 17:01:12.265948
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 512
2021-09-16 17:01:21.089385
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 512
2021-09-16 17:01:29.986129
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 512
2021-09-16 17:01:38.831355
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 512 -nz 512
2021-09-16 17:01:47.787803
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 512 -nz 512
2021-09-16 17:01:56.767271
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 512 -nz 512
2021-09-16 17:02:06.234565
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 512 -nz 512
2021-09-16 17:02:23.315723
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 512 -nz 512
2021-09-16 17:02:32.321847
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 512 -nz 512
2021-09-16 17:02:49.214208
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 512 -nz 512
2021-09-16 17:02:58.260573
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 512 -nz 512
2021-09-16 17:03:07.303780
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 512 -nz 512
2021-09-16 17:03:16.319700
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512
2021-09-16 17:03:25.525105
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512
2021-09-16 17:03:35.037961
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512
2021-09-16 17:03:44.451897
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512
2021-09-16 17:04:09.893160
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512
2021-09-16 17:04:19.346913
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512
2021-09-16 17:04:44.812904
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512
2021-09-16 17:04:54.451571
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512
2021-09-16 17:05:04.136160
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512
2021-09-16 17:05:13.574619
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 1024
2021-09-16 17:05:23.467720
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 1024
2021-09-16 17:05:33.870965
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 1024
2021-09-16 17:05:44.288889
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 1024
2021-09-16 17:06:12.951365
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 1024
2021-09-16 17:06:23.440793
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 1024
2021-09-16 17:06:50.466919
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 1024
2021-09-16 17:07:00.867763
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 1024
2021-09-16 17:07:11.493564
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 1024
2021-09-16 17:07:21.927248
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 1024 -nz 1024
2021-09-16 17:07:33.364735
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 1024 -nz 1024
2021-09-16 17:07:44.989940
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 1024 -nz 1024
2021-09-16 17:07:56.739594
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 1024 -nz 1024
2021-09-16 17:08:43.989257
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 1024 -nz 1024
2021-09-16 17:08:55.813697
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 1024 -nz 1024
2021-09-16 17:09:45.525477
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 1024 -nz 1024
2021-09-16 17:09:57.129421
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 1024 -nz 1024
2021-09-16 17:10:09.248354
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 1024 -nz 1024
2021-09-16 17:10:21.114153
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024
2021-09-16 17:10:34.865505
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024
2021-09-16 17:10:52.084264
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024
2021-09-16 17:11:09.418715
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024
2021-09-16 17:12:34.846074
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024
2021-09-16 17:12:52.098869
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024
2021-09-16 17:14:14.226668
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024
2021-09-16 17:14:32.047922
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024
2021-09-16 17:14:47.545148
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024
2021-09-16 17:15:05.165795
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 2048
2021-09-16 17:15:24.010911
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 2048
2021-09-16 17:15:50.223977
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 2048
2021-09-16 17:16:15.942887
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 2048
2021-09-16 17:17:59.456500
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 2048
2021-09-16 17:18:25.512325
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 2048
2021-09-16 17:20:03.546918
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 2048
2021-09-16 17:20:30.510602
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 2048
2021-09-16 17:20:52.365001
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 2048
2021-09-16 17:21:19.047590
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 2048 -nz 2048
2021-09-16 17:21:47.744398
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 2048 -nz 2048
2021-09-16 17:22:30.710890
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 2048 -nz 2048
2021-09-16 17:23:12.855297
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 2048 -nz 2048
2021-09-16 17:26:28.580234
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 2048 -nz 2048
2021-09-16 17:27:11.180768
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 2048 -nz 2048
2021-09-16 17:30:15.480092
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 2048 -nz 2048
2021-09-16 17:30:57.643516
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 2048 -nz 2048
2021-09-16 17:31:31.282423
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 2048 -nz 2048
2021-09-16 17:32:14.892642
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048
2021-09-16 17:33:02.134981
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048
2021-09-16 17:34:23.316573
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048
2021-09-16 17:35:42.703575
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048
2021-09-16 17:42:07.681480
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048
2021-09-16 17:43:27.669915
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048
2021-09-16 17:49:29.558367
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048
2021-09-16 17:50:48.457229
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048
2021-09-16 17:51:50.062179
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048
2021-09-16 17:52:05.575841
b''

Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 17:52:21.771774
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 17:52:34.371597
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 17:52:42.930193
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 17:52:51.588929
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 17:52:59.888799
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 17:53:08.473883
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 17:53:16.969601
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 17:53:25.513102
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 17:53:34.667946
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 17:53:44.140387
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 17:53:52.787314
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 17:54:02.223821
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 17:54:12.090873
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 17:54:22.040322
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 17:54:31.284567
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 17:54:39.879417
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 17:54:48.703148
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 17:54:57.277802
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 17:55:07.322960
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 17:55:18.849016
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 17:55:28.835778
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 17:55:39.984828
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 17:55:50.234197
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 17:56:01.207867
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 17:56:11.613180
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 17:56:21.611729
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 17:56:31.587575
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 17:56:42.854331
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 17:57:03.646873
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 17:57:24.371754
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 17:57:49.289232
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 17:58:10.878572
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 17:58:35.520552
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 17:58:56.319613
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 17:59:18.685089
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 17:59:42.857054
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 18:00:08.454409
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 18:00:24.864105
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 18:00:48.049459
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 18:02:57.719396
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 18:03:14.128668
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 18:05:23.545420
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 18:05:39.584444
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 18:06:01.459391
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 18:06:23.313964
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

Pencil Opt1
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1815781] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1815781] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1816051] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1816051] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1816319] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1816319] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1816599] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1816599] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1816867] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1816867] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1817133] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1817133] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1817406] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1817406] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1817673] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1817673] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1817938] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1817938] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1818205] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1818205] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1818483] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1818483] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1818749] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1818749] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1819017] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1819017] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1819291] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1819291] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1819559] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1819559] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1819828] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1819828] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1820106] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1820106] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1820373] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1820373] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1820638] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1820638] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1820920] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1820920] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1821187] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1821187] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1821452] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1821452] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1821718] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1821718] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1821995] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1821995] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1822262] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1822262] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1822529] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1822529] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1822806] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1822806] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1823073] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1823073] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1823338] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1823338] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1823621] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1823621] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1823889] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1823889] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1824156] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1824156] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1824432] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1824432] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1824698] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1824698] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1824965] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1824965] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1825232] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1825232] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1825508] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1825508] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1825774] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1825774] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1826037] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1826037] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1826320] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1826320] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1826587] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1826587] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1826855] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1826855] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1827129] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1827129] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1827396] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1827396] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1827663] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1827663] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1827940] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1827940] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1828205] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1828205] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1828472] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1828472] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1828753] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1828753] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1829017] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1829017] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1829297] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1829297] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1829563] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1829563] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1829833] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1829833] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1830108] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1830108] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1830378] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1830378] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1830659] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1830659] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1830926] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1830926] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1831197] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1831197] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1831472] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1831472] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1831739] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1831739] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1832016] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1832016] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1832285] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1832285] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1832556] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1832556] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1832845] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1832845] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1833108] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1833108] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1833385] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1833385] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1833655] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1833655] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1833932] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1833932] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1834207] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1834207] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1834485] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1834485] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1834770] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1834770] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1835037] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1835037] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1835322] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1835322] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1835588] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1835588] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1835871] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1835871] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1836147] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1836147] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1836422] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1836422] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1836711] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1836711] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1836978] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1836978] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1837272] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1837272] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1837547] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1837547] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1837841] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1837841] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1838126] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1838126] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1838395] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1838395] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1838695] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1838695] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1838967] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1838967] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1839280] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1839280] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1839560] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1839560] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1839854] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1839854] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1840135] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1840135] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1840436] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1840436] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1840720] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1840720] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1841004] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1841004] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1841334] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1841334] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1841608] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1841608] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1841944] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1841944] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1842229] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1842229] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1842561] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1842561] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1842849] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1842849] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1843193] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1843193] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1843481] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1843481] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1843792] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1843792] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1844137] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1844137] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1844439] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1844439] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1844807] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1844807] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1845097] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1845097] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1845482] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1845482] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1845778] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1845778] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1846186] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1846186] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1846519] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1846519] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1846839] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1846839] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1847271] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1847271] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:1847290:0:1847290] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x145a94400010)
[uc2n514:1847287:0:1847287] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x148504400010)
[uc2n514:1847291:0:1847291] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x150ecc400010)
[uc2n514:1847286:0:1847286] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14562c400010)
[uc2n516:3782332:0:3782332] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1516ac400010)
[uc2n516:3782333:0:3782333] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x151d58400010)
[uc2n516:3782337:0:3782337] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x146f00400010)
[uc2n516:3782336:0:3782336] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1456fc400010)
[uc2n514:1847289:0:1847289] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1452cc400000)
[uc2n514:1847288:0:1847288] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14d66c400000)
[uc2n514:1847284:0:1847284] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14dd82400000)
[uc2n514:1847285:0:1847285] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14fc16400000)
[uc2n516:3782335:0:3782335] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14af6c400000)
[uc2n516:3782331:0:3782331] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14864c400000)
[uc2n516:3782334:0:3782334] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14fab8400000)
[uc2n516:3782330:0:3782330] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1517e4400000)
==== backtrace (tid:1847288) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:1847289) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:1847285) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:1847284) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
==== backtrace (tid:1847290) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
==== backtrace (tid:1847291) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:1847286) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:1847287) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3782334) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3782331) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3782330) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3782335) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3782333) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3782332) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
==== backtrace (tid:3782336) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3782337) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 1 with PID 0 on node uc2n514 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1847609] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1847609] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:1847629:0:1847629] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14fac4400000)
[uc2n514:1847633:0:1847633] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x150674400000)
[uc2n514:1847628:0:1847628] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x154c94400000)
[uc2n514:1847632:0:1847632] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x153310400000)
==== backtrace (tid:1847628) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:1847633) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:1847632) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
==== backtrace (tid:1847629) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
11 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
[uc2n516:3782670:0:3782670] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x149bf0400000)
[uc2n516:3782674:0:3782674] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x145aa8400000)
[uc2n516:3782675:0:3782675] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x151e28400000)
[uc2n516:3782671:0:3782671] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x15011e400000)
==== backtrace (tid:3782670) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3782674) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3782675) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3782671) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 3 with PID 0 on node uc2n514 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1847904] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1847904] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1848238] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1848238] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1848637] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1848637] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n516:3783718:0:3783718] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14ab00000010)
[uc2n516:3783717:0:3783717] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x154ee6800010)
[uc2n516:3783719:0:3783719] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x153c30000010)
[uc2n516:3783720:0:3783720] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x150f0c000010)
[uc2n516:3783724:0:3783724] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x149b94000010)
[uc2n516:3783723:0:3783723] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1486a4000010)
[uc2n516:3783721:0:3783721] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1454c6c00010)
[uc2n516:3783722:0:3783722] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14a2a4000010)
==== backtrace (tid:3783718) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
17 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3783717) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
17 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3783719) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
17 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3783720) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
17 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3783724) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
17 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3783723) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
17 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3783721) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
17 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3783722) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
17 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
[uc2n514:1848660:0:1848660] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c1c2800000)
[uc2n514:1848661:0:1848661] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x146c8c000000)
[uc2n514:1848663:0:1848663] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x154b44000000)
[uc2n514:1848662:0:1848662] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1478fe000000)
[uc2n514:1848667:0:1848667] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x149b04000000)
[uc2n514:1848666:0:1848666] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14bf64000000)
[uc2n514:1848664:0:1848664] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1491c4800000)
[uc2n514:1848665:0:1848665] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e09e000000)
==== backtrace (tid:1848660) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
11 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:1848661) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
11 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:1848663) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
11 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:1848662) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
11 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:1848667) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
11 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:1848666) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
11 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:1848664) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
11 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:1848665) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
11 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 11 with PID 3783720 on node uc2n516 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1848971] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1848971] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n516:3784054:0:3784054] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14dbb4800000)
[uc2n516:3784055:0:3784055] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x153120000000)
[uc2n516:3784057:0:3784057] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c0b4000000)
[uc2n516:3784056:0:3784056] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x147d4c000000)
[uc2n516:3784061:0:3784061] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x149e60000000)
[uc2n516:3784060:0:3784060] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x150960000000)
[uc2n516:3784058:0:3784058] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c6e2c00000)
[uc2n516:3784059:0:3784059] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e94e000000)
==== backtrace (tid:3784054) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3784055) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3784057) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3784056) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3784061) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3784060) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3784058) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3784059) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[uc2n514:1848997:0:1848997] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x145fcc000000)
==== backtrace (tid:1848997) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
10 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
13 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
[uc2n514:1848998:0:1848998] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x154906000000)
==== backtrace (tid:1848998) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
10 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
13 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
[uc2n514:1848991:0:1848991] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x147c56800000)
==== backtrace (tid:1848991) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
10 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
13 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
[uc2n514:1848992:0:1848992] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14abf8000000)
==== backtrace (tid:1848992) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
10 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
13 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
[uc2n514:1848993:0:1848993] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x15366c000000)
==== backtrace (tid:1848993) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
10 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
13 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
[uc2n514:1848994:0:1848994] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x151b58000000)
==== backtrace (tid:1848994) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
10 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
13 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
[uc2n514:1848995:0:1848995] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x145912800000)
==== backtrace (tid:1848995) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
10 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
13 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
[uc2n514:1848996:0:1848996] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x146242000000)
==== backtrace (tid:1848996) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
10 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
13 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
mpiexec noticed that process rank 9 with PID 3784055 on node uc2n516 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1849307] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1849307] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1849581] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1849581] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1849866] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1849866] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1850132] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1850132] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1850399] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1850399] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1850679] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1850679] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1850962] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1850962] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1851229] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1851229] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1851506] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1851506] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1851773] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1851773] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1852038] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1852038] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1852333] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1852333] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1852600] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1852600] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1852866] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1852866] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1853145] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1853145] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1853428] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1853428] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1853733] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1853733] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1854002] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1854002] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1854280] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1854280] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1854549] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1854549] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1854833] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1854833] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1855108] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1855108] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1855375] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1855375] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1855657] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1855657] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1855939] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1855939] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1856206] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1856206] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1856485] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1856485] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1856754] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1856754] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1857038] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1857038] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1857324] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1857324] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1857608] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1857608] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1857890] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1857890] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1858162] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1858162] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1858459] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1858459] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1858748] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1858748] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1859028] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1859028] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1859302] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1859302] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1859655] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1859655] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1860015] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1860015] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1860378] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1860378] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:1860393:0:1860393] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1510fe400010)
[uc2n514:1860394:0:1860394] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14db0c400010)
[uc2n514:1860392:0:1860392] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x148fbc400000)
==== backtrace (tid:1860392) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
14 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:1860393) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
20 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:1860394) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
20 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[uc2n516:3795644:0:3795644] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1502f4400000)
==== backtrace (tid:3795644) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
14 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
[uc2n516:3795645:0:3795645] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x153a14400010)
==== backtrace (tid:3795645) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
20 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
[uc2n516:3795646:0:3795646] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x153c88400010)
==== backtrace (tid:3795646) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
20 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
[uc2n516:3795648:0:3795648] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1483f4400000)
==== backtrace (tid:3795648) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
14 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
[uc2n516:3795649:0:3795649] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14780c400010)
==== backtrace (tid:3795649) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
20 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
[uc2n516:3795650:0:3795650] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14ba4e400010)
==== backtrace (tid:3795650) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
20 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
mpiexec noticed that process rank 2 with PID 0 on node uc2n514 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1860740] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1860740] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:1860761:0:1860761] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c83c400000)
==== backtrace (tid:1860761) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
11 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
[uc2n514:1860760:0:1860760] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x15150c400000)
==== backtrace (tid:1860760) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
11 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
[uc2n514:1860759:0:1860759] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14a70c400000)
==== backtrace (tid:1860759) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
10 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
13 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[uc2n514:1860765:0:1860765] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c188400000)
==== backtrace (tid:1860765) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
11 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
[uc2n514:1860764:0:1860764] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x153696400000)
==== backtrace (tid:1860764) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
11 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
[uc2n516:3796045:0:3796045] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14fc36400000)
==== backtrace (tid:3796045) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
10 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
13 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
[uc2n516:3796046:0:3796046] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1502c8400000)
==== backtrace (tid:3796046) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
11 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
[uc2n516:3796047:0:3796047] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1464dc400000)
==== backtrace (tid:3796047) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
11 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
mpiexec noticed that process rank 3 with PID 0 on node uc2n514 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1861118] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1861118] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1861488] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1861488] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1861834] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1861834] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:1861852:0:1861852] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14da64000000)
[uc2n514:1861851:0:1861851] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e4da000000)
[uc2n514:1861850:0:1861850] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c260000000)
[uc2n514:1861849:0:1861849] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x150d0e800000)
==== backtrace (tid:1861851) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
11 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
14 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:1861852) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
11 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
14 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:1861850) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
11 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
14 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:1861849) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
11 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
14 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[uc2n514:1861855:0:1861855] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14690c000000)
==== backtrace (tid:1861855) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
11 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
14 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
[uc2n514:1861854:0:1861854] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14b084000000)
==== backtrace (tid:1861854) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
11 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
14 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
[uc2n514:1861856:0:1861856] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14777e000000)
==== backtrace (tid:1861856) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
11 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
14 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
[uc2n516:3797141:0:3797141] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14d79c000010)
==== backtrace (tid:3797141) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
17 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
20 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
[uc2n516:3797134:0:3797134] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x145d3e800010)
==== backtrace (tid:3797134) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
17 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
20 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
[uc2n516:3797135:0:3797135] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14b05c000010)
==== backtrace (tid:3797135) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
17 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
20 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
[uc2n516:3797136:0:3797136] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x144e50000010)
==== backtrace (tid:3797136) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
17 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
20 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
[uc2n516:3797137:0:3797137] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x146084000010)
==== backtrace (tid:3797137) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
17 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
20 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
[uc2n516:3797138:0:3797138] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x146b96c00010)
==== backtrace (tid:3797138) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
17 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
20 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
[uc2n516:3797139:0:3797139] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1457e8000010)
==== backtrace (tid:3797139) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
17 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
20 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
[uc2n516:3797140:0:3797140] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x148cdc000010)
==== backtrace (tid:3797140) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002d430 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
17 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
20 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
mpiexec noticed that process rank 3 with PID 0 on node uc2n514 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1862230] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1862230] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:1862250:0:1862250] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14fc04000000)
[uc2n514:1862251:0:1862251] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x149f9c000000)
[uc2n514:1862249:0:1862249] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14aa98000000)
[uc2n514:1862248:0:1862248] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e9fe800000)
==== backtrace (tid:1862250) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
10 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
13 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:1862251) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
10 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
13 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:1862249) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
10 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
13 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:1862248) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
10 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
13 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[uc2n514:1862255:0:1862255] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x152716000000)
==== backtrace (tid:1862255) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
10 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
13 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
[uc2n514:1862254:0:1862254] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14af8c000000)
==== backtrace (tid:1862254) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
10 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
13 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
[uc2n514:1862252:0:1862252] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14cf0a800000)
==== backtrace (tid:1862252) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
10 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
13 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
[uc2n514:1862253:0:1862253] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1487a0000000)
==== backtrace (tid:1862253) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000ce941 mca_btl_openib_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x0000000000121b20 mca_coll_basic_alltoallw_intra()  ???:0
 8 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 9 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
10 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
11 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
13 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
14 0x000000000040326b main()  ???:0
15 0x00000000000236a3 __libc_start_main()  ???:0
16 0x00000000004035fe _start()  ???:0
=================================
[uc2n516:3797563:0:3797563] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x152064000000)
[uc2n516:3797564:0:3797564] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x149fc4000000)
[uc2n516:3797562:0:3797562] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x144e44000000)
[uc2n516:3797561:0:3797561] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14979ac00000)
==== backtrace (tid:3797564) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
11 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3797562) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
11 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3797563) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
11 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3797561) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
11 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
[uc2n516:3797557:0:3797557] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x144faa800000)
==== backtrace (tid:3797557) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
11 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
[uc2n516:3797558:0:3797558] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c698000000)
==== backtrace (tid:3797558) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
11 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
[uc2n516:3797559:0:3797559] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1453ec000000)
==== backtrace (tid:3797559) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
11 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
[uc2n516:3797560:0:3797560] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e298000000)
==== backtrace (tid:3797560) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002dc9d MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a196 MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
11 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
mpiexec noticed that process rank 2 with PID 0 on node uc2n514 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-16 18:06:46.841760
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-16 18:07:02.361266
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-16 18:07:10.605663
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-16 18:07:19.236812
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-16 18:07:27.586728
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-16 18:07:36.491954
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-16 18:07:44.779365
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-16 18:07:53.499968
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-16 18:08:01.808352
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-16 18:08:10.675033
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-16 18:08:19.014167
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-16 18:08:27.326852
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-16 18:08:36.402441
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-16 18:08:44.752023
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-16 18:08:54.200173
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-16 18:09:06.733112
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-16 18:09:15.802385
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-16 18:09:24.171992
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-16 18:09:34.441899
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-16 18:09:42.805648
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-16 18:09:51.517345
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-16 18:10:00.469315
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-16 18:10:08.905570
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-16 18:10:20.058690
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-16 18:10:28.471516
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-16 18:10:38.277855
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-16 18:10:46.603091
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-16 18:10:56.725792
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-16 18:11:05.171087
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-16 18:11:13.591360
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-16 18:11:23.280751
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-16 18:11:31.745292
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-16 18:11:42.049345
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-16 18:11:50.459412
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-16 18:12:00.518455
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-16 18:12:08.887822
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-16 18:12:19.363770
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-16 18:12:27.788985
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-16 18:12:36.244511
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-16 18:12:47.385563
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-16 18:12:57.860867
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-16 18:13:11.007559
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-16 18:13:20.101339
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-16 18:13:32.657562
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-16 18:13:41.144587
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-16 18:13:53.887936
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-16 18:14:02.574476
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-16 18:14:11.030384
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-16 18:14:22.414718
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-16 18:14:30.994053
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-16 18:14:43.508579
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-16 18:14:52.008645
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-16 18:15:07.146421
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-16 18:15:15.743840
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-16 18:15:35.668997
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-16 18:15:44.544732
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-16 18:15:53.412798
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-16 18:16:07.894388
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-16 18:16:17.022332
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-16 18:16:33.824514
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-16 18:16:42.872609
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-16 18:16:59.445206
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-16 18:17:08.959791
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-16 18:17:26.601752
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-16 18:17:36.117206
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-16 18:17:45.618927
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-16 18:18:06.369541
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-16 18:18:15.991295
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-16 18:18:40.596192
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-16 18:18:50.106313
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-16 18:19:15.663767
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-16 18:19:25.206299
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-16 18:19:52.863605
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-16 18:20:03.718067
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-16 18:20:14.513720
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-16 18:20:38.360000
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-16 18:20:49.445653
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-16 18:21:18.455066
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-16 18:21:29.295200
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-16 18:22:09.094568
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-16 18:22:20.259313
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-16 18:23:06.709355
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-16 18:23:23.332703
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-16 18:23:39.606189
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-16 18:24:22.420713
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-16 18:24:38.657979
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-16 18:25:30.022609
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-16 18:25:47.096299
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-16 18:26:30.069007
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-16 18:26:47.651093
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-16 18:27:39.009185
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-16 18:28:03.195715
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-16 18:28:29.066535
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-16 18:29:44.459877
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-16 18:30:09.521700
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-16 18:31:41.910508
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-16 18:32:06.231533
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-16 18:33:21.278764
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-16 18:33:46.297775
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-16 18:35:24.806843
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-16 18:36:05.693418
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-16 18:36:46.897445
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-16 18:38:30.674524
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-16 18:39:13.253852
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-16 18:41:21.719195
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-16 18:42:03.342986
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-16 18:44:21.279167
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-16 18:45:08.787300
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-16 18:48:02.597104
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-16 18:49:18.284113
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-16 18:50:31.450337
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-16 18:53:48.690514
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-16 18:53:56.549369
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-16 18:54:06.027241
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-16 18:55:20.269708
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-16 18:58:13.593461
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-16 18:58:22.589954
b''

Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 18:58:36.857328
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 18:58:45.895772
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 18:58:54.793785
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 18:59:04.173752
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 18:59:12.945720
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 18:59:21.925185
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 18:59:30.862753
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 18:59:39.800032
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 18:59:49.305761
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 18:59:58.179813
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 19:00:07.479920
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 19:00:17.577501
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 19:00:27.596843
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 19:00:36.746204
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 19:00:45.974865
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 19:00:55.124109
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 19:01:04.197523
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 19:01:13.210455
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 19:01:22.185898
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 19:01:32.218916
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 19:01:42.588903
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 19:01:52.876727
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 19:02:02.972390
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 19:02:16.411059
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 19:02:26.163615
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 19:02:36.719509
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 19:02:46.870921
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 19:02:57.376520
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 19:03:17.831390
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 19:03:37.904795
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 19:03:59.328564
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 19:04:19.203584
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 19:04:41.614709
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 19:05:04.315281
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 19:05:25.498653
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 19:05:45.721170
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 19:06:10.635004
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 19:07:53.424092
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 19:09:37.140418
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 19:11:25.750249
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 19:12:52.855358
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 19:14:29.503308
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 19:16:21.243785
b'Result (avg): -nan\nResult (max): -nan\n'

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 19:18:06.179967
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 19:19:35.794616
b''

Pencil Default Inverse
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1862645] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1862645] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1862921] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1862921] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1863436] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1863436] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1863718] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1863718] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1863984] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1863984] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1864249] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1864249] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1864526] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1864526] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1864795] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1864795] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1865060] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1865060] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1865339] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1865339] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1865602] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1865602] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1866117] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1866117] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1866384] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1866384] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1866667] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1866667] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1866934] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1866934] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1867200] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1867200] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1867475] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1867475] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1867740] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1867740] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1868005] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1868005] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1868283] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1868283] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1868801] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1868801] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1869068] [[5756,0],0] ORTE_ERROR_LOG: Data unpack would read past end of buffer in file util/show_help.c at line 507
[uc2n514.localdomain:1869068] 14 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1869068] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1869347] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1869347] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1869616] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1869616] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1869881] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1869881] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1870148] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1870148] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1870425] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1870425] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1870692] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1870692] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1870959] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1870959] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1871483] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1871483] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1871750] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1871750] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1872018] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1872018] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1872302] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1872302] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1872566] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1872566] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1872830] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1872830] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1873107] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1873107] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1873373] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1873373] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1873641] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1873641] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1874168] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1874168] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1874436] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1874436] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1874702] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1874702] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1874986] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1874986] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1875251] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1875251] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1875528] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1875528] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1875795] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1875795] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1876058] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1876058] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1876335] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1876335] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1876848] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1876848] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1877119] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1877119] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1877400] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1877400] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1877670] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1877670] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1877946] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1877946] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1878213] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1878213] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1878478] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1878478] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1878754] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1878754] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1879021] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1879021] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1879533] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1879533] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1879820] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1879820] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1880087] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1880087] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1880373] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1880373] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1880649] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1880649] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1880919] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1880919] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1881184] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1881184] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1881466] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1881466] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1881732] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1881732] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1882247] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1882247] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1882530] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1882530] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1882809] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1882809] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1883096] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1883096] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1883363] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1883363] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1883628] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1883628] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1883907] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1883907] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1884174] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1884174] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1884443] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1884443] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1884968] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1884968] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1885268] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1885268] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1885545] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1885545] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1885838] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1885838] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1886119] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1886119] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1886388] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1886388] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1886671] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1886671] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1886940] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1886940] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1887219] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1887219] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1887736] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1887736] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1888072] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1888072] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1888356] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1888356] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1888671] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1888671] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1888960] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1888960] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1889227] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1889227] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1889507] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1889507] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1889787] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1889787] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1890077] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1890077] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1890599] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1890599] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1890958] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1890958] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1891244] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1891244] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1891601] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1891601] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1891887] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1891887] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1892159] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1892159] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1892443] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1892443] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1892736] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1892736] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1893038] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1893038] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1893580] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1893580] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1894035] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1894035] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1894332] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1894332] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1894769] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1894769] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1895075] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1895075] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1895366] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1895366] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1895658] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1895658] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1896011] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1896011] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1896340] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1896340] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1896911] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1896911] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1897482] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1897482] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
The call to cuMemcpyAsync failed. This is a unrecoverable error and will
cause the program to abort.
  cuMemcpyAsync(0x15388851b1b8, 0x153435fe0be0, 131040) returned value 1
Check the cuda.h file for what the return value means.
--------------------------------------------------------------------------
[uc2n514.localdomain:1897495] CUDA: Error in cuMemcpy: res=-1, dest=0x15388851b1b8, src=0x153435fe0be0, size=131040
[uc2n514:1897495] *** Process received signal ***
[uc2n514:1897495] Signal: Aborted (6)
[uc2n514:1897495] Signal code:  (-6)
[uc2n514:1897495] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x1538ad69fdd0]
[uc2n514:1897495] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x1538ad30270f]
[uc2n514:1897495] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x1538ad2ecb25]
[uc2n514:1897495] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x1538ac26c375]
[uc2n514:1897495] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x1538ac2631e8]
[uc2n514:1897495] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_smcuda_prepare_src+0x126)[0x1538ac2bb0a6]
[uc2n514:1897495] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x1538b921e22b]
[uc2n514:1897495] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x1538b922127c]
[uc2n514:1897495] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_smcuda_component_progress+0x507)[0x1538ac2bd4c7]
[uc2n514:1897495] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x1538ac252a1b]
[uc2n514:1897495] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x1538ac258ef5]
[uc2n514:1897495] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x1538b90958ea]
[uc2n514:1897495] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x1db)[0x1538b90fa77b]
[uc2n514:1897495] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x1538b9106702]
[uc2n514:1897495] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x1538b90a842b]
[uc2n514:1897495] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE27All2All_Sync_FirstTransposeEPvb+0x9fa)[0x1538c37ea01a]
[uc2n514:1897495] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x3d3)[0x1538c37e85e3]
[uc2n514:1897495] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x1538c3a4a65e]
[uc2n514:1897495] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x1538c3a4969f]
[uc2n514:1897495] [19] pencil[0x40326b]
[uc2n514:1897495] [20] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x1538ad2ee6a3]
[uc2n514:1897495] [21] pencil[0x4035fe]
[uc2n514:1897495] *** End of error message ***
[uc2n516.localdomain:3833418] CUDA: Error in cuMemcpy: res=-1, dest=0x146c001d7138, src=0x1467d3fe0be0, size=131040
[uc2n516:3833418] *** Process received signal ***
[uc2n516:3833418] Signal: Aborted (6)
[uc2n516:3833418] Signal code:  (-6)
[uc2n516:3833418] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x146c4bd4ddd0]
[uc2n516:3833418] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x146c4b9b070f]
[uc2n516:3833418] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x146c4b99ab25]
[uc2n516:3833418] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x146c4a91a375]
[uc2n516:3833418] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x146c4a9111e8]
[uc2n516:3833418] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_smcuda_prepare_src+0x126)[0x146c4a9690a6]
[uc2n516:3833418] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x146c578cc22b]
[uc2n516:3833418] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x146c578cf27c]
[uc2n516:3833418] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_smcuda_component_progress+0x507)[0x146c4a96b4c7]
[uc2n516:3833418] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x146c4a900a1b]
[uc2n516:3833418] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x146c4a906ef5]
[uc2n516:3833418] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x146c577438ea]
[uc2n516:3833418] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x1db)[0x146c577a877b]
[uc2n516:3833418] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x146c577b4702]
[uc2n516:3833418] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x146c5775642b]
[uc2n516:3833418] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE27All2All_Sync_FirstTransposeEPvb+0x9fa)[0x146c61e9801a]
[uc2n516:3833418] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x3d3)[0x146c61e965e3]
[uc2n516:3833418] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x146c620f865e]
[uc2n516:3833418] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x146c620f769f]
[uc2n516:3833418] [19] pencil[0x40326b]
[uc2n516:3833418] [20] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x146c4b99c6a3]
[uc2n516:3833418] [21] pencil[0x4035fe]
[uc2n516:3833418] *** End of error message ***
[uc2n516.localdomain:3833414] CUDA: Error in cuMemcpy: res=-1, dest=0x14630eacb038, src=0x145eb9fe0be0, size=131040
[uc2n516:3833414] *** Process received signal ***
[uc2n516:3833414] Signal: Aborted (6)
[uc2n516:3833414] Signal code:  (-6)
[uc2n516:3833414] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x146331bc6dd0]
[uc2n516:3833414] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x14633182970f]
[uc2n516:3833414] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x146331813b25]
[uc2n516:3833414] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x146330793375]
[uc2n516:3833414] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x14633078a1e8]
[uc2n516:3833414] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_smcuda_prepare_src+0x126)[0x1463307e20a6]
[uc2n516:3833414] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x14633d74522b]
[uc2n516:3833414] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x14633d74827c]
[uc2n516:3833414] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_smcuda_component_progress+0x507)[0x1463307e44c7]
[uc2n516:3833414] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x146330779a1b]
[uc2n516:3833414] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x14633077fef5]
[uc2n516:3833414] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x14633d5bc8ea]
[uc2n516:3833414] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x1db)[0x14633d62177b]
[uc2n516:3833414] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x14633d62d702]
[uc2n516:3833414] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x14633d5cf42b]
[uc2n516:3833414] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE27All2All_Sync_FirstTransposeEPvb+0x9fa)[0x146347d1101a]
[uc2n516:3833414] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x3d3)[0x146347d0f5e3]
[uc2n516:3833414] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x146347f7165e]
[uc2n516:3833414] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x146347f7069f]
[uc2n516:3833414] [19] pencil[0x40326b]
[uc2n516:3833414] [20] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x1463318156a3]
[uc2n516:3833414] [21] pencil[0x4035fe]
[uc2n516:3833414] *** End of error message ***
[uc2n514.localdomain:1897499] CUDA: Error in cuMemcpy: res=-1, dest=0x1463c5ac7038, src=0x145f8ffe0be0, size=131040
[uc2n514:1897499] *** Process received signal ***
[uc2n514:1897499] Signal: Aborted (6)
[uc2n514:1897499] Signal code:  (-6)
[uc2n514:1897499] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x1464069f0dd0]
[uc2n514:1897499] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x14640665370f]
[uc2n514:1897499] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x14640663db25]
[uc2n514:1897499] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x1464055bd375]
[uc2n514:1897499] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x1464055b41e8]
[uc2n514:1897499] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_smcuda_prepare_src+0x126)[0x14640560c0a6]
[uc2n514:1897499] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x14641256f22b]
[uc2n514:1897499] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x14641257227c]
[uc2n514:1897499] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_smcuda_component_progress+0x507)[0x14640560e4c7]
[uc2n514:1897499] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x1464055a3a1b]
[uc2n514:1897499] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x1464055a9ef5]
[uc2n514:1897499] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x1464123e68ea]
[uc2n514:1897499] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x1db)[0x14641244b77b]
[uc2n514:1897499] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x146412457702]
[uc2n514:1897499] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x1464123f942b]
[uc2n514:1897499] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE27All2All_Sync_FirstTransposeEPvb+0x9fa)[0x14641cb3b01a]
[uc2n514:1897499] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x3d3)[0x14641cb395e3]
[uc2n514:1897499] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x14641cd9b65e]
[uc2n514:1897499] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x14641cd9a69f]
[uc2n514:1897499] [19] pencil[0x40326b]
[uc2n514:1897499] [20] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x14640663f6a3]
[uc2n514:1897499] [21] pencil[0x4035fe]
[uc2n514:1897499] *** End of error message ***
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 0 with PID 0 on node uc2n514 exited on signal 6 (Aborted).
--------------------------------------------------------------------------
[uc2n514.localdomain:1897482] 3 more processes have sent help message help-mpi-common-cuda.txt / cuMemcpyAsync failed
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1897772] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1897772] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1898330] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1898330] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1898666] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1898666] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1898971] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1898971] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:1898990] CUDA: Error in cuMemcpy: res=1, dest=0x14bfe3b5a171, src=0x14bb93fe0be0, size=131040
[uc2n514:1898990] *** Process received signal ***
[uc2n514:1898990] Signal: Aborted (6)
[uc2n514:1898990] Signal code:  (-6)
[uc2n514:1898990] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x14c00aebfdd0]
[uc2n514:1898990] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x14c00ab2270f]
[uc2n514:1898990] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x14c00ab0cb25]
[uc2n514:1898990] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x14c009a8c375]
[uc2n514:1898990] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x14c009a831e8]
[uc2n514:1898990] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_openib_prepare_src+0x81)[0x14c009ade941]
[uc2n514:1898990] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x14c016a3e22b]
[uc2n514:1898990] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x14c016a4127c]
[uc2n514:1898990] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda31f)[0x14c009aea31f]
[uc2n514:1898990] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x14c009aeb1a6]
[uc2n514:1898990] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x14c009a72a1b]
[uc2n514:1898990] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x14c009a78ef5]
[uc2n514:1898990] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x14c0168b58ea]
[uc2n514:1898990] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x1db)[0x14c01691a77b]
[uc2n514:1898990] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x14c016926702]
[uc2n514:1898990] [15] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x14c0168c842b]
[uc2n514:1898990] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE28All2All_Sync_SecondTransposeEPvb+0x47b)[0x14c02100bd3b]
[uc2n514:1898990] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x45e)[0x14c02100866e]
[uc2n514:1898990] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x14c02126a65e]
[uc2n514:1898990] [19] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x14c02126969f]
[uc2n514:1898990] [20] pencil[0x40326b]
[uc2n514:1898990] [21] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x14c00ab0e6a3]
[uc2n514:1898990] [22] pencil[0x4035fe]
[uc2n514:1898990] *** End of error message ***
[uc2n514.localdomain:1898986] CUDA: Error in cuMemcpy: res=1, dest=0x154a12c0f131, src=0x1545c9fe0be0, size=131040
[uc2n514:1898986] *** Process received signal ***
[uc2n514:1898986] Signal: Aborted (6)
[uc2n514:1898986] Signal code:  (-6)
[uc2n514:1898986] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x154a420b0dd0]
[uc2n514:1898986] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x154a41d1370f]
[uc2n514:1898986] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x154a41cfdb25]
[uc2n514:1898986] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x154a40c7d375]
[uc2n514:1898986] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x154a40c741e8]
[uc2n514:1898986] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_openib_prepare_src+0x81)[0x154a40ccf941]
[uc2n514:1898986] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x154a4dc2f22b]
[uc2n514:1898986] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x154a4dc3227c]
[uc2n514:1898986] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda31f)[0x154a40cdb31f]
[uc2n514:1898986] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x154a40cdc1a6]
[uc2n514:1898986] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x154a40c63a1b]
[uc2n514:1898986] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x154a40c69ef5]
[uc2n514:1898986] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x154a4daa68ea]
[uc2n514:1898986] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x1db)[0x154a4db0b77b]
[uc2n514:1898986] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x154a4db17702]
[uc2n514:1898986] [15] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x154a4dab942b]
[uc2n514:1898986] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE28All2All_Sync_SecondTransposeEPvb+0x47b)[0x154a581fcd3b]
[uc2n514:1898986] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x45e)[0x154a581f966e]
[uc2n514:1898986] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x154a5845b65e]
[uc2n514:1898986] [19] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x154a5845a69f]
[uc2n514:1898986] [20] pencil[0x40326b]
[uc2n514:1898986] [21] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x154a41cff6a3]
[uc2n514:1898986] [22] pencil[0x4035fe]
[uc2n514:1898986] *** End of error message ***
--------------------------------------------------------------------------
The call to cuMemcpyAsync failed. This is a unrecoverable error and will
cause the program to abort.
  cuMemcpyAsync(0x1549d48671b8, 0x154583fe0be0, 131040) returned value 1
Check the cuda.h file for what the return value means.
--------------------------------------------------------------------------
[uc2n516.localdomain:3834923] CUDA: Error in cuMemcpy: res=-1, dest=0x1549d48671b8, src=0x154583fe0be0, size=131040
[uc2n516:3834923] *** Process received signal ***
[uc2n516:3834923] Signal: Aborted (6)
[uc2n516:3834923] Signal code:  (-6)
[uc2n516:3834923] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x1549fb427dd0]
[uc2n516:3834923] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x1549fb08a70f]
[uc2n516:3834923] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x1549fb074b25]
[uc2n516:3834923] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x1549f9ff4375]
[uc2n516:3834923] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x1549f9feb1e8]
[uc2n516:3834923] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_smcuda_prepare_src+0x126)[0x1549fa0430a6]
[uc2n516:3834923] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x154a06fa622b]
[uc2n516:3834923] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x154a06fa927c]
[uc2n516:3834923] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_smcuda_component_progress+0x507)[0x1549fa0454c7]
[uc2n516:3834923] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x1549f9fdaa1b]
[uc2n516:3834923] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x1549f9fe0ef5]
[uc2n516:3834923] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x154a06e1d8ea]
[uc2n516:3834923] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_base_alltoallv_intra_basic_linear+0x1db)[0x154a06e8277b]
[uc2n516:3834923] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_coll_tuned_alltoallv_intra_dec_fixed+0x42)[0x154a06e8e702]
[uc2n516:3834923] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallv+0x1ab)[0x154a06e3042b]
[uc2n516:3834923] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE28All2All_Sync_SecondTransposeEPvb+0x47b)[0x154a11573d3b]
[uc2n516:3834923] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x45e)[0x154a1157066e]
[uc2n516:3834923] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x154a117d265e]
[uc2n516:3834923] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x154a117d169f]
[uc2n516:3834923] [19] pencil[0x40326b]
[uc2n516:3834923] [20] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x1549fb0766a3]
[uc2n516:3834923] [21] pencil[0x4035fe]
[uc2n516:3834923] *** End of error message ***
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 4 with PID 0 on node uc2n514 exited on signal 6 (Aborted).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1899262] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1899262] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:1899275] CUDA: Error in cuMemcpy: res=1, dest=0x14757413f171, src=0x147119fe0be0, size=131040
[uc2n514:1899275] *** Process received signal ***
[uc2n514:1899275] Signal: Aborted (6)
[uc2n514:1899275] Signal code:  (-6)
[uc2n514:1899275] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x14758f913dd0]
[uc2n514:1899275] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x14758f57670f]
[uc2n514:1899275] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x14758f560b25]
[uc2n514:1899275] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x14758e4e0375]
[uc2n514:1899275] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x14758e4d71e8]
[uc2n514:1899275] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_openib_prepare_src+0x81)[0x14758e532941]
[uc2n514:1899275] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x14759b49222b]
[uc2n514:1899275] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x14759b49527c]
[uc2n514:1899275] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda31f)[0x14758e53e31f]
[uc2n514:1899275] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x14758e53f1a6]
[uc2n514:1899275] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x14758e4c6a1b]
[uc2n514:1899275] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x14758e4ccef5]
[uc2n514:1899275] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x14759b3098ea]
[uc2n514:1899275] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_coll_basic_alltoallw_intra+0x252)[0x14759b3adb32]
[uc2n514:1899275] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallw+0x1eb)[0x14759b31cccb]
[uc2n514:1899275] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE31All2All_MPIType_SecondTransposeEPvb+0x393)[0x1475a5a60443]
[uc2n514:1899275] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x45e)[0x1475a5a5c66e]
[uc2n514:1899275] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x1475a5cbe65e]
[uc2n514:1899275] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x1475a5cbd69f]
[uc2n514:1899275] [19] pencil[0x40326b]
[uc2n514:1899275] [20] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x14758f5626a3]
[uc2n514:1899275] [21] pencil[0x4035fe]
[uc2n514:1899275] *** End of error message ***
[uc2n514.localdomain:1899279] CUDA: Error in cuMemcpy: res=1, dest=0x146bf82a51b1, src=0x14679bfe0be0, size=131040
[uc2n514:1899279] *** Process received signal ***
[uc2n514:1899279] Signal: Aborted (6)
[uc2n514:1899279] Signal code:  (-6)
[uc2n514:1899279] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x146c135bedd0]
[uc2n514:1899279] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x146c1322170f]
[uc2n514:1899279] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x146c1320bb25]
[uc2n514:1899279] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x146c1218b375]
[uc2n514:1899279] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x146c121821e8]
[uc2n514:1899279] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_openib_prepare_src+0x81)[0x146c121dd941]
[uc2n514:1899279] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x146c1f13d22b]
[uc2n514:1899279] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x146c1f14027c]
[uc2n514:1899279] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xda31f)[0x146c121e931f]
[uc2n514:1899279] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0xdb1a6)[0x146c121ea1a6]
[uc2n514:1899279] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x146c12171a1b]
[uc2n514:1899279] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x146c12177ef5]
[uc2n514:1899279] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x146c1efb48ea]
[uc2n514:1899279] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_coll_basic_alltoallw_intra+0x252)[0x146c1f058b32]
[uc2n514:1899279] [14] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallw+0x1eb)[0x146c1efc7ccb]
[uc2n514:1899279] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE31All2All_MPIType_SecondTransposeEPvb+0x393)[0x146c2970b443]
[uc2n514:1899279] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x45e)[0x146c2970766e]
[uc2n514:1899279] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x146c2996965e]
[uc2n514:1899279] [18] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x146c2996869f]
[uc2n514:1899279] [19] pencil[0x40326b]
[uc2n514:1899279] [20] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x146c1320d6a3]
[uc2n514:1899279] [21] pencil[0x4035fe]
[uc2n514:1899279] *** End of error message ***
--------------------------------------------------------------------------
The call to cuMemcpyAsync failed. This is a unrecoverable error and will
cause the program to abort.
  cuMemcpyAsync(0x14d0240cc1b8, 0x14cbd5fe0be0, 131040) returned value 1
Check the cuda.h file for what the return value means.
--------------------------------------------------------------------------
[uc2n516.localdomain:3835207] CUDA: Error in cuMemcpy: res=-1, dest=0x14d0240cc1b8, src=0x14cbd5fe0be0, size=131040
[uc2n516:3835207] *** Process received signal ***
[uc2n516:3835207] Signal: Aborted (6)
[uc2n516:3835207] Signal code:  (-6)
[uc2n516:3835207] [ 0] /usr/lib64/libpthread.so.0(+0x12dd0)[0x14d04a579dd0]
[uc2n516:3835207] [ 1] /usr/lib64/libc.so.6(gsignal+0x10f)[0x14d04a1dc70f]
[uc2n516:3835207] [ 2] /usr/lib64/libc.so.6(abort+0x127)[0x14d04a1c6b25]
[uc2n516:3835207] [ 3] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(+0x7c375)[0x14d049146375]
[uc2n516:3835207] [ 4] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_convertor_pack+0xd8)[0x14d04913d1e8]
[uc2n516:3835207] [ 5] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_smcuda_prepare_src+0x126)[0x14d0491950a6]
[uc2n516:3835207] [ 6] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_pml_ob1_send_request_schedule_once+0x1bb)[0x14d0560f822b]
[uc2n516:3835207] [ 7] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(+0x20927c)[0x14d0560fb27c]
[uc2n516:3835207] [ 8] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(mca_btl_smcuda_component_progress+0x507)[0x14d0491974c7]
[uc2n516:3835207] [ 9] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(opal_progress+0x2b)[0x14d04912ca1b]
[uc2n516:3835207] [10] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libopen-pal.so.40(ompi_sync_wait_mt+0xb5)[0x14d049132ef5]
[uc2n516:3835207] [11] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(ompi_request_default_wait_all+0x3da)[0x14d055f6f8ea]
[uc2n516:3835207] [12] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(mca_coll_basic_alltoallw_intra+0x252)[0x14d056013b32]
[uc2n516:3835207] [13] /opt/bwhpc/common/mpi/openmpi/4.1.0-gnu-8.3.1/lib/libmpi.so.40(MPI_Alltoallw+0x1eb)[0x14d055f82ccb]
[uc2n516:3835207] [14] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE31All2All_MPIType_SecondTransposeEPvb+0x393)[0x14d0606c6443]
[uc2n516:3835207] [15] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_decomp.so(_ZN15MPIcuFFT_PencilIdE7execC2REPvPKvi+0x45e)[0x14d0606c266e]
[uc2n516:3835207] [16] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE9testcase2Eii+0x696)[0x14d06092465e]
[uc2n516:3835207] [17] /home/st/st_us-051200/st_st160727/DistributedFFT/build/libpencil_tests.so(_ZN22Tests_Pencil_Random_3DIdE3runEiii+0x67)[0x14d06092369f]
[uc2n516:3835207] [18] pencil[0x40326b]
[uc2n516:3835207] [19] /usr/lib64/libc.so.6(__libc_start_main+0xf3)[0x14d04a1c86a3]
[uc2n516:3835207] [20] pencil[0x4035fe]
[uc2n516:3835207] *** End of error message ***
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 0 with PID 0 on node uc2n514 exited on signal 6 (Aborted).
--------------------------------------------------------------------------
Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-16 19:21:15.482986
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-16 19:21:33.171895
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-16 19:21:42.394461
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-16 19:21:52.366609
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-16 19:22:01.101951
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-16 19:22:10.771043
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-16 19:22:19.593900
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-16 19:22:28.554232
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-16 19:22:37.551508
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-16 19:22:46.659321
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-16 19:22:55.646595
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-16 19:23:04.468605
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-16 19:23:14.212707
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-16 19:23:22.823064
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-16 19:23:32.697576
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-16 19:23:41.505660
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-16 19:23:50.523733
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-16 19:23:59.300516
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-16 19:24:08.382147
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-16 19:24:17.211338
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-16 19:24:26.159553
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-16 19:24:36.906439
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-16 19:24:45.846502
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-16 19:24:56.784192
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-16 19:25:05.723563
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-16 19:25:15.003245
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-16 19:25:24.390390
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-16 19:25:33.742847
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-16 19:25:42.963502
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-16 19:25:52.330861
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-16 19:26:05.282497
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-16 19:26:14.417326
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-16 19:26:26.907566
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-16 19:26:35.816100
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-16 19:26:44.955215
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-16 19:26:53.754881
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-16 19:27:02.846540
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-16 19:27:12.193592
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-16 19:27:21.621731
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-16 19:27:35.426658
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-16 19:27:44.669608
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-16 19:27:59.045773
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-16 19:28:08.426845
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-16 19:28:17.727750
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-16 19:28:26.940999
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-16 19:28:36.277851
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-16 19:28:46.377372
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-16 19:28:55.785283
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-16 19:29:12.573935
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-16 19:29:21.934256
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-16 19:29:38.513909
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-16 19:29:47.904453
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-16 19:29:57.419827
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-16 19:30:06.892731
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-16 19:30:16.690849
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-16 19:30:26.741074
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-16 19:30:36.573298
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-16 19:31:02.904161
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-16 19:31:12.709545
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-16 19:31:40.439699
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-16 19:31:50.190864
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-16 19:32:00.180848
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-16 19:32:09.877340
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-16 19:32:20.444113
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-16 19:32:31.273860
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-16 19:32:42.117567
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-16 19:33:09.562925
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-16 19:33:20.297570
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-16 19:33:46.788706
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-16 19:33:57.516432
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-16 19:34:08.595621
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-16 19:34:20.252140
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-16 19:34:32.201838
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-16 19:34:44.530566
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-16 19:34:56.476604
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-16 19:35:43.934102
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-16 19:35:56.086177
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-16 19:36:40.634743
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-16 19:36:52.786625
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-16 19:37:05.315675
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-16 19:37:18.099926
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-16 19:37:32.109697
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-16 19:37:49.655775
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-16 19:38:07.243032
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-16 19:39:31.427541
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-16 19:39:49.265613
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-16 19:41:10.202674
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-16 19:41:28.414681
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-16 19:41:44.424563
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-16 19:42:02.211943
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-16 19:42:21.632863
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-16 19:42:48.351967
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-16 19:43:16.050671
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-16 19:45:11.429791
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-16 19:45:38.051601
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-16 19:47:23.924047
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-16 19:47:50.732336
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-16 19:48:13.364883
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-16 19:48:40.258612
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-16 19:49:09.268326
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-16 19:49:52.872405
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-16 19:50:35.146645
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-16 19:54:25.262803
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-16 19:55:08.063596
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-16 19:58:41.399670
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-16 19:59:24.774561
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-16 19:59:59.458944
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-16 20:00:44.051659
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-16 20:01:31.373486
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-16 20:02:51.092584
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-16 20:04:10.199240
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-16 20:10:26.994131
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-16 20:10:45.556473
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-16 20:16:32.334237
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-16 20:17:51.486875
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-16 20:18:56.207746
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-16 20:19:09.749214
b''

Pencil Opt1 Inverse
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1899560] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1899560] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1899826] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1899826] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1900341] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1900341] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1900619] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1900619] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1900886] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1900886] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1901153] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1901153] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1901682] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1901682] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1901950] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1901950] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1902216] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1902216] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1902485] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1902485] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1902758] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1902758] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1903275] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1903275] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1903540] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1903540] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1903819] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1903819] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1904088] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1904088] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1904601] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1904601] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1904881] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1904881] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1905148] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1905148] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1905413] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1905413] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1905688] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1905688] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1906203] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1906203] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1906467] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1906467] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1906744] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1906744] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1907009] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1907009] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1907524] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1907524] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1907792] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1907792] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1908073] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1908073] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1908341] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1908341] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1908608] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1908608] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1909135] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1909135] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1909402] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1909402] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1909667] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1909667] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1909947] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1909947] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1910461] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1910461] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1910726] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1910726] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1911007] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1911007] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1911272] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1911272] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1911539] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1911539] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1912054] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1912054] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1912330] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1912330] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1912597] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1912597] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1912874] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1912874] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1913387] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1913387] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1913656] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1913656] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1913924] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1913924] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1914203] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1914203] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1914470] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1914470] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1914985] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1914985] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1915260] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1915260] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1915526] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1915526] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1915808] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1915808] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1916321] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1916321] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1916588] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1916588] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1916861] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1916861] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1917136] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1917136] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1917399] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1917399] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1917924] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1917924] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1918190] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1918190] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1918456] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1918456] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1918738] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1918738] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1919251] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1919251] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1919535] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1919535] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1919801] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1919801] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1920071] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1920071] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1920346] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1920346] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1920863] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1920863] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1921143] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1921143] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1921410] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1921410] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1921697] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1921697] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1922210] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1922210] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1922491] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1922491] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1922758] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1922758] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1923038] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1923038] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1923306] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1923306] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1923835] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1923835] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1924108] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1924108] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1924385] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1924385] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1924672] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1924672] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1925187] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1925187] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1925471] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1925471] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1925740] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1925740] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1926026] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1926026] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1926304] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1926304] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1926821] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1926821] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1927118] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1927118] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1927396] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1927396] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1927704] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1927704] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1928221] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1928221] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1928507] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1928507] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1928777] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1928777] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1929076] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1929076] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1929352] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1929352] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1929882] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1929882] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1930211] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1930211] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1930485] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1930485] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1930834] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1930834] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1931354] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1931354] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1931660] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1931660] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1931936] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1931936] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1932249] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1932249] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1932548] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1932548] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1933090] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1933090] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1933524] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1933524] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1933822] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1933822] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1934190] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1934190] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1934730] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1934730] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1935053] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1935053] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1935352] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1935352] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1935715] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1935715] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1936032] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1936032] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1936597] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1936597] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1937022] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1937022] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n516:3873509:0:3873509] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14d820400010)
[uc2n516:3873513:0:3873513] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1491a6400010)
[uc2n516:3873508:0:3873508] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x15409c400010)
[uc2n516:3873512:0:3873512] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x146c54400010)
[uc2n514:1937042:0:1937042] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14ff48400010)
[uc2n514:1937041:0:1937041] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e6b4400010)
[uc2n514:1937038:0:1937038] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x145010400010)
[uc2n514:1937037:0:1937037] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14dafc400010)
==== backtrace (tid:1937042) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002bbc5 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
18 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:1937041) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002bbc5 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
18 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:1937038) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002bbc5 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
18 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:1937037) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002bbc5 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
18 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3873509) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002bbc5 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
18 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3873508) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
==== backtrace (tid:3873512) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002bbc5 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
18 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002bbc5 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
18 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3873513) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002bbc5 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
18 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 6 with PID 0 on node uc2n514 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1937317] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1937317] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n516:3873817:0:3873817] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x147d46400000)
[uc2n516:3873821:0:3873821] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1468cc400000)
[uc2n516:3873818:0:3873818] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x154f46400000)
[uc2n516:3873822:0:3873822] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x147ace400000)
[uc2n514:1937340:0:1937340] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e9ee400000)
[uc2n514:1937344:0:1937344] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1490bc400000)
[uc2n514:1937339:0:1937339] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14f71c400000)
[uc2n514:1937343:0:1937343] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14eca0400000)
==== backtrace (tid:3873821) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c263 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3873817) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c263 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3873818) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c263 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3873822) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c263 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:1937344) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c263 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:1937340) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c263 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:1937343) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c263 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:1937339) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c263 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x000000000002a74b MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 7 with PID 0 on node uc2n514 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1937620] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1937620] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1938247] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1938247] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n516:3875093:0:3875093] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x152de0000010)
[uc2n516:3875088:0:3875088] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14fc40000010)
[uc2n516:3875090:0:3875090] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14b9fac00010)
[uc2n516:3875089:0:3875089] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14f3f6000010)
[uc2n516:3875092:0:3875092] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x149464000010)
[uc2n516:3875086:0:3875086] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1454e2800010)
[uc2n516:3875087:0:3875087] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c740000010)
[uc2n516:3875091:0:3875091] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14d582000010)
==== backtrace (tid:3875089) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002d85d MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
18 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3875087) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002d85d MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
18 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3875088) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002d85d MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
18 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3875092) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002d85d MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
18 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3875093) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002d85d MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
18 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3875090) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002d85d MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
18 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3875091) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002d85d MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
18 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3875086) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e98 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000003009e8 cudbgGetAPI()  ???:0
 5 0x0000000000435d90 cudbgApiInit()  ???:0
 6 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 7 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 9 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
10 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
11 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
12 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
13 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
14 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
15 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
16 0x000000000009042b PMPI_Alltoallv()  ???:0
17 0x000000000002d85d MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_SecondTranspose()  ???:0
18 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
19 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
20 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
21 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
22 0x000000000040326b main()  ???:0
23 0x00000000000236a3 __libc_start_main()  ???:0
24 0x00000000004035fe _start()  ???:0
=================================
[uc2n514.localdomain:1938581] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1938581] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 13 with PID 3875091 on node uc2n516 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n516:3875425:0:3875425] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x150832c00000)
[uc2n516:3875427:0:3875427] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x146bfe000000)
[uc2n516:3875421:0:3875421] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x149756800000)
[uc2n516:3875423:0:3875423] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14f8ac000000)
[uc2n516:3875422:0:3875422] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x146982000000)
[uc2n516:3875428:0:3875428] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x154be0000000)
[uc2n516:3875426:0:3875426] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14fb14000000)
[uc2n516:3875424:0:3875424] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c948000000)
==== backtrace (tid:3875425) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002ded3 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3875427) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002ded3 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3875421) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002ded3 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3875423) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002ded3 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3875422) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
==== backtrace (tid:3875424) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002ded3 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002ded3 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
10 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3875428) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002ded3 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3875426) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x0000000000073399 opal_convertor_unpack()  ???:0
 4 0x000000000008d817 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002ded3 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_SecondTranspose()  ???:0
 8 0x000000000002a545 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
 9 0x000000000001d249 MPIcuFFT_Pencil_Opt1<double>::execC2R()  ???:0
10 0x000000000002e65e Tests_Pencil_Random_3D<double>::testcase2()  ???:0
11 0x000000000002d69f Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
[uc2n514.localdomain:1938851] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1938851] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 13 with PID 3875426 on node uc2n516 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-16 20:19:25.439234
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-16 20:19:35.064255
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-16 20:19:43.981914
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-16 20:19:54.005836
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-16 20:20:02.771163
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-16 20:20:12.109191
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-16 20:20:20.764615
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-16 20:20:29.760019
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-16 20:20:38.321633
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-16 20:20:47.494092
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-16 20:20:56.143302
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-16 20:21:04.823034
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-16 20:21:14.488846
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-16 20:21:25.332556
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-16 20:21:35.374523
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-16 20:21:44.109770
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-16 20:21:53.145722
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-16 20:22:03.541186
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-16 20:22:13.471434
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-16 20:22:22.210745
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-16 20:22:31.001217
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-16 20:22:40.428434
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-16 20:22:49.463840
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-16 20:22:59.204085
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-16 20:23:07.910178
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-16 20:23:17.458089
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-16 20:23:26.105571
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-16 20:23:35.667983
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-16 20:23:44.544633
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-16 20:23:53.170392
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-16 20:24:03.332737
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-16 20:24:12.162080
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-16 20:24:23.013794
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-16 20:24:31.760229
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-16 20:24:41.179968
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-16 20:24:49.901830
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-16 20:24:59.879196
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-16 20:25:08.641897
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-16 20:25:17.459018
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-16 20:25:29.028908
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-16 20:25:37.905974
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-16 20:25:50.741997
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-16 20:25:59.420636
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-16 20:26:09.624282
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-16 20:26:18.536576
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-16 20:26:29.800174
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-16 20:26:38.692515
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-16 20:26:47.752518
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-16 20:26:59.611275
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-16 20:27:08.512805
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-16 20:27:20.977425
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-16 20:27:29.551833
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-16 20:27:40.600867
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-16 20:27:49.112994
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-16 20:28:02.542814
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-16 20:28:11.385277
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-16 20:28:20.222986
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-16 20:28:34.733989
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-16 20:28:43.620964
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-16 20:29:00.642099
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-16 20:29:14.388231
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-16 20:29:25.685826
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-16 20:29:34.615652
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-16 20:29:48.283603
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-16 20:29:58.279435
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-16 20:30:07.717126
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-16 20:30:28.695049
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-16 20:30:38.466683
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-16 20:31:04.749465
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-16 20:31:14.363655
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-16 20:31:28.866034
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-16 20:31:38.446758
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-16 20:31:57.761702
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-16 20:32:09.065086
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-16 20:32:21.732590
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-16 20:32:44.984396
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-16 20:32:55.968005
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-16 20:33:24.692379
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-16 20:33:35.437016
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-16 20:33:56.214223
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-16 20:34:07.016460
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-16 20:34:37.253560
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-16 20:34:52.983531
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-16 20:35:08.426166
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-16 20:35:47.767301
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-16 20:36:03.742424
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-16 20:36:53.763751
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-16 20:37:09.247914
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-16 20:37:32.316208
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-16 20:37:48.342395
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-16 20:38:22.214100
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-16 20:38:46.630820
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-16 20:39:11.765171
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-16 20:40:23.542760
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-16 20:40:48.469537
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-16 20:42:20.933560
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-16 20:42:45.258139
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-16 20:43:23.212122
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-16 20:43:47.950158
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-16 20:44:47.357145
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-16 20:45:28.774734
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-16 20:46:10.567070
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-16 20:47:46.519202
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-16 20:48:28.930703
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-16 20:50:31.253756
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-16 20:51:12.353800
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-16 20:52:19.911271
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-16 20:53:01.751616
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-16 20:54:52.598992
b''

-> Executing test 1
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-16 20:56:06.995158
b''

-> Executing test 2
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-16 20:57:20.020673
b''

-> Executing test 3
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-16 21:00:22.450941
b''

-> Executing test 4
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-16 21:00:31.176746
b''

-> Executing test 5
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-16 21:00:41.737063
b''

-> Executing test 6
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-16 21:01:56.950238
b''

-> Executing test 7
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-16 21:03:25.614113
b''

-> Executing test 8
mpiexec -n 16 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 4 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-16 21:03:36.828905
b''

Partition 2x8
-----------------------------------------------------------------------------
Pencil Default
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1939120] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1939120] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1939396] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1939396] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1939910] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1939910] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1940175] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1940175] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1940454] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1940454] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1940721] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1940721] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1941234] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1941234] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1941501] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1941501] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1941776] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1941776] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1942044] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1942044] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1942307] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1942307] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1942838] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1942838] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1943104] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1943104] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1943371] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1943371] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1943648] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1943648] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1944161] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1944161] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1944429] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1944429] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1944697] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1944697] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1944972] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1944972] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1945240] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1945240] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1945751] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1945751] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1946034] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1946034] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1946301] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1946301] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1946568] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1946568] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1947095] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1947095] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1947361] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1947361] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1947622] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1947622] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1947899] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1947899] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1948164] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1948164] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1948679] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1948679] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1948962] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1948962] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1949227] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1949227] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1949507] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1949507] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1950024] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1950024] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1950291] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1950291] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1950554] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1950554] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1950830] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1950830] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1951099] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1951099] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1951612] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1951612] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1951896] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1951896] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1952163] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1952163] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1952444] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1952444] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1952958] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1952958] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1953224] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1953224] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1953501] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1953501] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1953768] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1953768] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1954036] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1954036] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1954559] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1954559] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1954837] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1954837] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1955114] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1955114] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1955389] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1955389] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1955912] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1955912] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1956179] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1956179] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1956443] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1956443] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1956724] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1956724] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1956991] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1956991] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1957506] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1957506] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1957807] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1957807] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1958074] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1958074] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1958366] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1958366] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1958891] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1958891] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1959156] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1959156] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1959423] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1959423] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1959702] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1959702] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1959969] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1959969] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1960487] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1960487] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1960789] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1960789] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1961056] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1961056] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1961347] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1961347] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1961878] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1961878] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1962145] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1962145] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1962422] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1962422] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1962693] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1962693] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1962964] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1962964] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1963486] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1963486] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1963807] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1963807] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1964084] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1964084] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1964398] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1964398] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1964930] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1964930] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1965199] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1965199] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1965486] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1965486] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1965756] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1965756] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1966039] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1966039] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1966567] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1966567] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1966942] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1966942] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1967226] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1967226] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1967611] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1967611] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1968133] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1968133] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1968414] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1968414] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1968694] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1968694] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1968985] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1968985] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1969274] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1969274] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1969808] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1969808] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1970199] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1970199] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1970489] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1970489] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1970874] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1970874] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1971424] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1971424] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1971719] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1971719] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1972010] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1972010] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1972317] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1972317] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1972631] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1972631] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1973178] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1973178] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1973687] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1973687] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1973997] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1973997] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1974503] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1974503] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1975066] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1975066] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1975381] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1975381] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1975689] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1975689] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1976025] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1976025] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:1976038] *** An error occurred in MPI_Irecv
[uc2n514:1976038] *** reported by process [3047882753,0]
[uc2n514:1976038] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:1976038] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:1976038] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:1976038] ***    and potentially your MPI job)
[uc2n514.localdomain:1976025] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1976286] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1976286] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:1976311] *** An error occurred in MPI_Irecv
[uc2n514:1976311] *** reported by process [3031171073,6]
[uc2n514:1976311] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:1976311] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:1976311] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:1976311] ***    and potentially your MPI job)
[uc2n514.localdomain:1976286] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1976577] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1976577] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n516:3913793] *** An error occurred in MPI_Irecv
[uc2n516:3913793] *** reported by process [3128098817,14]
[uc2n516:3913793] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n516:3913793] *** MPI_ERR_COUNT: invalid count argument
[uc2n516:3913793] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n516:3913793] ***    and potentially your MPI job)
[uc2n514.localdomain:1976577] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1976867] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1976867] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:1976879] *** An error occurred in MPI_Irecv
[uc2n514:1976879] *** reported by process [3109093377,0]
[uc2n514:1976879] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:1976879] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:1976879] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:1976879] ***    and potentially your MPI job)
[uc2n514.localdomain:1976867] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1977144] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1977144] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n516:3914369] *** An error occurred in MPI_Irecv
[uc2n516:3914369] *** reported by process [3091857409,9]
[uc2n516:3914369] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n516:3914369] *** MPI_ERR_COUNT: invalid count argument
[uc2n516:3914369] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n516:3914369] ***    and potentially your MPI job)
[uc2n514.localdomain:1977144] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1977435] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1977435] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n516:3914659] *** An error occurred in MPI_Irecv
[uc2n516:3914659] *** reported by process [3207135233,9]
[uc2n516:3914659] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n516:3914659] *** MPI_ERR_COUNT: invalid count argument
[uc2n516:3914659] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n516:3914659] ***    and potentially your MPI job)
[uc2n514.localdomain:1977435] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1977710] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1977710] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n516:3914947] *** An error occurred in MPI_Irecv
[uc2n516:3914947] *** reported by process [3189506049,13]
[uc2n516:3914947] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n516:3914947] *** MPI_ERR_COUNT: invalid count argument
[uc2n516:3914947] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n516:3914947] ***    and potentially your MPI job)
[uc2n514.localdomain:1977710] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1977981] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1977981] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n516:3915228] *** An error occurred in MPI_Alltoallv
[uc2n516:3915228] *** reported by process [3171876865,8]
[uc2n516:3915228] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n516:3915228] *** MPI_ERR_COUNT: invalid count argument
[uc2n516:3915228] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n516:3915228] ***    and potentially your MPI job)
[uc2n514.localdomain:1977981] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1978263] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1978263] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n516:3915505] *** An error occurred in MPI_Alltoallw
[uc2n516:3915505] *** reported by process [3169124353,10]
[uc2n516:3915505] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n516:3915505] *** MPI_ERR_COUNT: invalid count argument
[uc2n516:3915505] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n516:3915505] ***    and potentially your MPI job)
[uc2n514.localdomain:1978263] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1978530] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1978530] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1978809] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1978809] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1979101] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1979101] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1979365] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1979365] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1979640] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1979640] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1979904] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1979904] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1980187] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1980187] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1980454] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1980454] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1980733] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1980733] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1981000] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1981000] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1981267] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1981267] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1981570] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1981570] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1981838] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1981838] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1982103] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1982103] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1982378] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1982378] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1982658] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1982658] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1982924] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1982924] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1983191] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1983191] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1983471] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1983471] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1983781] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1983781] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1984070] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1984070] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1984349] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1984349] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1984618] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1984618] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1984887] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1984887] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1985180] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1985180] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1985447] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1985447] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1985715] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1985715] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1985994] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1985994] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1986267] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1986267] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1986573] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1986573] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1986864] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1986864] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1987147] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1987147] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1987432] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1987432] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1987720] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1987720] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1988001] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1988001] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1988287] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1988287] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1988558] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1988558] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 0 with PID 0 on
node uc2n514 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1988838] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1988838] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 15 with PID 3926274 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1989116] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1989116] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:1989132] *** An error occurred in MPI_Irecv
[uc2n514:1989132] *** reported by process [3398303745,3]
[uc2n514:1989132] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:1989132] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:1989132] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:1989132] ***    and potentially your MPI job)
[uc2n514.localdomain:1989116] 2 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1989462] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1989462] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 14 with PID 3926921 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1989751] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1989751] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:1989780] *** An error occurred in MPI_Irecv
[uc2n514:1989780] *** reported by process [3473211393,3]
[uc2n514:1989780] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:1989780] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:1989780] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:1989780] ***    and potentially your MPI job)
[uc2n514.localdomain:1989751] 2 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1990105] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1990105] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 14 with PID 3927576 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1990392] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1990392] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 15 with PID 3927854 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1990678] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1990678] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 15 with PID 3928141 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1990950] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1990950] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 6 with PID 0 on
node uc2n514 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128
2021-09-16 21:03:48.049815
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128
2021-09-16 21:03:56.329058
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128
2021-09-16 21:04:04.603158
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128
2021-09-16 21:04:14.746088
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128
2021-09-16 21:04:22.979020
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128
2021-09-16 21:04:33.399947
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128
2021-09-16 21:04:41.674282
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128
2021-09-16 21:04:49.937531
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128
2021-09-16 21:04:58.244318
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 256
2021-09-16 21:05:06.551641
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 256
2021-09-16 21:05:14.984698
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 256
2021-09-16 21:05:24.288138
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 256
2021-09-16 21:05:34.682928
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 256
2021-09-16 21:05:43.050843
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 256
2021-09-16 21:05:53.532133
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 256
2021-09-16 21:06:01.974679
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 256
2021-09-16 21:06:10.403924
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 256
2021-09-16 21:06:19.054577
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 256 -nz 256
2021-09-16 21:06:28.077931
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 256 -nz 256
2021-09-16 21:06:37.075182
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 256 -nz 256
2021-09-16 21:06:46.196876
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 256 -nz 256
2021-09-16 21:06:58.961804
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 256 -nz 256
2021-09-16 21:07:07.400095
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 256 -nz 256
2021-09-16 21:07:20.294242
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 256 -nz 256
2021-09-16 21:07:28.734365
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 256 -nz 256
2021-09-16 21:07:37.111101
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 256 -nz 256
2021-09-16 21:07:45.498480
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256
2021-09-16 21:07:54.025468
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256
2021-09-16 21:08:02.549384
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256
2021-09-16 21:08:11.008696
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256
2021-09-16 21:08:27.258141
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256
2021-09-16 21:08:35.761513
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256
2021-09-16 21:08:52.231314
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256
2021-09-16 21:09:00.792614
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256
2021-09-16 21:09:09.268206
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256
2021-09-16 21:09:17.649479
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 512
2021-09-16 21:09:26.196060
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 512
2021-09-16 21:09:34.973056
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 512
2021-09-16 21:09:43.737351
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 512
2021-09-16 21:10:00.746325
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 512
2021-09-16 21:10:09.522194
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 512
2021-09-16 21:10:26.952776
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 512
2021-09-16 21:10:35.747163
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 512
2021-09-16 21:10:44.481243
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 512
2021-09-16 21:10:53.817816
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 512 -nz 512
2021-09-16 21:11:02.756155
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 512 -nz 512
2021-09-16 21:11:12.151448
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 512 -nz 512
2021-09-16 21:11:21.555354
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 512 -nz 512
2021-09-16 21:11:45.379860
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 512 -nz 512
2021-09-16 21:11:54.391486
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 512 -nz 512
2021-09-16 21:12:18.627028
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 512 -nz 512
2021-09-16 21:12:27.700280
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 512 -nz 512
2021-09-16 21:12:36.777309
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 512 -nz 512
2021-09-16 21:12:45.818625
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512
2021-09-16 21:12:55.248183
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512
2021-09-16 21:13:05.021125
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512
2021-09-16 21:13:15.016603
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512
2021-09-16 21:13:54.768205
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512
2021-09-16 21:14:04.554309
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512
2021-09-16 21:14:43.453540
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512
2021-09-16 21:14:53.147680
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512
2021-09-16 21:15:03.014685
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512
2021-09-16 21:15:12.787469
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 1024
2021-09-16 21:15:23.228094
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 1024
2021-09-16 21:15:35.472433
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 1024
2021-09-16 21:15:48.765402
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 1024
2021-09-16 21:16:29.555852
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 1024
2021-09-16 21:16:40.799654
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 1024
2021-09-16 21:17:21.092832
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 1024
2021-09-16 21:17:32.382147
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 1024
2021-09-16 21:17:43.660612
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 1024
2021-09-16 21:17:55.003235
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 1024 -nz 1024
2021-09-16 21:18:07.990957
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 1024 -nz 1024
2021-09-16 21:18:21.953089
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 1024 -nz 1024
2021-09-16 21:18:36.024561
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 1024 -nz 1024
2021-09-16 21:19:49.104697
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 1024 -nz 1024
2021-09-16 21:20:03.676583
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 1024 -nz 1024
2021-09-16 21:21:16.357165
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 1024 -nz 1024
2021-09-16 21:21:31.036668
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 1024 -nz 1024
2021-09-16 21:21:45.360064
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 1024 -nz 1024
2021-09-16 21:21:59.549349
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024
2021-09-16 21:22:17.104214
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024
2021-09-16 21:22:38.765475
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024
2021-09-16 21:23:00.101960
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024
2021-09-16 21:25:18.939082
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024
2021-09-16 21:25:41.048524
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024
2021-09-16 21:27:58.722664
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024
2021-09-16 21:28:20.446271
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024
2021-09-16 21:28:42.219785
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024
2021-09-16 21:29:04.349509
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 2048
2021-09-16 21:29:34.980066
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 2048
2021-09-16 21:30:09.232660
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 2048
2021-09-16 21:30:44.303729
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 2048
2021-09-16 21:33:17.498096
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 2048
2021-09-16 21:33:52.071404
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 2048
2021-09-16 21:36:21.793344
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 2048
2021-09-16 21:36:57.442283
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 2048
2021-09-16 21:37:32.601051
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 2048
2021-09-16 21:38:08.244070
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 2048 -nz 2048
2021-09-16 21:38:55.666110
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 2048 -nz 2048
2021-09-16 21:39:54.465539
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 2048 -nz 2048
2021-09-16 21:40:52.105841
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 2048 -nz 2048
2021-09-16 21:45:46.840217
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 2048 -nz 2048
2021-09-16 21:46:45.748341
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 2048 -nz 2048
2021-09-16 21:51:33.048324
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 2048 -nz 2048
2021-09-16 21:52:32.148040
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 2048 -nz 2048
2021-09-16 21:53:30.978199
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 2048 -nz 2048
2021-09-16 21:54:30.675092
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048
2021-09-16 21:55:55.375707
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048
2021-09-16 21:56:04.834664
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048
2021-09-16 21:56:18.065404
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048
2021-09-16 21:56:46.549415
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048
2021-09-16 21:56:58.998285
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048
2021-09-16 21:57:26.894459
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048
2021-09-16 21:57:39.894095
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048
2021-09-16 21:57:53.032753
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048
2021-09-16 21:58:06.233228
b''

Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 21:58:19.255282
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 21:58:29.347618
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 21:58:37.899008
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 21:58:47.312488
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 21:58:56.155221
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 21:59:04.674291
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 21:59:15.057427
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 21:59:24.239353
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 21:59:33.413129
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 21:59:41.719504
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 21:59:50.226716
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 21:59:58.835546
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 22:00:07.923672
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 22:00:17.024883
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 22:00:26.226881
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 22:00:34.645827
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 22:00:43.236435
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 22:00:51.677096
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 22:01:00.287671
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 22:01:10.510562
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 22:01:20.582034
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 22:01:32.251388
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 22:01:42.105614
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 22:01:53.780628
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 22:02:03.618007
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 22:02:13.339640
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 22:02:23.109036
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 22:02:32.880440
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 22:02:53.473653
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 22:03:13.764389
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 22:03:41.773502
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 22:04:02.258970
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 22:04:31.331166
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 22:04:52.081347
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 22:05:12.821553
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 22:05:33.389858
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 22:05:54.249222
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 22:06:10.243086
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 22:06:28.397440
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 22:08:18.938802
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 22:08:49.006522
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 22:10:39.552990
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 22:11:09.682364
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 22:11:31.886263
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 22:11:54.050852
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:727\n'

Pencil Opt1
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1991231] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1991231] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1991509] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1991509] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1991776] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1991776] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1992042] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1992042] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1992312] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1992312] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1992592] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1992592] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1992859] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1992859] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1993125] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1993125] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1993406] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1993406] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1993675] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1993675] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1993941] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1993941] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1994215] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1994215] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1994484] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1994484] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1994749] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1994749] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1995030] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1995030] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1995295] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1995295] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1995562] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1995562] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1995829] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1995829] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1996106] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1996106] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1996374] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1996374] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1996639] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1996639] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1996920] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1996920] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1997187] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1997187] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1997452] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1997452] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1997736] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1997736] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1998003] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1998003] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1998266] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1998266] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1998544] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1998544] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1998811] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1998811] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1999078] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1999078] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1999355] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1999355] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1999622] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1999622] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:1999891] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:1999891] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2000173] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2000173] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2000438] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2000438] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2000707] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2000707] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2000975] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2000975] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2001250] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2001250] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2001517] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2001517] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2001796] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2001796] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2002059] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2002059] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2002329] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2002329] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2002611] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2002611] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2002880] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2002880] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2003145] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2003145] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2003425] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2003425] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2003691] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2003691] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2003956] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2003956] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2004236] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2004236] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2004501] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2004501] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2004785] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2004785] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2005051] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2005051] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2005318] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2005318] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2005591] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2005591] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2005861] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2005861] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2006141] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2006141] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2006408] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2006408] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2006694] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2006694] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2006961] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2006961] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2007241] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2007241] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2007508] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2007508] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2007788] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2007788] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2008055] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2008055] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2008323] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2008323] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2008606] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2008606] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2008873] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2008873] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2009160] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2009160] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2009435] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2009435] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2009732] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2009732] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2010013] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2010013] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2010284] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2010284] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2010563] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2010563] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2010833] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2010833] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2011115] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2011115] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2011386] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2011386] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2011690] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2011690] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2011957] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2011957] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2012251] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2012251] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2012531] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2012531] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2012814] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2012814] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2013081] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2013081] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2013386] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2013386] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2013658] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2013658] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2013943] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2013943] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2014263] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2014263] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2014544] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2014544] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2014875] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2014875] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2015147] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2015147] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2015448] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2015448] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2015718] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2015718] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2016029] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2016029] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2016314] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2016314] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2016603] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2016603] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2016986] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2016986] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2017275] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2017275] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2017661] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2017661] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2017947] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2017947] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2018261] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2018261] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2018551] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2018551] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2018886] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2018886] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2019199] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2019199] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2019513] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2019513] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2019900] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2019900] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2020214] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2020214] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2020623] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2020623] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2020924] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2020924] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2021283] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2021283] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2021595] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2021595] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2022105] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2022105] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n516:3960053] *** An error occurred in MPI_Irecv
[uc2n516:3960053] *** reported by process [1235943425,11]
[uc2n516:3960053] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n516:3960053] *** MPI_ERR_COUNT: invalid count argument
[uc2n516:3960053] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n516:3960053] ***    and potentially your MPI job)
[uc2n514.localdomain:2022105] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2022374] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2022374] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:2022393] *** An error occurred in MPI_Irecv
[uc2n514:2022393] *** reported by process [1217658881,7]
[uc2n514:2022393] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2022393] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2022393] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2022393] ***    and potentially your MPI job)
[uc2n514.localdomain:2022374] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2022642] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2022642] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:2022657] *** An error occurred in MPI_Irecv
[uc2n514:2022657] *** reported by process [1333788673,3]
[uc2n514:2022657] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2022657] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2022657] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2022657] ***    and potentially your MPI job)
[uc2n514.localdomain:2022642] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2022968] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2022968] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:2022986:0:2022986] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x145850400010)
[uc2n514:2022984:0:2022984] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14c266400010)
[uc2n514:2022987:0:2022987] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14928e400010)
[uc2n514:2022985:0:2022985] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x153ce4400010)
[uc2n516:3960930:0:3960930] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14b060400010)
[uc2n516:3960929:0:3960929] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x146394400010)
[uc2n516:3960928:0:3960928] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x147e1c400010)
[uc2n516:3960927:0:3960927] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x150cc4400010)
[uc2n514:2022982:0:2022982] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14e614400000)
[uc2n514:2022980:0:2022980] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x145300400000)
[uc2n514:2022981:0:2022981] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14d436400000)
[uc2n514:2022983:0:2022983] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14fd3c400000)
==== backtrace (tid:2022987) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
==== backtrace (tid:2022985) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:2022984) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:2022986) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
[uc2n516:3960925:0:3960925] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14f150400000)
[uc2n516:3960923:0:3960923] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x153d82400000)
[uc2n516:3960924:0:3960924] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14cb70400000)
[uc2n516:3960926:0:3960926] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1460d8400000)
==== backtrace (tid:2022980) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:2022982) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:2022981) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:2022983) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3960924) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3960926) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3960925) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3960923) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3960930) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3960928) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3960927) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3960929) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 4 with PID 0 on node uc2n514 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2023291] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2023291] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n516:3961266:0:3961266] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14bbd4400000)
[uc2n516:3961264:0:3961264] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14d9e4400000)
[uc2n516:3961267:0:3961267] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14bac4400000)
[uc2n516:3961265:0:3961265] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x15062e400000)
[uc2n514:2023316:0:2023316] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14607c400000)
[uc2n514:2023315:0:2023315] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14ff74400000)
[uc2n514:2023314:0:2023314] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1502f4400000)
[uc2n514:2023313:0:2023313] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14bb4c400000)
==== backtrace (tid:3961266) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3961267) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3961265) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:3961264) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:2023316) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:2023314) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
==== backtrace (tid:2023315) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
=================================
==== backtrace (tid:2023313) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 5 with PID 0 on node uc2n514 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2023599] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2023599] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:2023623] *** An error occurred in MPI_Irecv
[uc2n514:2023623] *** reported by process [1943863297,6]
[uc2n514:2023623] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2023623] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2023623] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2023623] ***    and potentially your MPI job)
[uc2n514.localdomain:2023599] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2023872] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2023872] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n516:3961844] *** An error occurred in MPI_Isend
[uc2n516:3961844] *** reported by process [1924268033,11]
[uc2n516:3961844] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n516:3961844] *** MPI_ERR_COUNT: invalid count argument
[uc2n516:3961844] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n516:3961844] ***    and potentially your MPI job)
[uc2n514.localdomain:2023872] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2024150] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2024150] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n516:3962124] *** An error occurred in MPI_Alltoallv
[uc2n516:3962124] *** reported by process [1906573313,8]
[uc2n516:3962124] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n516:3962124] *** MPI_ERR_COUNT: invalid count argument
[uc2n516:3962124] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n516:3962124] ***    and potentially your MPI job)
[uc2n514.localdomain:2024150] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2024419] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2024419] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n516:3962403] *** An error occurred in MPI_Alltoallw
[uc2n516:3962403] *** reported by process [1888550913,13]
[uc2n516:3962403] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n516:3962403] *** MPI_ERR_COUNT: invalid count argument
[uc2n516:3962403] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n516:3962403] ***    and potentially your MPI job)
[uc2n514.localdomain:2024419] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2024684] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2024684] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2024964] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2024964] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2025246] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2025246] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2025511] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2025511] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2025790] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2025790] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2026057] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2026057] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2026340] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2026340] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2026619] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2026619] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2026885] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2026885] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2027152] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2027152] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2027417] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2027417] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2027712] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2027712] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2027979] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2027979] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2028244] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2028244] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2028523] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2028523] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2028804] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2028804] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2029071] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2029071] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2029347] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2029347] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2029613] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2029613] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2029878] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2029878] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2030163] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2030163] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2030444] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2030444] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2030711] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2030711] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2030987] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2030987] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2031268] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2031268] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2031537] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2031537] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2031813] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2031813] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2032082] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2032082] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2032369] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2032369] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2032654] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2032654] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2032941] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2032941] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2033221] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2033221] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2033508] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2033508] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2033793] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2033793] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2034076] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2034076] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2034357] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2034357] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2034631] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2034631] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:2034644] *** An error occurred in MPI_Irecv
[uc2n514:2034644] *** reported by process [2561933313,0]
[uc2n514:2034644] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2034644] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2034644] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2034644] ***    and potentially your MPI job)
[uc2n514.localdomain:2034631] 7 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2034966] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2034966] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:2035000] *** An error occurred in MPI_Irecv
[uc2n514:2035000] *** reported by process [2657419265,0]
[uc2n514:2035000] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2035000] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2035000] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2035000] ***    and potentially your MPI job)
[uc2n514.localdomain:2034966] 7 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2035320] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2035320] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:2035359] *** An error occurred in MPI_Irecv
[uc2n514:2035359] *** reported by process [2634743809,3]
[uc2n514:2035359] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2035359] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2035359] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2035359] ***    and potentially your MPI job)
[uc2n514.localdomain:2035320] 5 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2035678] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2035678] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:2035705:0:2035705] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x147bc0400010)
==== backtrace (tid:2035705) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
20 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
[uc2n514:2035702:0:2035702] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14a266400010)
==== backtrace (tid:2035702) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
20 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[uc2n516:3973887:0:3973887] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x149b8c400010)
==== backtrace (tid:3973887) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
20 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
[uc2n516:3973890:0:3973890] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x144ef0400010)
==== backtrace (tid:3973890) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
20 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
mpiexec noticed that process rank 7 with PID 0 on node uc2n514 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2036034] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2036034] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:2036062:0:2036062] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x153040400000)
==== backtrace (tid:2036062) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
11 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
[uc2n514:2036059:0:2036059] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14d1d0400000)
==== backtrace (tid:2036059) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
11 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[uc2n516:3974254:0:3974254] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1517f4400000)
==== backtrace (tid:3974254) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x0000000000030a71 Tests_Pencil_Random_3D<double>::testcase4()  ???:0
11 0x000000000002d6d7 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
mpiexec noticed that process rank 7 with PID 0 on node uc2n514 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2036397] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2036397] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:2036424] *** An error occurred in MPI_Irecv
[uc2n514:2036424] *** reported by process [2178809857,7]
[uc2n514:2036424] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2036424] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2036424] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2036424] ***    and potentially your MPI job)
[uc2n514.localdomain:2036397] 7 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2036740] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2036740] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:2036769] *** An error occurred in MPI_Isend
[uc2n514:2036769] *** reported by process [2272722945,0]
[uc2n514:2036769] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2036769] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2036769] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2036769] ***    and potentially your MPI job)
[uc2n514.localdomain:2036740] 7 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2037094] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2037094] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:2037114] *** An error occurred in MPI_Alltoallv
[uc2n514:2037114] *** reported by process [2249523201,0]
[uc2n514:2037114] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2037114] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2037114] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2037114] ***    and potentially your MPI job)
[uc2n514.localdomain:2037094] 12 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2037436] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2037436] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:2037471] *** An error occurred in MPI_Alltoallw
[uc2n514:2037471] *** reported by process [2244935681,0]
[uc2n514:2037471] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2037471] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2037471] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2037471] ***    and potentially your MPI job)
[uc2n514.localdomain:2037436] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-16 22:12:17.174855
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-16 22:12:28.263812
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-16 22:12:36.521122
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-16 22:12:45.537789
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-16 22:12:53.948227
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-16 22:13:03.627252
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-16 22:13:12.276550
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-16 22:13:21.177187
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-16 22:13:29.883303
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-16 22:13:38.989013
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-16 22:13:47.749386
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-16 22:13:56.412724
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-16 22:14:06.696841
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-16 22:14:15.423099
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-16 22:14:25.992239
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-16 22:14:34.783473
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-16 22:14:43.892873
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-16 22:14:52.694301
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-16 22:15:01.909486
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-16 22:15:10.464663
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-16 22:15:19.228437
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-16 22:15:29.472379
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-16 22:15:38.644833
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-16 22:15:49.204628
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-16 22:15:58.148756
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-16 22:16:07.515580
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-16 22:16:16.160976
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-16 22:16:26.199110
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-16 22:16:35.091062
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-16 22:16:43.836256
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-16 22:16:56.262174
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-16 22:17:04.953769
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-16 22:17:17.517468
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-16 22:17:26.139019
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-16 22:17:35.669925
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-16 22:17:44.793251
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-16 22:17:54.868945
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-16 22:18:03.679756
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-16 22:18:12.542835
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-16 22:18:27.214621
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-16 22:18:36.145657
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-16 22:18:52.234990
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-16 22:19:01.196255
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-16 22:19:11.793163
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-16 22:19:20.778949
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-16 22:19:32.234349
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-16 22:19:41.477385
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-16 22:19:50.798425
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-16 22:20:06.589566
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-16 22:20:15.645134
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-16 22:20:32.489376
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-16 22:20:41.659328
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-16 22:20:54.404099
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-16 22:21:03.742528
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-16 22:21:18.441928
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-16 22:21:28.245232
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-16 22:21:38.097790
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-16 22:22:01.661447
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-16 22:22:11.476843
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-16 22:22:36.079469
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-16 22:22:45.988256
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-16 22:22:59.534909
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-16 22:23:09.543307
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-16 22:23:25.381646
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-16 22:23:36.576847
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-16 22:23:47.875883
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-16 22:24:24.862222
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-16 22:24:36.036028
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-16 22:25:15.598550
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-16 22:25:26.739557
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-16 22:25:45.461876
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-16 22:25:56.619917
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-16 22:26:19.544242
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-16 22:26:33.288783
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-16 22:26:46.933389
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-16 22:27:28.003863
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-16 22:27:41.778192
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-16 22:28:25.497749
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-16 22:28:39.137554
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-16 22:29:08.016432
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-16 22:29:21.684059
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-16 22:30:00.104758
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-16 22:30:21.669139
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-16 22:30:43.216626
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-16 22:31:54.051629
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-16 22:32:14.826663
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-16 22:33:33.108935
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-16 22:33:55.076120
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-16 22:34:31.992218
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-16 22:34:53.113197
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-16 22:35:42.653942
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-16 22:36:16.085427
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-16 22:36:50.177947
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-16 22:38:59.504280
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-16 22:39:33.500814
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-16 22:41:57.788229
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-16 22:42:31.619924
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-16 22:43:34.959464
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-16 22:44:10.199959
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-16 22:45:37.389753
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-16 22:46:32.721442
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-16 22:47:29.930701
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-16 22:50:07.404748
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-16 22:51:04.301235
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-16 22:54:01.191581
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-16 22:54:57.552557
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-16 22:56:52.605916
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-16 22:57:50.440490
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-16 23:00:33.617504
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-16 23:00:46.013204
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-16 23:00:57.532368
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-16 23:01:14.919820
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-16 23:01:22.595431
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-16 23:01:32.251521
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-16 23:01:45.720856
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-16 23:01:58.308068
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-16 23:02:11.202730
b''

Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 23:02:23.566086
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 23:02:32.323547
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 23:02:41.179795
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 23:02:52.210879
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 23:03:01.221838
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 23:03:10.425921
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 23:03:19.563907
b'Result (avg): 440.009\nResult (max): 2172.23\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 23:03:28.563651
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-16 23:03:37.699170
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 23:03:46.655231
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 23:03:55.607449
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 23:04:04.521469
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 23:04:13.733364
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 23:04:22.481325
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 23:04:31.607753
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 23:04:40.431578
b'Result (avg): 5.19272e-09\nResult (max): 5.37366e-08\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 23:04:49.299133
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-16 23:04:58.354052
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 23:05:07.279644
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 23:05:17.336130
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 23:05:27.314358
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 23:05:38.628424
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 23:05:48.341549
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 23:05:59.280708
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 23:06:09.668619
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 23:06:21.578473
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-16 23:06:31.555056
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 23:06:41.765831
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 23:07:02.162875
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 23:07:22.824625
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 23:07:46.509372
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 23:08:07.135436
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 23:08:32.042190
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 23:08:53.093665
b'Result (avg): 9960.22\nResult (max): 49152\n'

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 23:09:15.514067
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-16 23:09:35.981603
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 23:09:57.838108
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 23:11:28.322878
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 23:13:13.989627
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 23:15:04.832074
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 23:16:41.683692
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 23:18:12.299650
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 23:19:50.648554
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 23:21:34.921420
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-16 23:23:20.404304
b''

Pencil Default Inverse
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2037792] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2037792] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2038057] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2038057] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2038586] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2038586] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2038851] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2038851] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2039118] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2039118] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2039394] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2039394] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2039660] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2039660] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2039929] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2039929] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2040192] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2040192] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2040473] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2040473] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2040740] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2040740] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2041253] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2041253] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2041530] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2041530] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2041795] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2041795] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2042065] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2042065] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2042346] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2042346] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2042611] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2042611] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2042878] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2042878] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2043145] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2043145] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2043422] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2043422] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2043939] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2043939] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2044208] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2044208] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2044483] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2044483] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2044750] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2044750] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2045019] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2045019] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2045294] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2045294] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2045560] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2045560] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2045825] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2045825] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2046110] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2046110] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2046625] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2046625] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2046894] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2046894] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2047169] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2047169] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2047439] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2047439] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2047717] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2047717] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2047983] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2047983] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2048249] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2048249] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2048529] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2048529] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2048794] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2048794] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2049309] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2049309] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2049589] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2049589] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2049858] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2049858] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2050137] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2050137] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2050400] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2050400] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2050667] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2050667] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2050934] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2050934] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2051212] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2051212] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2051479] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2051479] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2051994] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2051994] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2052275] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2052275] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2052557] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2052557] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2052829] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2052829] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2053108] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2053108] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2053374] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2053374] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2053639] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2053639] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2053918] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2053918] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2054185] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2054185] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2054700] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2054700] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2055006] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2055006] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2055274] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2055274] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2055560] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2055560] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2055837] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2055837] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2056104] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2056104] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2056373] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2056373] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2056654] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2056654] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2056922] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2056922] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2057455] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2057455] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2057745] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2057745] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2058010] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2058010] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2058314] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2058314] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2058584] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2058584] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2058862] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2058862] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2059127] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2059127] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2059396] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2059396] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2059676] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2059676] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2060192] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2060192] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2060520] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2060520] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2060789] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2060789] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2061112] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2061112] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2061387] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2061387] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2061656] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2061656] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2061936] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2061936] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2062217] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2062217] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2062492] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2062492] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2063026] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2063026] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2063388] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2063388] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2063672] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2063672] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2064042] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2064042] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2064330] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2064330] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2064610] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2064610] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2064898] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2064898] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2065183] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2065183] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2065470] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2065470] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2066012] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2066012] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2066395] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2066395] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2066687] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2066687] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2067076] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2067076] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2067370] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2067370] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2067655] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2067655] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2067942] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2067942] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2068260] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2068260] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2068616] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2068616] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2069178] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2069178] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2069684] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2069684] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2069987] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2069987] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2070487] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2070487] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2070802] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2070802] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2071116] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2071116] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2071427] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2071427] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2071759] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2071759] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:2071772] *** An error occurred in MPI_Irecv
[uc2n514:2071772] *** reported by process [263979009,0]
[uc2n514:2071772] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2071772] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2071772] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2071772] ***    and potentially your MPI job)
[uc2n514.localdomain:2071759] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2072027] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2072027] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:2072039] *** An error occurred in MPI_Irecv
[uc2n514:2072039] *** reported by process [245891073,0]
[uc2n514:2072039] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2072039] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2072039] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2072039] ***    and potentially your MPI job)
[uc2n514.localdomain:2072027] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2072296] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2072296] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:2072308] *** An error occurred in MPI_Irecv
[uc2n514:2072308] *** reported by process [228261889,0]
[uc2n514:2072308] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2072308] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2072308] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2072308] ***    and potentially your MPI job)
[uc2n514.localdomain:2072296] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2072582] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2072582] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:2072594] *** An error occurred in MPI_Irecv
[uc2n514:2072594] *** reported by process [863305729,0]
[uc2n514:2072594] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2072594] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2072594] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2072594] ***    and potentially your MPI job)
[uc2n514.localdomain:2072582] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2072851] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2072851] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:2072863] *** An error occurred in MPI_Irecv
[uc2n514:2072863] *** reported by process [845152257,0]
[uc2n514:2072863] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2072863] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2072863] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2072863] ***    and potentially your MPI job)
[uc2n514.localdomain:2072851] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2073119] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2073119] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:2073131] *** An error occurred in MPI_Irecv
[uc2n514:2073131] *** reported by process [829161473,0]
[uc2n514:2073131] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2073131] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2073131] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2073131] ***    and potentially your MPI job)
[uc2n514.localdomain:2073119] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2073396] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2073396] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n516:4012214] *** An error occurred in MPI_Isend
[uc2n516:4012214] *** reported by process [809959425,13]
[uc2n516:4012214] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n516:4012214] *** MPI_ERR_COUNT: invalid count argument
[uc2n516:4012214] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n516:4012214] ***    and potentially your MPI job)
[uc2n514.localdomain:2073396] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2073666] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2073666] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:2073678] *** An error occurred in MPI_Alltoallv
[uc2n514:2073678] *** reported by process [925958145,0]
[uc2n514:2073678] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2073678] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2073678] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2073678] ***    and potentially your MPI job)
[uc2n514.localdomain:2073666] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2073931] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2073931] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:2073943] *** An error occurred in MPI_Alltoallw
[uc2n514:2073943] *** reported by process [909639681,0]
[uc2n514:2073943] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2073943] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2073943] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2073943] ***    and potentially your MPI job)
[uc2n514.localdomain:2073931] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-16 23:25:06.049665
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-16 23:25:21.598822
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-16 23:25:30.265580
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-16 23:25:40.687895
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-16 23:25:49.290440
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-16 23:25:59.833569
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-16 23:26:08.501840
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-16 23:26:17.239221
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-16 23:26:25.704559
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-16 23:26:34.514075
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-16 23:26:43.217677
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-16 23:26:51.919450
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-16 23:27:02.396379
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-16 23:27:11.050966
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-16 23:27:21.768139
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-16 23:27:31.261640
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-16 23:27:39.962448
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-16 23:27:48.692777
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-16 23:27:57.514653
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-16 23:28:06.287943
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-16 23:28:15.007389
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-16 23:28:27.604275
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-16 23:28:36.438859
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-16 23:28:49.153962
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-16 23:28:57.927099
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-16 23:29:08.043099
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-16 23:29:16.962762
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-16 23:29:25.801678
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-16 23:29:34.597679
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-16 23:29:43.389574
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-16 23:29:59.388578
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-16 23:30:08.297233
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-16 23:30:24.663940
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-16 23:30:33.876243
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-16 23:30:43.312086
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-16 23:30:52.239837
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-16 23:31:01.105420
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-16 23:31:10.077951
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-16 23:31:19.070727
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-16 23:31:35.967647
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-16 23:31:45.708545
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-16 23:32:02.234950
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-16 23:32:11.458244
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-16 23:32:20.611841
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-16 23:32:29.771512
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-16 23:32:39.470957
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-16 23:32:48.931238
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-16 23:32:58.473576
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-16 23:33:23.356500
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-16 23:33:32.808244
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-16 23:33:56.458845
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-16 23:34:05.919964
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-16 23:34:15.370226
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-16 23:34:25.017200
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-16 23:34:38.134860
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-16 23:34:48.921386
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-16 23:34:59.171246
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-16 23:35:37.803043
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-16 23:35:47.865212
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-16 23:36:26.089954
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-16 23:36:36.107391
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-16 23:36:46.208020
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-16 23:36:56.842682
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-16 23:37:07.890097
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-16 23:37:19.739014
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-16 23:37:31.590313
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-16 23:38:13.258871
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-16 23:38:25.044482
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-16 23:39:06.065376
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-16 23:39:18.578421
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-16 23:39:30.805404
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-16 23:39:42.427611
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-16 23:39:55.804803
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-16 23:40:10.470715
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-16 23:40:24.951411
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-16 23:41:36.288619
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-16 23:41:50.948881
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-16 23:43:00.774399
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-16 23:43:15.374760
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-16 23:43:30.002472
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-16 23:43:43.971618
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-16 23:44:01.280913
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-16 23:44:22.388011
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-16 23:44:43.568349
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-16 23:46:56.300484
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-16 23:47:17.896514
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-16 23:49:28.460773
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-16 23:49:49.537816
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-16 23:50:11.003796
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-16 23:50:32.609340
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-16 23:51:00.910224
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-16 23:51:35.490462
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-16 23:52:10.016956
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-16 23:54:39.580245
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-16 23:55:14.352608
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-16 23:57:42.256875
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-16 23:58:17.629117
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-16 23:58:53.717668
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-16 23:59:28.659944
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 00:00:16.947381
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 00:01:15.744892
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 00:02:15.799761
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 00:07:03.110390
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 00:08:01.688871
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 00:12:42.925181
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 00:13:41.977815
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 00:14:40.642766
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 00:15:39.835980
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 00:17:03.399987
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 00:17:13.353850
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 00:17:23.765265
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 00:17:33.871524
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 00:17:44.738318
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 00:17:54.769194
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 00:18:04.800850
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 00:18:16.735640
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 00:18:26.757250
b''

Pencil Opt1 Inverse
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2074210] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2074210] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2074474] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2074474] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2074991] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2074991] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2075274] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2075274] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2075541] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2075541] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2075808] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2075808] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2076336] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2076336] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2076600] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2076600] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2076867] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2076867] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2077134] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2077134] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2077411] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2077411] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2077921] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2077921] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2078188] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2078188] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2078471] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2078471] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2078739] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2078739] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2079254] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2079254] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2079518] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2079518] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2079795] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2079795] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2080064] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2080064] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2080326] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2080326] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2080853] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2080853] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2081118] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2081118] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2081385] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2081385] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2081666] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2081666] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2082183] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2082183] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2082450] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2082450] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2082717] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2082717] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2082993] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2082993] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2083260] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2083260] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2083771] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2083771] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2084050] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2084050] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2084316] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2084316] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2084583] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2084583] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2085116] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2085116] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2085380] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2085380] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2085647] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2085647] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2085914] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2085914] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2086191] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2086191] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2086707] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2086707] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2086983] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2086983] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2087248] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2087248] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2087519] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2087519] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2088048] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2088048] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2088314] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2088314] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2088581] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2088581] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2088860] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2088860] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2089127] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2089127] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2089644] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2089644] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2089923] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2089923] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2090189] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2090189] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2090471] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2090471] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2090984] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2090984] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2091251] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2091251] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2091518] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2091518] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2091795] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2091795] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2092062] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2092062] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2092577] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2092577] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2092860] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2092860] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2093139] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2093139] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2093415] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2093415] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2093942] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2093942] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2094211] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2094211] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2094476] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2094476] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2094753] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2094753] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2095020] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2095020] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2095535] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2095535] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2095842] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2095842] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2096109] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2096109] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2096396] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2096396] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2096927] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2096927] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2097194] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2097194] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2097459] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2097459] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2097744] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2097744] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2098010] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2098010] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2098535] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2098535] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2098831] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2098831] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2099108] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2099108] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2099401] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2099401] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2099921] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2099921] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2100204] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2100204] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2100474] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2100474] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2100756] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2100756] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2101036] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2101036] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2101562] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2101562] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2101884] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2101884] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2102160] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2102160] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2102495] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2102495] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2103026] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2103026] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2103297] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2103297] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2103579] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2103579] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2103867] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2103867] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2104157] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2104157] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2104692] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2104692] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2105061] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2105061] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2105360] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2105360] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2105736] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2105736] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2106285] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2106285] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2106560] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2106560] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2106865] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2106865] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2107158] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2107158] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2107468] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2107468] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2108028] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2108028] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2108413] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2108413] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2108723] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2108723] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2109117] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2109117] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2109675] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2109675] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2109987] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2109987] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2110291] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2110291] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n516:4050027] *** An error occurred in MPI_Irecv
[uc2n516:4050027] *** reported by process [2816606209,15]
[uc2n516:4050027] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n516:4050027] *** MPI_ERR_COUNT: invalid count argument
[uc2n516:4050027] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n516:4050027] ***    and potentially your MPI job)
[uc2n514.localdomain:2110638] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2110638] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2110638] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514:2110981] *** An error occurred in MPI_Irecv
[uc2n514:2110981] *** reported by process [2797535233,5]
[uc2n514:2110981] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2110981] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2110981] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2110981] ***    and potentially your MPI job)
[uc2n514.localdomain:2110963] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2110963] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2110963] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514:2111244] *** An error occurred in MPI_Irecv
[uc2n514:2111244] *** reported by process [2779840513,3]
[uc2n514:2111244] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2111244] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2111244] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2111244] ***    and potentially your MPI job)
[uc2n514.localdomain:2111229] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2111229] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2111229] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514:2111511] *** An error occurred in MPI_Irecv
[uc2n514:2111511] *** reported by process [2873491457,1]
[uc2n514:2111511] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2111511] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2111511] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2111511] ***    and potentially your MPI job)
[uc2n514.localdomain:2111498] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2111498] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2111498] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514:2111789] *** An error occurred in MPI_Irecv
[uc2n514:2111789] *** reported by process [2859204609,1]
[uc2n514:2111789] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2111789] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2111789] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2111789] ***    and potentially your MPI job)
[uc2n514.localdomain:2111776] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2111776] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2111776] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514:2112056] *** An error occurred in MPI_Irecv
[uc2n514:2112056] *** reported by process [2841968641,3]
[uc2n514:2112056] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2112056] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2112056] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2112056] ***    and potentially your MPI job)
[uc2n514.localdomain:2112041] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2112041] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2112041] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514:2112329] *** An error occurred in MPI_Irecv
[uc2n514:2112329] *** reported by process [2826371073,1]
[uc2n514:2112329] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2112329] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2112329] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2112329] ***    and potentially your MPI job)
[uc2n514.localdomain:2112315] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2112315] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2112315] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514:2112596] *** An error occurred in MPI_Alltoallv
[uc2n514:2112596] *** reported by process [2936799233,3]
[uc2n514:2112596] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2112596] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2112596] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2112596] ***    and potentially your MPI job)
[uc2n514.localdomain:2112576] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2112576] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2112576] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n516:4052279] *** An error occurred in MPI_Alltoallw
[uc2n516:4052279] *** reported by process [2920546305,11]
[uc2n516:4052279] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n516:4052279] *** MPI_ERR_COUNT: invalid count argument
[uc2n516:4052279] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n516:4052279] ***    and potentially your MPI job)
[uc2n514.localdomain:2112856] 15 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2112856] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2112856] 15 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
Starting computation for size 128
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-17 00:18:36.835606
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-17 00:18:45.359157
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-17 00:18:54.263654
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-17 00:19:04.126475
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-17 00:19:15.754378
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-17 00:19:25.130359
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-17 00:19:33.357338
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-17 00:19:41.675490
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-17 00:19:49.966929
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-17 00:19:58.422056
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-17 00:20:06.673465
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-17 00:20:14.986429
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-17 00:20:25.240050
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-17 00:20:33.458377
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-17 00:20:43.926004
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-17 00:20:52.203342
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-17 00:21:00.525452
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-17 00:21:08.876537
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-17 00:21:17.498551
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-17 00:21:25.799817
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-17 00:21:34.070865
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-17 00:21:44.270932
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-17 00:21:53.925098
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-17 00:22:04.997877
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-17 00:22:13.363407
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-17 00:22:21.830260
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-17 00:22:30.160032
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-17 00:22:39.075392
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-17 00:22:47.401341
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-17 00:22:55.718134
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-17 00:23:07.492081
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-17 00:23:15.820362
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-17 00:23:28.282471
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-17 00:23:36.704517
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-17 00:23:45.267871
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-17 00:23:53.554804
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-17 00:24:02.608442
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-17 00:24:11.139511
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-17 00:24:19.656112
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-17 00:24:34.633457
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-17 00:24:43.208607
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-17 00:24:59.169161
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-17 00:25:07.609183
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-17 00:25:16.295728
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-17 00:25:24.801467
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-17 00:25:34.809645
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-17 00:25:43.966755
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-17 00:25:52.994859
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-17 00:26:07.923743
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-17 00:26:16.781699
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-17 00:26:33.730640
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-17 00:26:42.583327
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-17 00:26:52.213979
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-17 00:27:01.082768
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-17 00:27:12.830753
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-17 00:27:22.249874
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-17 00:27:31.734452
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-17 00:27:53.522305
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-17 00:28:04.980194
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-17 00:28:29.311763
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-17 00:28:38.919688
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-17 00:28:48.561596
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-17 00:28:58.040572
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-17 00:29:10.370747
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-17 00:29:21.637639
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-17 00:29:32.318963
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-17 00:30:07.920246
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-17 00:30:18.629927
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-17 00:30:57.932389
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-17 00:31:08.627346
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-17 00:31:19.620972
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-17 00:31:30.299694
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-17 00:31:47.030340
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-17 00:32:00.295488
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-17 00:32:14.269153
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-17 00:32:51.271027
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-17 00:33:04.587374
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-17 00:33:46.211608
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-17 00:33:59.442361
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-17 00:34:13.467559
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-17 00:34:27.788505
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-17 00:34:52.791998
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-17 00:35:13.022126
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-17 00:35:33.466514
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-17 00:36:41.422543
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-17 00:37:01.771536
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-17 00:38:19.726561
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-17 00:38:40.106834
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-17 00:38:58.464939
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-17 00:39:19.217556
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-17 00:39:51.766077
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-17 00:40:24.477163
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-17 00:40:56.431758
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-17 00:43:04.082859
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-17 00:43:36.437514
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-17 00:46:02.852360
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-17 00:46:34.763290
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-17 00:47:02.978556
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-17 00:47:36.850310
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 00:48:31.931169
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 00:49:26.915147
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 00:50:22.546490
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 00:52:49.873831
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 00:53:45.031415
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 00:56:34.681470
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 00:57:29.739947
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 00:58:19.083592
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 00:59:16.184650
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 01:00:58.222149
b''

-> Executing test 1
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 01:01:08.518658
b''

-> Executing test 2
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 01:01:17.539765
b''

-> Executing test 3
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 01:01:26.591760
b''

-> Executing test 4
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 01:01:35.655529
b''

-> Executing test 5
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 01:01:45.041350
b''

-> Executing test 6
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 01:01:54.330258
b''

-> Executing test 7
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 01:02:00.520439
b''

-> Executing test 8
mpiexec -n 16 --mca btl_smcuda_use_cuda_ipc 0 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_0 --rankfile ../mpi/rankfile_0 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 8 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 01:02:10.477081
b''

Starting on HOST8
*****************************************************************************
Partition 2x4
-----------------------------------------------------------------------------
Pencil Default / Opt1
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2113129] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2113129] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2113128] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2113128] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2113397] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2113397] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2113486] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2113486] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2113915] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2113915] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2114003] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2114003] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2114198] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2114198] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2114215] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2114215] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2114466] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2114466] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2114483] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2114483] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2114739] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2114739] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2114757] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2114757] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2115010] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2115010] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2115275] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2115275] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2115530] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2115530] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2115558] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2115558] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2115811] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2115811] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2115828] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2115828] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2116082] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2116082] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2116095] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2116095] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2116352] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2116352] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2116369] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2116369] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2116871] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2116871] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2116888] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2116888] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2117156] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2117156] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2117173] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2117173] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2117424] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2117424] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2117441] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2117441] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2117697] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2117697] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2117714] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2117714] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2118216] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2118216] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2118233] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2118233] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2118486] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2118486] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2118503] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2118503] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2118771] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2118771] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2118788] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2118788] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2119052] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2119052] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2119046] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2119046] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2119318] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2119318] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2119406] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2119406] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2119836] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2119836] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2119948] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2119948] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2120115] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2120115] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2120132] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2120132] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2120385] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2120385] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2120403] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2120403] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2120660] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2120660] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2120678] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2120678] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2120923] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2120923] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2121196] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2121196] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2121452] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2121452] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2121481] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2121481] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2121734] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2121734] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2121751] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2121751] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2122007] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2122007] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2122024] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2122024] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2122276] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2122276] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2122294] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2122294] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2122794] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2122794] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2122811] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2122811] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2123083] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2123083] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2123097] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2123097] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2123116] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2123116] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2123373] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2123373] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2123626] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2123626] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2123641] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2123641] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2123673] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2123673] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2123919] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2123919] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2124191] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2124191] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2124436] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2124436] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2124465] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2124465] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2124716] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2124716] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2124734] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2124734] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2124989] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2124989] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2125006] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2125006] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2125260] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2125260] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2125289] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2125289] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2125795] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2125795] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2126050] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2126050] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2126065] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2126065] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2126085] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2126085] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2126345] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2126345] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2126604] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2126604] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2126625] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2126625] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2126648] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2126648] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2126814] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2126814] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2127165] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2127165] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2127322] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2127322] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2127436] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2127436] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2127706] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2127706] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2127723] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2127723] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2127976] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2127976] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2127993] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2127993] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2128248] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2128248] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2128265] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2128265] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2128771] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2128771] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2129014] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2129014] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2129050] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2129050] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2129068] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2129068] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2129085] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2129085] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2129351] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2129351] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2129339] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2129339] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2129627] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2129627] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2129640] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2129640] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2129662] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2129662] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2130167] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2130167] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2130319] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2130319] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2130436] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2130436] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2130548] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2130548] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2130719] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2130719] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2130971] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2130971] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2130990] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2130990] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2131249] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2131249] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2131750] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2131750] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2131767] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2131767] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2132035] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2132035] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2132056] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2132056] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2132072] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2132072] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2132105] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2132105] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2132359] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2132359] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2132378] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2132378] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2132631] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2132631] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2132662] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2132662] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2132675] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2132675] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2132693] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2132693] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2132710] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2132710] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2133216] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2133216] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2133485] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2133485] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2133743] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2133743] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2133998] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2133998] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2134016] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2134016] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2134271] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2134271] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2134289] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2134289] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2134812] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2134812] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2135075] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2135075] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2135100] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2135100] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2135122] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2135122] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2135376] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2135376] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2135393] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2135393] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2135644] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2135644] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2135681] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2135681] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2135697] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2135697] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2135730] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2135730] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2135842] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2135842] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2136249] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2136249] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2136509] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2136509] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2136779] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2136779] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2137033] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2137033] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2137052] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2137052] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2137305] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2137305] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2137325] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2137325] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2137830] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2137830] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2138102] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2138102] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2138133] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2138133] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2138157] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2138157] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2138182] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2138182] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2138204] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2138204] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2138462] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2138462] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2138736] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2138736] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2138751] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2138751] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2138782] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2138782] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2138822] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2138822] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2139332] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2139332] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2139593] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2139593] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2139857] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2139857] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2139874] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2139874] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2140131] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2140131] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2140151] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2140151] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2140430] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2140430] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2140941] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2140941] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2141233] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2141233] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2141247] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2141247] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2141286] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2141286] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2141304] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2141304] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2141368] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2141368] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2141371] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2141371] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2141639] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2141639] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2141794] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2141794] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2141924] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2141924] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2142021] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2142021] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2142051] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2142051] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2142070] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2142070] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2142576] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2142576] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2142850] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2142850] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2143111] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2143111] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2143395] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2143395] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2143665] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2143665] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2144176] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2144176] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2144470] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2144470] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2144487] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2144487] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2144545] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2144545] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2144563] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2144563] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2144623] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2144623] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2144885] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2144885] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n516:4080308] *** An error occurred in MPI_Irecv
[uc2n516:4080308] *** reported by process [684916737,2]
[uc2n516:4080308] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n516:4080308] *** MPI_ERR_COUNT: invalid count argument
[uc2n516:4080308] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n516:4080308] ***    and potentially your MPI job)
[uc2n514.localdomain:2145183] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2145183] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2145183] 1 more process has sent help message help-mpi-errors.txt / mpi_errors_are_fatal
[uc2n514.localdomain:2145183] 6 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n516:4080578] *** An error occurred in MPI_Irecv
[uc2n516:4080578] *** reported by process [687669249,0]
[uc2n516:4080578] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n516:4080578] *** MPI_ERR_COUNT: invalid count argument
[uc2n516:4080578] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n516:4080578] ***    and potentially your MPI job)
[uc2n514.localdomain:2145201] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2145201] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2145201] 1 more process has sent help message help-mpi-errors.txt / mpi_errors_are_fatal
[uc2n514.localdomain:2145201] 6 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2145217] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2145217] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n516:4080853] *** An error occurred in MPI_Irecv
[uc2n516:4080853] *** reported by process [680329217,3]
[uc2n516:4080853] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n516:4080853] *** MPI_ERR_COUNT: invalid count argument
[uc2n516:4080853] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n516:4080853] ***    and potentially your MPI job)
[uc2n514.localdomain:2145217] 7 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n516:4081138:0:4081138] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x149866400010)
[uc2n516:4081143:0:4081143] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1497f0400010)
[uc2n516:4081142:0:4081142] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x149c30400010)
[uc2n516:4081139:0:4081139] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1546bc400010)
[uc2n516:4081141:0:4081141] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x154752400000)
[uc2n516:4081140:0:4081140] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1490ce400000)
[uc2n516:4081136:0:4081136] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x146fb2400000)
[uc2n516:4081137:0:4081137] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14569e400000)
==== backtrace (tid:4081137) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:4081136) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:4081140) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:4081141) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015ddb5 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x00000000000cb0a6 mca_btl_smcuda_prepare_src()  ???:0
 5 0x000000000020ae1e mca_pml_ob1_send_request_start_rndv()  ???:0
 6 0x000000000020d3ea mca_pml_ob1_start()  ???:0
 7 0x00000000000e2769 ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
 8 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
 9 0x000000000009042b PMPI_Alltoallv()  ???:0
10 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
11 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
12 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
13 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
14 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
15 0x000000000040326b main()  ???:0
16 0x00000000000236a3 __libc_start_main()  ???:0
17 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:4081143) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:4081142) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:4081138) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:4081139) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x00000000001d5e80 cuMemGetAttribute()  ???:0
 3 0x00000000002ffe53 cudbgGetAPI()  ???:0
 4 0x00000000004359a6 cudbgApiInit()  ???:0
 5 0x000000000018d730 ???()  /lib64/libcuda.so.1:0
 6 0x000000000018df04 ???()  /lib64/libcuda.so.1:0
 7 0x00000000001904d9 ???()  /lib64/libcuda.so.1:0
 8 0x00000000001fe77e cuGraphAddMemAllocNode()  ???:0
 9 0x00000000000a2944 mca_common_cuda_cu_memcpy()  common_cuda.c:0
10 0x000000000007c563 opal_cuda_memcpy_sync()  ???:0
11 0x0000000000077119 non_overlap_cuda_copy_content_same_ddt()  opal_datatype_copy.c:0
12 0x000000000008db2a ompi_datatype_sndrcv()  ???:0
13 0x00000000000e280e ompi_coll_base_alltoallv_intra_basic_linear()  ???:0
14 0x00000000000ee702 ompi_coll_tuned_alltoallv_intra_dec_fixed()  ???:0
15 0x000000000009042b PMPI_Alltoallv()  ???:0
16 0x000000000002b790 MPIcuFFT_Pencil_Opt1<double>::All2All_Sync_FirstTranspose()  ???:0
17 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
18 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
19 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
20 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
21 0x000000000040326b main()  ???:0
22 0x00000000000236a3 __libc_start_main()  ???:0
23 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 7 with PID 4081143 on node uc2n516 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
[uc2n514.localdomain:2145245] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2145245] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n516:4081476:0:4081476] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x145180400000)
[uc2n516:4081479:0:4081479] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x154b60400000)
[uc2n516:4081475:0:4081475] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x14b644400000)
[uc2n516:4081480:0:4081480] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x1507e0400000)
==== backtrace (tid:4081476) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:4081475) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:4081479) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
==== backtrace (tid:4081480) ====
 0 0x00000000000565ee ucs_debug_print_backtrace()  /home/es/es_es/es_rakeller/WORK/BWHPC-C5/bwhpc-rpmbuild-svn/BUILD/openmpi-4.1.0/ucx-1.9.0/src/ucs/debug/debug.c:656
 1 0x0000000000012dd0 .annobin_sigaction.c()  sigaction.c:0
 2 0x000000000015dbf3 __memmove_avx_unaligned_erms()  :0
 3 0x00000000000731e8 opal_convertor_pack()  ???:0
 4 0x000000000008d803 ompi_datatype_sndrcv()  ???:0
 5 0x0000000000121984 mca_coll_basic_alltoallw_intra()  ???:0
 6 0x0000000000090ccb PMPI_Alltoallw()  ???:0
 7 0x000000000002c023 MPIcuFFT_Pencil_Opt1<double>::All2All_MPIType_FirstTranspose()  ???:0
 8 0x0000000000029f3f MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
 9 0x000000000001cfdf MPIcuFFT_Pencil_Opt1<double>::execR2C()  ???:0
10 0x000000000002dd66 Tests_Pencil_Random_3D<double>::testcase0()  ???:0
11 0x000000000002d667 Tests_Pencil_Random_3D<double>::run()  ???:0
12 0x000000000040326b main()  ???:0
13 0x00000000000236a3 __libc_start_main()  ???:0
14 0x00000000004035fe _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 3 with PID 4081476 on node uc2n516 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
[uc2n514.localdomain:2145258] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2145258] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n516:4081778] *** An error occurred in MPI_Irecv
[uc2n516:4081778] *** reported by process [682622977,1]
[uc2n516:4081778] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n516:4081778] *** MPI_ERR_COUNT: invalid count argument
[uc2n516:4081778] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n516:4081778] ***    and potentially your MPI job)
[uc2n514.localdomain:2145276] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2145276] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2145276] 7 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n516:4082064] *** An error occurred in MPI_Isend
[uc2n516:4082064] *** reported by process [792723457,4]
[uc2n516:4082064] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n516:4082064] *** MPI_ERR_COUNT: invalid count argument
[uc2n516:4082064] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n516:4082064] ***    and potentially your MPI job)
[uc2n514.localdomain:2145292] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2145292] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2145292] 7 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n516:4082334] *** An error occurred in MPI_Alltoallv
[uc2n516:4082334] *** reported by process [795082753,4]
[uc2n516:4082334] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n516:4082334] *** MPI_ERR_COUNT: invalid count argument
[uc2n516:4082334] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n516:4082334] ***    and potentially your MPI job)
[uc2n514.localdomain:2145320] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2145320] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2145320] 7 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n516:4082602] *** An error occurred in MPI_Alltoallw
[uc2n516:4082602] *** reported by process [796262401,3]
[uc2n516:4082602] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n516:4082602] *** MPI_ERR_COUNT: invalid count argument
[uc2n516:4082602] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n516:4082602] ***    and potentially your MPI job)
[uc2n514.localdomain:2145338] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2145338] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2145338] 7 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec has exited due to process rank 7 with PID 4082876 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2145353] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2145353] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec has exited due to process rank 6 with PID 4083155 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2145387] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2145387] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec has exited due to process rank 7 with PID 4083427 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2145400] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2145400] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec has exited due to process rank 7 with PID 4083696 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2145415] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2145415] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec has exited due to process rank 5 with PID 4083962 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2145431] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2145431] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec has exited due to process rank 7 with PID 4084235 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2145446] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2145446] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec has exited due to process rank 4 with PID 4084501 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2145460] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2145460] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec has exited due to process rank 6 with PID 4084786 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2145487] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2145487] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2145505] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2145505] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 7 with PID 4085057 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2145756] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2145756] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2145843] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2145843] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2146039] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2146039] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2146181] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2146181] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2146304] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2146304] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2146331] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2146331] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2146345] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2146345] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2146361] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2146361] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2146380] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2146380] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2146631] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2146631] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2146647] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2146647] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2146683] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2146683] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2146824] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2146824] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2146948] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2146948] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2146966] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2146966] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2146982] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2146982] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2147000] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2147000] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2147025] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2147025] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2147043] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2147043] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2147058] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2147058] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2147076] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2147076] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2147225] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2147225] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:2147089] *** An error occurred in MPI_Irecv
[uc2n514:2147089] *** reported by process [1346895873,7]
[uc2n514:2147089] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2147089] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2147089] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2147089] ***    and potentially your MPI job)
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2147355] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2147355] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2147359] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2147359] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:2147374] *** An error occurred in MPI_Irecv
[uc2n514:2147374] *** reported by process [1465057281,0]
[uc2n514:2147374] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2147374] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2147374] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2147374] ***    and potentially your MPI job)
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2147643] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2147643] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2147656] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2147656] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2147916] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2147916] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:2147665] *** An error occurred in MPI_Irecv
[uc2n514:2147665] *** reported by process [1443102721,3]
[uc2n514:2147665] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2147665] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2147665] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2147665] ***    and potentially your MPI job)
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2147932] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2147932] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2148046] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2148046] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:2147941] *** An error occurred in MPI_Irecv
[uc2n514:2147941] *** reported by process [1427111937,3]
[uc2n514:2147941] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2147941] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2147941] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2147941] ***    and potentially your MPI job)
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2148221] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2148221] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2148480] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2148480] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514:2148228] *** An error occurred in MPI_Irecv
[uc2n514:2148228] *** reported by process [1412497409,1]
[uc2n514:2148228] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2148228] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2148228] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2148228] ***    and potentially your MPI job)
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2148497] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2148497] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2148513] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2148513] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514:2148520] *** An error occurred in MPI_Irecv
[uc2n514:2148520] *** reported by process [1542258689,1]
[uc2n514:2148520] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2148520] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2148520] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2148520] ***    and potentially your MPI job)
[uc2n514.localdomain:2148513] 1 more process has sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2148770] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2148770] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2148787] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2148787] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:2148801] *** An error occurred in MPI_Irecv
[uc2n514:2148801] *** reported by process [1526661121,3]
[uc2n514:2148801] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2148801] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2148801] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2148801] ***    and potentially your MPI job)
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2149065] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2149065] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2149078] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2149078] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:2149085] *** An error occurred in MPI_Alltoallv
[uc2n514:2149085] *** reported by process [1503264769,1]
[uc2n514:2149085] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2149085] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2149085] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2149085] ***    and potentially your MPI job)
[uc2n514.localdomain:2149078] 1 more process has sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2149340] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2149340] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2149351] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2149351] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514:2149365] *** An error occurred in MPI_Alltoallw
[uc2n514:2149365] *** reported by process [1487601665,6]
[uc2n514:2149365] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2149365] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2149365] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2149365] ***    and potentially your MPI job)
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[24481,1],3]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n514.localdomain:2149613] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2149613] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2149757] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2149757] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[24246,1],4]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n514.localdomain:2149882] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2149882] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec has exited due to process rank 6 with PID 2150181 on
node uc2n514 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2150169] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2150169] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2150156] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2150156] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[17233,1],7]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n514.localdomain:2150429] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2150429] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec has exited due to process rank 5 with PID 2150702 on
node uc2n514 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2150691] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2150691] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[16744,1],7]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n514.localdomain:2150948] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2150948] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[16484,1],6]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n514.localdomain:2151208] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2151208] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[18303,1],7]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n514.localdomain:2151475] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2151475] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2151597] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2151597] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[17926,1],2]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n514.localdomain:2151754] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2151754] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2152013] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2152013] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2152275] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2152275] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2152557] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2152557] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2152811] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2152811] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2152840] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2152840] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2153095] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2153095] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2153353] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2153353] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2153629] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2153629] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2153884] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2153884] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2154150] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2154150] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2154167] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2154167] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2154423] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2154423] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2154682] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2154682] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2154964] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2154964] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2155215] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2155215] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2155253] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2155253] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2155510] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2155510] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2155770] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2155770] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2156044] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2156044] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2156301] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2156301] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2156476] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2156476] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2156581] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2156581] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2156839] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2156839] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2157099] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2157099] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2157361] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2157361] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2157406] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2157406] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2157664] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2157664] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2157924] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2157924] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2158179] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2158179] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2158213] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2158213] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2158487] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2158487] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2158747] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2158747] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2158998] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2158998] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2159034] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2159034] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2159293] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2159293] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec has exited due to process rank 6 with PID 4095472 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2159549] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2159549] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec has exited due to process rank 6 with PID 4095742 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2159577] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2159577] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec has exited due to process rank 4 with PID 4096010 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2159590] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2159590] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2159610] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2159610] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
mpiexec has exited due to process rank 6 with PID 4096281 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2159853] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2159853] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec has exited due to process rank 6 with PID 4096550 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2159876] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2159876] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec has exited due to process rank 6 with PID 4096817 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2159892] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2159892] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec has exited due to process rank 7 with PID 4097099 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2159923] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2159923] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec has exited due to process rank 4 with PID 4097366 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2159947] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2159947] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec has exited due to process rank 5 with PID 4097636 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2159985] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2159985] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
Starting computation for size 128
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-17 01:02:20.482121
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-17 01:02:26.569827
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-17 01:02:32.563385
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-17 01:02:39.241988
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-17 01:02:45.261404
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-17 01:02:52.253471
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-17 01:02:58.368478
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-17 01:03:04.690706
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128
2021-09-17 01:03:10.670904
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-17 01:03:17.262021
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-17 01:03:24.034080
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-17 01:03:30.144443
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-17 01:03:37.531927
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-17 01:03:43.571811
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-17 01:03:51.268085
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-17 01:03:57.294052
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-17 01:04:03.719101
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 256
2021-09-17 01:04:09.596262
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-17 01:04:17.050530
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-17 01:04:23.413149
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-17 01:04:29.594337
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-17 01:04:37.204752
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-17 01:04:43.263442
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-17 01:04:51.199897
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-17 01:04:57.432124
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-17 01:05:04.211132
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 256 -nz 256
2021-09-17 01:05:11.189543
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-17 01:05:18.843039
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-17 01:05:24.898636
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-17 01:05:30.948402
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-17 01:05:39.683190
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-17 01:05:45.792122
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-17 01:05:55.264603
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-17 01:06:01.347068
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-17 01:06:08.434577
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256
2021-09-17 01:06:14.527650
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-17 01:06:22.519630
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-17 01:06:28.717271
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-17 01:06:34.864235
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-17 01:06:46.569884
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-17 01:06:52.659702
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-17 01:07:06.482896
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-17 01:07:12.605354
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-17 01:07:20.667366
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 512
2021-09-17 01:07:26.887204
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-17 01:07:36.926848
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-17 01:07:43.074358
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-17 01:07:49.123332
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-17 01:08:00.669573
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-17 01:08:07.199715
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-17 01:08:20.658837
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-17 01:08:26.877273
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-17 01:08:37.633879
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 512 -nz 512
2021-09-17 01:08:43.796889
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-17 01:08:57.360641
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-17 01:09:03.600274
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-17 01:09:12.676757
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-17 01:09:30.267554
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-17 01:09:36.507081
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-17 01:09:58.104450
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-17 01:10:04.911018
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-17 01:10:15.260576
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512
2021-09-17 01:10:22.337082
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-17 01:10:37.251153
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-17 01:10:43.900734
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-17 01:10:50.558359
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-17 01:11:20.526226
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-17 01:11:27.133937
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-17 01:12:05.094995
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-17 01:12:11.738727
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-17 01:12:26.534402
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 1024
2021-09-17 01:12:33.435529
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-17 01:12:57.554283
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-17 01:13:04.558620
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-17 01:13:11.829648
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-17 01:13:44.879027
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-17 01:13:52.473788
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-17 01:14:33.358448
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-17 01:14:40.625451
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-17 01:15:04.755595
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 1024 -nz 1024
2021-09-17 01:15:12.513121
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-17 01:15:54.875670
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-17 01:16:03.731598
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-17 01:16:12.401349
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-17 01:17:11.001773
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-17 01:17:21.198075
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-17 01:18:37.355314
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-17 01:18:46.015411
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-17 01:19:15.949610
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024
2021-09-17 01:19:25.726613
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-17 01:20:19.869089
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-17 01:20:31.636486
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-17 01:20:43.483099
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-17 01:22:34.541061
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-17 01:22:47.435595
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-17 01:25:13.848596
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-17 01:25:25.499837
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-17 01:26:19.495544
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 2048
2021-09-17 01:26:33.527770
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-17 01:28:14.116409
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-17 01:28:20.956852
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-17 01:28:28.666504
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-17 01:28:39.305024
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-17 01:28:45.573032
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-17 01:28:52.799260
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-17 01:29:01.466069
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-17 01:29:15.149326
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 2048 -nz 2048
2021-09-17 01:29:24.424077
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-17 01:29:32.138229
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\n'

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-17 01:29:37.063499
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\n'

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-17 01:29:41.943437
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\n'

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-17 01:29:46.779399
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\n'

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-17 01:29:51.693130
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\n'

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-17 01:29:57.221116
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\n'

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-17 01:30:02.242178
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\n'

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-17 01:30:07.129334
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\n'

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048
2021-09-17 01:30:12.075801
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\n'

Starting computation for size 128
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-17 01:30:17.288922
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-17 01:30:24.842000
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-17 01:30:31.239838
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-17 01:30:37.524731
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-17 01:30:43.549770
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-17 01:30:50.047360
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-17 01:30:56.238311
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-17 01:31:02.566129
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-17 01:31:08.964316
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

Starting computation for size 256
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-17 01:31:15.038998
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-17 01:31:22.454604
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-17 01:31:29.205831
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-17 01:31:36.554218
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-17 01:31:43.205431
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-17 01:31:50.370840
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-17 01:31:56.940348
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-17 01:32:03.427510
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-17 01:32:09.900978
b'Result (avg): 5.19278e-09\nResult (max): 5.37366e-08\n'

Starting computation for size 512
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-17 01:32:16.976565
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-17 01:32:25.882578
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-17 01:32:34.327647
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-17 01:32:44.067449
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-17 01:32:52.913053
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-17 01:33:02.756773
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-17 01:33:11.945945
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-17 01:33:21.041556
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-17 01:33:29.912703
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

Starting computation for size 1024
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-17 01:33:39.215821
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-17 01:34:07.448291
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-17 01:34:35.880841
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-17 01:35:07.132927
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-17 01:35:35.398806
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-17 01:36:07.881942
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-17 01:36:36.352813
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-17 01:37:05.832539
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-17 01:37:33.972582
b'Result (avg): 7.69766e-07\nResult (max): 9.22813e-06\n'

Starting computation for size 2048
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-17 01:38:05.286613
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\n'

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-17 01:38:09.254777
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\n'

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-17 01:38:14.325028
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\n'

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-17 01:38:20.102765
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\n'

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-17 01:38:25.914585
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\n'

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-17 01:38:31.745448
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\n'

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-17 01:38:37.528870
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\n'

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-17 01:38:42.319109
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\n'

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-17 01:38:47.284359
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\n'

[uc2n514.localdomain:2159982] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2159982] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2160281] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2160281] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2160560] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2160560] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2160845] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2160845] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2161139] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2161139] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2161416] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2161416] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2161700] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2161700] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[28273,1],2]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n514.localdomain:2161981] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2161981] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[28016,1],4]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n514.localdomain:2162236] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2162236] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec has exited due to process rank 7 with PID 2162517 on
node uc2n514 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2162504] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2162504] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[37633,1],5]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n514.localdomain:2162764] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2162764] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec has exited due to process rank 5 with PID 2163035 on
node uc2n514 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2163024] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2163024] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[37144,1],4]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n514.localdomain:2163285] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2163285] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[36891,1],6]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n514.localdomain:2163542] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2163542] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[38695,1],5]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n514.localdomain:2163818] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2163818] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[38438,1],7]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n514.localdomain:2164075] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2164075] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
Starting computation for size 128
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128
2021-09-17 01:02:20.482309
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128
2021-09-17 01:02:26.402204
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128
2021-09-17 01:02:32.349193
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128
2021-09-17 01:02:40.164434
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128
2021-09-17 01:02:46.152405
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128
2021-09-17 01:02:54.179579
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128
2021-09-17 01:03:00.137179
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128
2021-09-17 01:03:06.064691
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128
2021-09-17 01:03:12.129304
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 256
2021-09-17 01:03:18.055415
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 256
2021-09-17 01:03:24.225774
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 256
2021-09-17 01:03:30.434704
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 256
2021-09-17 01:03:38.543567
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 256
2021-09-17 01:03:44.657076
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 256
2021-09-17 01:03:52.670096
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 256
2021-09-17 01:03:58.673345
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 256
2021-09-17 01:04:04.814926
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 256
2021-09-17 01:04:10.919256
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 256 -nz 256
2021-09-17 01:04:17.132532
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 256 -nz 256
2021-09-17 01:04:23.091380
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 256 -nz 256
2021-09-17 01:04:29.201842
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 256 -nz 256
2021-09-17 01:04:39.388842
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 256 -nz 256
2021-09-17 01:04:45.449197
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 256 -nz 256
2021-09-17 01:04:55.513961
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 256 -nz 256
2021-09-17 01:05:01.720644
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 256 -nz 256
2021-09-17 01:05:07.852749
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 256 -nz 256
2021-09-17 01:05:13.967677
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256
2021-09-17 01:05:20.264676
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256
2021-09-17 01:05:26.423967
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256
2021-09-17 01:05:32.583664
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256
2021-09-17 01:05:46.644105
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256
2021-09-17 01:05:52.736471
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256
2021-09-17 01:06:06.632335
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256
2021-09-17 01:06:12.647094
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256
2021-09-17 01:06:18.869469
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256
2021-09-17 01:06:24.970559
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 512
2021-09-17 01:06:31.357502
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 512
2021-09-17 01:06:37.645880
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 512
2021-09-17 01:06:44.005419
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 512
2021-09-17 01:06:58.337553
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 512
2021-09-17 01:07:04.762297
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 512
2021-09-17 01:07:19.176376
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 512
2021-09-17 01:07:25.652333
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 512
2021-09-17 01:07:32.290157
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 512
2021-09-17 01:07:38.708356
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 512 -nz 512
2021-09-17 01:07:45.697590
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 512 -nz 512
2021-09-17 01:07:52.174624
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 512 -nz 512
2021-09-17 01:07:58.670508
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 512 -nz 512
2021-09-17 01:08:21.179268
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 512 -nz 512
2021-09-17 01:08:27.678189
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 512 -nz 512
2021-09-17 01:08:50.003668
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 512 -nz 512
2021-09-17 01:08:56.411336
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 512 -nz 512
2021-09-17 01:09:03.109864
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 512 -nz 512
2021-09-17 01:09:09.710165
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512
2021-09-17 01:09:17.435436
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512
2021-09-17 01:09:23.943408
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512
2021-09-17 01:09:30.498752
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512
2021-09-17 01:10:09.859335
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512
2021-09-17 01:10:16.661682
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512
2021-09-17 01:10:54.476284
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512
2021-09-17 01:11:01.204536
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512
2021-09-17 01:11:08.704376
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512
2021-09-17 01:11:15.582150
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 1024
2021-09-17 01:11:24.700919
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 1024
2021-09-17 01:11:32.270344
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 1024
2021-09-17 01:11:39.730212
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 1024
2021-09-17 01:12:22.423386
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 1024
2021-09-17 01:12:30.147350
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 1024
2021-09-17 01:13:11.093554
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 1024
2021-09-17 01:13:18.883740
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 1024
2021-09-17 01:13:28.029649
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 1024
2021-09-17 01:13:35.898095
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 1024 -nz 1024
2021-09-17 01:13:48.285465
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 1024 -nz 1024
2021-09-17 01:13:56.763489
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 1024 -nz 1024
2021-09-17 01:14:05.314797
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 1024 -nz 1024
2021-09-17 01:15:22.472024
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 1024 -nz 1024
2021-09-17 01:15:31.135902
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 1024 -nz 1024
2021-09-17 01:16:45.389827
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 1024 -nz 1024
2021-09-17 01:16:54.034117
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 1024 -nz 1024
2021-09-17 01:17:05.346827
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 1024 -nz 1024
2021-09-17 01:17:14.367296
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024
2021-09-17 01:17:32.318648
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024
2021-09-17 01:17:42.646069
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024
2021-09-17 01:17:52.818407
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024
2021-09-17 01:20:19.848596
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024
2021-09-17 01:20:30.412477
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024
2021-09-17 01:22:50.688710
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024
2021-09-17 01:23:01.004990
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024
2021-09-17 01:23:17.258356
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024
2021-09-17 01:23:28.727806
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 2048
2021-09-17 01:23:58.293885
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 2048
2021-09-17 01:24:13.406525
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 2048
2021-09-17 01:24:28.359915
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 2048
2021-09-17 01:27:16.286533
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 2048
2021-09-17 01:27:31.995564
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 2048
2021-09-17 01:30:08.229850
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 2048
2021-09-17 01:30:23.405747
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 2048
2021-09-17 01:30:50.368317
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 2048
2021-09-17 01:31:07.744716
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 2048 -nz 2048
2021-09-17 01:32:01.979828
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 2048 -nz 2048
2021-09-17 01:32:09.953516
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 2048 -nz 2048
2021-09-17 01:32:17.209048
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 2048 -nz 2048
2021-09-17 01:32:33.823821
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 2048 -nz 2048
2021-09-17 01:32:41.533692
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 2048 -nz 2048
2021-09-17 01:32:57.785082
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 2048 -nz 2048
2021-09-17 01:33:05.616811
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 2048 -nz 2048
2021-09-17 01:33:13.424916
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 2048 -nz 2048
2021-09-17 01:33:21.267000
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048
2021-09-17 01:33:29.124056
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\n'

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048
2021-09-17 01:33:34.872957
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\n'

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048
2021-09-17 01:33:40.000996
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\n'

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048
2021-09-17 01:33:45.402368
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\n'

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048
2021-09-17 01:33:50.815899
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:187\n'

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048
2021-09-17 01:33:56.285609
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\n'

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048
2021-09-17 01:34:01.760166
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\n'

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048
2021-09-17 01:34:07.043010
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\n'

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048
2021-09-17 01:34:12.453184
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\n'

Starting computation for size 128
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-17 01:34:17.721523
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-17 01:34:23.585158
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-17 01:34:30.121286
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-17 01:34:36.983651
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-17 01:34:43.449859
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-17 01:34:50.197965
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-17 01:34:56.550669
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-17 01:35:02.992062
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 128 -ny 128 -nz 128 --testcase 4
2021-09-17 01:35:09.504677
b'Result (avg): 1.91723e-05\nResult (max): 7.43495e-05\n'

Starting computation for size 256
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-17 01:35:16.060398
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-17 01:35:23.041491
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-17 01:35:30.062143
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-17 01:35:37.727708
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-17 01:35:44.636094
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-17 01:35:52.091811
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-17 01:35:58.925931
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-17 01:36:05.983355
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 256 -ny 256 -nz 256 --testcase 4
2021-09-17 01:36:12.992200
b'Result (avg): 4.77529e-09\nResult (max): 5.11245e-08\n'

Starting computation for size 512
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-17 01:36:19.801740
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-17 01:36:29.326874
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-17 01:36:38.503240
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-17 01:36:50.239008
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-17 01:36:59.565738
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-17 01:37:10.776747
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-17 01:37:20.186490
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-17 01:37:29.550278
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 512 -ny 512 -nz 512 --testcase 4
2021-09-17 01:37:38.981233
b'Result (avg): 0.000153465\nResult (max): 0.000595014\n'

Starting computation for size 1024
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-17 01:37:48.466724
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-17 01:38:17.865004
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-17 01:38:47.206021
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-17 01:39:24.943620
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-17 01:39:54.453148
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-17 01:40:31.856669
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-17 01:41:01.377727
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-17 01:41:31.030022
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 1024 -ny 1024 -nz 1024 --testcase 4
2021-09-17 01:42:00.466713
b'Result (avg): 7.33017e-07\nResult (max): 8.68929e-06\n'

Starting computation for size 2048
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-17 01:42:31.106583
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\n'

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-17 01:42:36.829879
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\n'

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-17 01:42:42.112276
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\n'

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-17 01:42:47.712543
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\n'

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-17 01:42:53.181842
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:722\n'

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-17 01:42:58.550981
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\n'

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-17 01:43:04.030462
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\n'

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-17 01:43:09.503183
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\n'

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 1 --iterations 0 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/forward -nx 2048 -ny 2048 -nz 2048 --testcase 4
2021-09-17 01:43:14.555128
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\n'

Pencil Default / Opt1 Inverse
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2164338] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2164338] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2164339] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2164339] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2164697] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2164697] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2164609] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2164609] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2165124] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2165124] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2165141] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2165141] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2165409] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2165409] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2165426] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2165426] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2165677] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2165677] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2165696] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2165696] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2165951] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2165951] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2165968] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2165968] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2166221] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2166221] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2166239] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2166239] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2166484] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2166484] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2166524] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2166524] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2166687] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2166687] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2166792] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2166792] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2167035] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2167035] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2167063] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2167063] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2167226] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2167226] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2167336] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2167336] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2167480] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2167480] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2167852] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2167852] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2168096] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2168096] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2168139] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2168139] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2168142] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2168142] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2168412] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2168412] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2168606] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2168606] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2168684] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2168684] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2168687] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2168687] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2168969] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2168969] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2168955] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2168955] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2169236] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2169236] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2169253] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2169253] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2169510] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2169510] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2169513] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2169513] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2169783] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2169783] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2169886] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2169886] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2170054] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2170054] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2170142] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2170142] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2170571] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2170571] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2170726] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2170726] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2170852] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2170852] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2170869] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2170869] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2171126] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2171126] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2171143] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2171143] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2171396] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2171396] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2171414] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2171414] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2171667] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2171667] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2171702] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2171702] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2171939] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2171939] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2171972] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2171972] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2172228] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2172228] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2172247] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2172247] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2172500] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2172500] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2172520] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2172520] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2172772] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2172772] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2172789] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2172789] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2173303] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2173303] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2173320] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2173320] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2173573] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2173573] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2173593] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2173593] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2173830] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2173830] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2173864] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2173864] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2174110] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2174110] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2174146] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2174146] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2174163] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2174163] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2174309] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2174309] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2174436] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2174436] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2174687] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2174687] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2174707] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2174707] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2174958] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2174958] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2174975] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2174975] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2175248] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2175248] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2175266] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2175266] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2175523] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2175523] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2175719] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2175719] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2176042] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2176042] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2176290] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2176290] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2176330] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2176330] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2176493] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2176493] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2176599] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2176599] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2176776] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2176776] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2176868] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2176868] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2176888] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2176888] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2177131] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2177131] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2177160] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2177160] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2177422] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2177422] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2177439] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2177439] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2177693] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2177693] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2177712] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2177712] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2177963] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2177963] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2177983] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2177983] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2178240] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2178240] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2178493] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2178493] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2178775] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2178775] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2179026] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2179026] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2179047] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2179047] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2179064] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2179064] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2179218] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2179218] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2179349] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2179349] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2179603] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2179603] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2179622] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2179622] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2179642] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2179642] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2179897] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2179897] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2179925] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2179925] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2180175] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2180175] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2180195] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2180195] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2180439] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2180439] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2180466] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2180466] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2180724] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2180724] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2180979] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2180979] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2181010] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2181010] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2181262] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2181262] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2181529] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2181529] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2181786] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2181786] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2181816] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2181816] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2181834] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2181834] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2181851] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2181851] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2182107] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2182107] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2182124] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2182124] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2182395] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2182395] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2182413] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2182413] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2182429] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2182429] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2182450] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2182450] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2182720] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2182720] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2182981] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2182981] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2183234] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2183234] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2183252] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2183252] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2183503] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2183503] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2183534] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2183534] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2183792] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2183792] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2184300] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2184300] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2184570] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2184570] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2184586] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2184586] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2184604] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2184604] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2184625] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2184625] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2184893] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2184893] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2184910] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2184910] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2185184] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2185184] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2185197] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2185197] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2185215] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2185215] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2185232] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2185232] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2185489] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2185489] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2185759] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2185759] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2186017] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2186017] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2186270] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2186270] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2186286] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2186286] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2186303] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2186303] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2186579] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2186579] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2187091] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2187091] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2187362] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2187362] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2187378] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2187378] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2187410] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2187410] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2187428] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2187428] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2187448] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2187448] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2187724] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2187724] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2187999] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2187999] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2188015] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2188015] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2188031] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2188031] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2188077] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2188077] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2188333] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2188333] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2188610] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2188610] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2188863] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2188863] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2188885] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2188885] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2189137] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2189137] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2189169] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2189169] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2189429] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2189429] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2189937] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2189937] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2190232] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2190232] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2190250] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2190250] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2190283] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2190283] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2190299] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2190299] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2190408] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2190408] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2190661] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2190661] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2190679] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2190679] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2190946] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2190946] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2190963] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2190963] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2191054] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2191054] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2191088] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2191088] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2191341] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2191341] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2191361] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2191361] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2191641] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2191641] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2191899] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2191899] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2192176] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2192176] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2192440] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2192440] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2192961] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2192961] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2193264] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2193264] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2193283] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2193283] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2193338] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2193338] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2193359] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2193359] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2193402] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2193402] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2193678] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2193678] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n516:4131389] *** An error occurred in MPI_Irecv
[uc2n516:4131389] *** reported by process [3916759041,5]
[uc2n516:4131389] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n516:4131389] *** MPI_ERR_COUNT: invalid count argument
[uc2n516:4131389] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n516:4131389] ***    and potentially your MPI job)
[uc2n514.localdomain:2193976] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2193976] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2193976] 7 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n516:4131655] *** An error occurred in MPI_Irecv
[uc2n516:4131655] *** reported by process [3909615617,1]
[uc2n516:4131655] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n516:4131655] *** MPI_ERR_COUNT: invalid count argument
[uc2n516:4131655] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n516:4131655] ***    and potentially your MPI job)
[uc2n514.localdomain:2193989] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2193989] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2193989] 7 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n516:4131928] *** An error occurred in MPI_Irecv
[uc2n516:4131928] *** reported by process [3910664193,4]
[uc2n516:4131928] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n516:4131928] *** MPI_ERR_COUNT: invalid count argument
[uc2n516:4131928] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n516:4131928] ***    and potentially your MPI job)
[uc2n514.localdomain:2194005] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2194005] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2194005] 7 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n516:4132199] *** An error occurred in MPI_Irecv
[uc2n516:4132199] *** reported by process [3911778305,5]
[uc2n516:4132199] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n516:4132199] *** MPI_ERR_COUNT: invalid count argument
[uc2n516:4132199] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n516:4132199] ***    and potentially your MPI job)
[uc2n514.localdomain:2194020] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2194020] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2194020] 7 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n516:4132465] *** An error occurred in MPI_Irecv
[uc2n516:4132465] *** reported by process [3912826881,1]
[uc2n516:4132465] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n516:4132465] *** MPI_ERR_COUNT: invalid count argument
[uc2n516:4132465] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n516:4132465] ***    and potentially your MPI job)
[uc2n514.localdomain:2194036] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2194036] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2194036] 7 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n516:4132749] *** An error occurred in MPI_Irecv
[uc2n516:4132749] *** reported by process [3922460673,6]
[uc2n516:4132749] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n516:4132749] *** MPI_ERR_COUNT: invalid count argument
[uc2n516:4132749] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n516:4132749] ***    and potentially your MPI job)
[uc2n514.localdomain:2194049] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2194049] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2194049] 7 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n516:4133020] *** An error occurred in MPI_Irecv
[uc2n516:4133020] *** reported by process [3922853889,2]
[uc2n516:4133020] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n516:4133020] *** MPI_ERR_COUNT: invalid count argument
[uc2n516:4133020] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n516:4133020] ***    and potentially your MPI job)
[uc2n514.localdomain:2194079] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2194079] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2194079] 7 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n516:4133294] *** An error occurred in MPI_Alltoallv
[uc2n516:4133294] *** reported by process [3923968001,5]
[uc2n516:4133294] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n516:4133294] *** MPI_ERR_COUNT: invalid count argument
[uc2n516:4133294] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n516:4133294] ***    and potentially your MPI job)
[uc2n514.localdomain:2194094] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2194094] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2194094] 7 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n516:4133557] *** An error occurred in MPI_Alltoallw
[uc2n516:4133557] *** reported by process [3925016577,1]
[uc2n516:4133557] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n516:4133557] *** MPI_ERR_COUNT: invalid count argument
[uc2n516:4133557] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n516:4133557] ***    and potentially your MPI job)
[uc2n514.localdomain:2194110] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2194110] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2194110] 7 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec has exited due to process rank 6 with PID 4133833 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2194127] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2194127] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec has exited due to process rank 6 with PID 4134100 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2194140] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2194140] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec has exited due to process rank 6 with PID 4134379 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2194164] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2194164] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec has exited due to process rank 7 with PID 4134651 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2194185] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2194185] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec has exited due to process rank 5 with PID 4134917 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2194201] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2194201] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec has exited due to process rank 0 with PID 4135182 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2194216] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2194216] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec has exited due to process rank 5 with PID 4135458 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2194233] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2194233] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec has exited due to process rank 1 with PID 4135719 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2194246] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2194246] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n516
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec has exited due to process rank 2 with PID 4136008 on
node uc2n516 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2194274] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2194274] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
Starting computation for size 128
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-17 01:43:19.875789
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-17 01:43:25.941123
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-17 01:43:31.857517
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-17 01:43:38.669911
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-17 01:43:44.471266
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-17 01:43:51.465732
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-17 01:43:57.427806
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-17 01:44:03.538041
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-17 01:44:09.616815
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-17 01:44:16.190001
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-17 01:44:22.177704
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-17 01:44:28.218917
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-17 01:44:35.709467
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-17 01:44:41.740747
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-17 01:44:49.959551
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-17 01:44:56.646436
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-17 01:45:03.184242
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-17 01:45:09.236446
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-17 01:45:16.288834
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-17 01:45:23.671620
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-17 01:45:29.991407
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-17 01:45:37.467195
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-17 01:45:44.105979
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-17 01:45:51.988080
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-17 01:45:58.058650
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-17 01:46:05.059023
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-17 01:46:11.018221
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-17 01:46:19.487715
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-17 01:46:26.200472
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-17 01:46:32.271785
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-17 01:46:41.111562
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-17 01:46:47.224024
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-17 01:46:57.253853
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-17 01:47:04.024906
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-17 01:47:11.001134
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-17 01:47:17.021256
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-17 01:47:25.289025
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-17 01:47:31.379433
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-17 01:47:38.305551
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-17 01:47:50.064425
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-17 01:47:57.148418
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-17 01:48:11.129486
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-17 01:48:18.073041
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-17 01:48:26.048302
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-17 01:48:32.915614
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-17 01:48:43.421002
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-17 01:48:49.426641
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-17 01:48:55.546740
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-17 01:49:07.827956
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-17 01:49:15.143549
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-17 01:49:29.462468
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-17 01:49:36.097902
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-17 01:49:46.008800
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-17 01:49:52.823950
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-17 01:50:07.491420
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-17 01:50:13.576755
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-17 01:50:19.744598
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-17 01:50:37.242327
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-17 01:50:43.547771
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-17 01:51:05.741909
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-17 01:51:12.086461
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-17 01:51:23.718572
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-17 01:51:30.026920
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-17 01:51:45.615526
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-17 01:51:52.240163
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-17 01:51:58.836439
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-17 01:52:27.894123
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-17 01:52:34.448365
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-17 01:53:13.871334
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-17 01:53:20.558175
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-17 01:53:35.799682
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-17 01:53:42.768679
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-17 01:54:08.289927
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-17 01:54:15.708470
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-17 01:54:22.839353
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-17 01:54:54.242418
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-17 01:55:01.779197
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-17 01:55:43.914309
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-17 01:55:51.238126
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-17 01:56:13.933922
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-17 01:56:22.326278
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-17 01:57:08.919203
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-17 01:57:17.597666
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-17 01:57:25.926277
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-17 01:58:21.906637
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-17 01:58:30.981738
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-17 01:59:49.000942
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-17 01:59:57.608221
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-17 02:00:24.352421
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-17 02:00:34.129076
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-17 02:01:27.940684
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-17 02:01:39.622971
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-17 02:01:50.335751
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-17 02:03:35.878229
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-17 02:03:48.065158
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-17 02:06:17.455692
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-17 02:06:28.859413
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-17 02:07:16.232944
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-17 02:07:29.655996
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:09:10.611237
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:09:14.544310
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:09:20.300830
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:09:25.248623
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:09:31.195638
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:09:36.092548
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:09:42.477040
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:09:47.215477
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:09:53.589350
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:09:59.309182
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\n'

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:10:04.083074
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\n'

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:10:09.183682
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\n'

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:10:14.466039
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\n'

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:10:19.620584
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\n'

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:10:24.613307
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\n'

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:10:29.611193
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\n'

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:10:34.504629
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\n'

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_2 --rankfile ../mpi/rankfile_2 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse --opt 1 -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:10:39.419744
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\n'

--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2194297] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2194297] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2194569] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2194569] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2194835] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2194835] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514.localdomain:2195116] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2195116] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514:2195421] *** An error occurred in MPI_Irecv
[uc2n514:2195421] *** reported by process [3969515521,0]
[uc2n514:2195421] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2195421] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2195421] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2195421] ***    and potentially your MPI job)
[uc2n514.localdomain:2195415] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2195415] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2195415] 1 more process has sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514:2195678] *** An error occurred in MPI_Irecv
[uc2n514:2195678] *** reported by process [328794113,4]
[uc2n514:2195678] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2195678] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2195678] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2195678] ***    and potentially your MPI job)
[uc2n514.localdomain:2195668] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2195668] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2195668] 1 more process has sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514:2195934] *** An error occurred in MPI_Irecv
[uc2n514:2195934] *** reported by process [311754753,0]
[uc2n514:2195934] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2195934] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2195934] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2195934] ***    and potentially your MPI job)
[uc2n514.localdomain:2195928] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2195928] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2195928] 1 more process has sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514:2196197] *** An error occurred in MPI_Irecv
[uc2n514:2196197] *** reported by process [295043073,4]
[uc2n514:2196197] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2196197] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2196197] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2196197] ***    and potentially your MPI job)
[uc2n514.localdomain:2196187] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2196187] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2196187] 1 more process has sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514:2196469] *** An error occurred in MPI_Irecv
[uc2n514:2196469] *** reported by process [279052289,0]
[uc2n514:2196469] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2196469] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2196469] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2196469] ***    and potentially your MPI job)
[uc2n514.localdomain:2196463] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2196463] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2196463] 1 more process has sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514:2196736] *** An error occurred in MPI_Irecv
[uc2n514:2196736] *** reported by process [398131201,4]
[uc2n514:2196736] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2196736] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2196736] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2196736] ***    and potentially your MPI job)
[uc2n514.localdomain:2196726] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2196726] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2196726] 1 more process has sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514:2196995] *** An error occurred in MPI_Isend
[uc2n514:2196995] *** reported by process [380960769,5]
[uc2n514:2196995] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2196995] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2196995] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2196995] ***    and potentially your MPI job)
[uc2n514.localdomain:2196984] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2196984] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514:2197256] *** An error occurred in MPI_Alltoallv
[uc2n514:2197256] *** reported by process [364052481,4]
[uc2n514:2197256] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2197256] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2197256] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2197256] ***    and potentially your MPI job)
[uc2n514.localdomain:2197246] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2197246] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2197246] 1 more process has sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
[uc2n514:2197509] *** An error occurred in MPI_Alltoallw
[uc2n514:2197509] *** reported by process [347209729,0]
[uc2n514:2197509] *** on communicator MPI COMMUNICATOR 4 SPLIT FROM 0
[uc2n514:2197509] *** MPI_ERR_COUNT: invalid count argument
[uc2n514:2197509] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[uc2n514:2197509] ***    and potentially your MPI job)
[uc2n514.localdomain:2197503] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2197503] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[uc2n514.localdomain:2197503] 1 more process has sent help message help-mpi-errors.txt / mpi_errors_are_fatal
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[6748,1],7]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n514.localdomain:2197777] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2197777] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[6494,1],2]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n514.localdomain:2198035] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2198035] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec has exited due to process rank 6 with PID 2198308 on
node uc2n514 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2198295] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2198295] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[8022,1],6]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n514.localdomain:2198555] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2198555] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec has exited due to process rank 6 with PID 2198825 on
node uc2n514 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpiexec (as reported here).

You can avoid this message by specifying -quiet on the mpiexec command line.
--------------------------------------------------------------------------
[uc2n514.localdomain:2198813] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2198813] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[7533,1],4]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n514.localdomain:2199072] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2199072] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[7267,1],4]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n514.localdomain:2199342] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2199342] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[892,1],5]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n514.localdomain:2199601] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2199601] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
Open MPI failed an OFI Libfabric library call (fi_domain).  This is highly
unusual; your job may behave unpredictably (and/or abort) after this.

  Local host: uc2n514
  Location: mtl_ofi_component.c:911
  Error: No data available (61)
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[632,1],7]
  Exit code:    1
--------------------------------------------------------------------------
[uc2n514.localdomain:2199861] 7 more processes have sent help message help-mtl-ofi.txt / OFI call fail
[uc2n514.localdomain:2199861] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
Starting computation for size 128
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-17 01:43:19.875683
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-17 01:43:25.707952
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-17 01:43:32.113768
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-17 01:43:40.321644
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-17 01:43:46.768086
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-17 01:43:54.945705
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-17 01:44:01.307057
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-17 01:44:07.804818
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 128 --testcase 2
2021-09-17 01:44:14.146339
b''

Starting computation for size [128, 128, 256]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-17 01:44:20.384490
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-17 01:44:26.933147
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-17 01:44:33.494555
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-17 01:44:41.720411
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-17 01:44:48.228735
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-17 01:44:56.540083
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-17 01:45:03.061746
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-17 01:45:09.682850
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 128 -nz 256 --testcase 2
2021-09-17 01:45:16.193177
b''

Starting computation for size [128, 256, 256]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-17 01:45:22.825885
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-17 01:45:29.385994
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-17 01:45:35.919242
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-17 01:45:45.992597
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-17 01:45:52.595930
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-17 01:46:02.490402
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-17 01:46:09.025431
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-17 01:46:15.541913
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 128 -ny 256 -nz 256 --testcase 2
2021-09-17 01:46:22.050631
b''

Starting computation for size 256
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-17 01:46:28.628309
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-17 01:46:35.032376
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-17 01:46:41.623810
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-17 01:46:55.316204
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-17 01:47:01.738393
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-17 01:47:15.620832
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-17 01:47:22.168304
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-17 01:47:28.636561
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 256 --testcase 2
2021-09-17 01:47:34.884136
b''

Starting computation for size [256, 256, 512]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-17 01:47:41.657941
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-17 01:47:48.376825
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-17 01:47:54.976471
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-17 01:48:09.350948
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-17 01:48:16.190015
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-17 01:48:30.899593
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-17 01:48:37.517087
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-17 01:48:44.604070
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 256 -nz 512 --testcase 2
2021-09-17 01:48:51.392831
b''

Starting computation for size [256, 512, 512]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-17 01:48:58.646885
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-17 01:49:05.615783
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-17 01:49:12.458883
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-17 01:49:34.529135
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-17 01:49:41.332686
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-17 01:50:03.575117
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-17 01:50:10.365089
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-17 01:50:17.686392
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 256 -ny 512 -nz 512 --testcase 2
2021-09-17 01:50:24.582052
b''

Starting computation for size 512
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-17 01:50:32.659047
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-17 01:50:39.705820
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-17 01:50:46.576783
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-17 01:51:24.557504
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-17 01:51:31.501527
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-17 01:52:07.108479
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-17 01:52:14.051237
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-17 01:52:21.881356
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 512 --testcase 2
2021-09-17 01:52:29.127315
b''

Starting computation for size [512, 512, 1024]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-17 01:52:38.760593
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-17 01:52:46.771047
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-17 01:52:54.729816
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-17 01:53:36.927354
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-17 01:53:45.034398
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-17 01:54:25.329915
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-17 01:54:33.468934
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-17 01:54:43.215107
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 512 -nz 1024 --testcase 2
2021-09-17 01:54:51.471414
b''

Starting computation for size [512, 1024, 1024]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-17 01:55:04.381470
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-17 01:55:13.337425
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-17 01:55:22.204656
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-17 01:56:35.891906
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-17 01:56:44.764711
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-17 01:57:56.505669
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-17 01:58:05.525245
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-17 01:58:17.333677
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 512 -ny 1024 -nz 1024 --testcase 2
2021-09-17 01:58:26.854058
b''

Starting computation for size 1024
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-17 01:58:45.281223
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-17 01:58:56.025647
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-17 01:59:06.671065
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-17 02:01:22.495751
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-17 02:01:33.244789
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-17 02:03:42.724256
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-17 02:03:53.439982
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-17 02:04:09.953908
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 1024 --testcase 2
2021-09-17 02:04:21.866440
b''

Starting computation for size [1024, 1024, 2048]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-17 02:04:51.629812
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-17 02:05:06.885669
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-17 02:05:21.907371
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-17 02:08:05.468608
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-17 02:08:20.772856
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-17 02:10:54.961774
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-17 02:11:10.321776
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-17 02:11:37.055199
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 1024 -nz 2048 --testcase 2
2021-09-17 02:11:54.486530
b''

Starting computation for size [1024, 2048, 2048]
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:12:48.482368
b''

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:12:54.342554
b''

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:12:59.932528
b''

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:13:05.514095
b''

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:13:11.034715
b''

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:13:16.665510
b''

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:13:22.232665
b''

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:13:28.488042
b''

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 1024 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:13:34.274932
b''

Starting computation for size 2048
-> Executing test 0
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:13:39.848964
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\n'

-> Executing test 1
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Streams -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:13:45.287357
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\n'

-> Executing test 2
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:13:50.600065
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\n'

-> Executing test 3
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 Sync -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:13:56.006294
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\n'

-> Executing test 4
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 All2All -snd1 MPI_Type -comm2 Peer2Peer -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:14:01.439925
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/tests/src/pencil/random_dist_3D.cu:539\n'

-> Executing test 5
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 Streams --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:14:06.826705
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\n'

-> Executing test 6
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 Peer2Peer -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:14:12.371485
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\n'

-> Executing test 7
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 Sync --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:14:17.745411
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\n'

-> Executing test 8
mpiexec -n 8 --mca btl_openib_warn_default_gid_prefix 0 --hostfile ../mpi/hostfile_1 --rankfile ../mpi/rankfile_1 pencil -comm1 Peer2Peer -snd1 Sync -comm2 All2All -snd2 MPI_Type --warmup-rounds 10 --iterations 20 --double_prec --cuda_aware -p1 2 -p2 4 -b ../benchmarks/bwunicluster/gpu8/small/inverse -nx 2048 -ny 2048 -nz 2048 --testcase 2
2021-09-17 02:14:23.126085
b'Error 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\nError 2 at /home/st/st_us-051200/st_st160727/DistributedFFT/src/pencil/mpicufft_pencil.cpp:339\n'

all done

============================= JOB FEEDBACK =============================

NodeName=uc2n[514,516]
Job ID: 19784344
Cluster: uc2
User/Group: st_st160727/st_us-051200
State: COMPLETED (exit code 0)
Nodes: 2
Cores per node: 80
CPU Utilized: 4-08:43:08
CPU Efficiency: 6.99% of 62-09:28:00 core-walltime
Job Wall-clock time: 09:21:33
Memory Utilized: 71.20 GB
Memory Efficiency: 0.00% of 0.00 MB
